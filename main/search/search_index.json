{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#overview","title":"Overview","text":"<p>TODO</p>"},{"location":"#motivation","title":"Motivation","text":"<p>TODO</p>"},{"location":"#api-stability","title":"API stability","text":"<p> While <code>arkas</code> is in development stage, no API is guaranteed to be stable from one release to the next. In fact, it is very likely that the API will change multiple times before a stable 1.0.0 release. In practice, this means that upgrading <code>arkas</code> to a new version will possibly break any code that was using the old version of <code>arkas</code>.</p>"},{"location":"#license","title":"License","text":"<p><code>arkas</code> is licensed under BSD 3-Clause \"New\" or \"Revised\" license available in LICENSE file.</p>"},{"location":"get_started/","title":"Get Started","text":"<p>It is highly recommended to install in a virtual environment to keep your system in order.</p>"},{"location":"get_started/#installing-with-pip-recommended","title":"Installing with <code>pip</code> (recommended)","text":"<p>The following command installs the latest version of the library:</p> <pre><code>pip install arkas\n</code></pre> <p>To make the package as slim as possible, only the packages required to use <code>arkas</code> are installed. It is possible to install all the optional dependencies by running the following command:</p> <pre><code>pip install 'arkas[all]'\n</code></pre> <p>This command also installed NumPy and PyTorch. It is also possible to install the optional packages manually or to select the packages to install. In the following example, only NumPy is installed:</p> <pre><code>pip install arkas numpy\n</code></pre>"},{"location":"get_started/#installing-from-source","title":"Installing from source","text":"<p>To install <code>arkas</code> from source, you can follow the steps below. First, you will need to install <code>poetry</code>. <code>poetry</code> is used to manage and install the dependencies. If <code>poetry</code> is already installed on your machine, you can skip this step. There are several ways to install <code>poetry</code> so you can use the one that you prefer. You can check the <code>poetry</code> installation by running the following command:</p> <pre><code>poetry --version\n</code></pre> <p>Then, you can clone the git repository:</p> <pre><code>git clone git@github.com:durandtibo/arkas.git\n</code></pre> <p>It is recommended to create a Python 3.8+ virtual environment. This step is optional so you can skip it. To create a virtual environment, you can use the following command:</p> <pre><code>make conda\n</code></pre> <p>It automatically creates a conda virtual environment. When the virtual environment is created, you can activate it with the following command:</p> <pre><code>conda activate arkas\n</code></pre> <p>This example uses <code>conda</code> to create a virtual environment, but you can use other tools or configurations. Then, you should install the required package to use <code>arkas</code> with the following command:</p> <pre><code>make install\n</code></pre> <p>This command will install all the required packages. You can also use this command to update the required packages. This command will check if there is a more recent package available and will install it. Finally, you can test the installation with the following command:</p> <pre><code>make unit-test-cov\n</code></pre>"},{"location":"refs/analyzer/","title":"arkas.analyzer","text":""},{"location":"refs/analyzer/#arkas.analyzer","title":"arkas.analyzer","text":"<p>Contain DataFrame analyzers.</p>"},{"location":"refs/analyzer/#arkas.analyzer.AccuracyAnalyzer","title":"arkas.analyzer.AccuracyAnalyzer","text":"<p>               Bases: <code>BaseTruePredAnalyzer</code></p> <p>Implement the accuracy analyzer.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; analyzer = AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; analyzer\nAccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n&gt;&gt;&gt; frame = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = analyzer.analyze(frame)\n&gt;&gt;&gt; result\nAccuracyOutput(\n  (state): AccuracyState(y_true=(6,), y_pred=(6,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BaseAnalyzer","title":"arkas.analyzer.BaseAnalyzer","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to analyze a DataFrame.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; analyzer = AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; analyzer\nAccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = analyzer.analyze(data)\n&gt;&gt;&gt; result\nAccuracyOutput(\n  (state): AccuracyState(y_true=(6,), y_pred=(6,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BaseAnalyzer.analyze","title":"arkas.analyzer.BaseAnalyzer.analyze","text":"<pre><code>analyze(frame: DataFrame) -&gt; BaseOutput\n</code></pre> <p>Analyze the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The DataFrame to analyze.</p> required <p>Returns:</p> Type Description <code>BaseOutput</code> <p>The generated output.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; analyzer = AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = analyzer.analyze(data)\n&gt;&gt;&gt; result\nAccuracyOutput(\n  (state): AccuracyState(y_true=(6,), y_pred=(6,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BaseTruePredAnalyzer","title":"arkas.analyzer.BaseTruePredAnalyzer","text":"<p>               Bases: <code>BaseAnalyzer</code></p> <p>Define a base class to implement <code>polars.DataFrame</code> analyzer that takes two input columns: <code>y_true</code> and <code>y_pred</code>.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> required <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> required"},{"location":"refs/analyzer/#arkas.analyzer.is_analyzer_config","title":"arkas.analyzer.is_analyzer_config","text":"<pre><code>is_analyzer_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseAnalyzer</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseAnalyzer</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.analyzer import is_analyzer_config\n&gt;&gt;&gt; is_analyzer_config({\"_target_\": \"arkas.analyzer.AccuracyAnalyzer\"})\nTrue\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.setup_analyzer","title":"arkas.analyzer.setup_analyzer","text":"<pre><code>setup_analyzer(\n    analyzer: BaseAnalyzer | dict,\n) -&gt; BaseAnalyzer\n</code></pre> <p>Set up an analyzer.</p> <p>The analyzer is instantiated from its configuration by using the <code>BaseAnalyzer</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>analyzer</code> <code>BaseAnalyzer | dict</code> <p>An analyzer or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseAnalyzer</code> <p>An instantiated analyzer.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.analyzer import setup_analyzer\n&gt;&gt;&gt; analyzer = setup_analyzer(\n...     {\n...         \"_target_\": \"arkas.analyzer.AccuracyAnalyzer\",\n...         \"y_true\": \"target\",\n...         \"y_pred\": \"pred\",\n...     }\n... )\n&gt;&gt;&gt; analyzer\nAccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/","title":"arkas.evaluator","text":""},{"location":"refs/evaluator/#arkas.evaluator","title":"arkas.evaluator","text":"<p>Contain evaluators.</p>"},{"location":"refs/evaluator/#arkas.evaluator.AccuracyEvaluator","title":"arkas.evaluator.AccuracyEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[AccuracyResult]</code></p> <p>Implement the accuracy evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.AveragePrecisionEvaluator","title":"arkas.evaluator.AveragePrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[AveragePrecisionResult]</code></p> <p>Implement the average precision evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, <code>'multilabel'</code>, and <code>'auto'</code>. If <code>'auto'</code>, it tries to automatically find the label type from the arrays' shape.</p> <code>'auto'</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_score</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AveragePrecisionEvaluator\n&gt;&gt;&gt; evaluator = AveragePrecisionEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nAveragePrecisionEvaluator(y_true='target', y_score='pred', label_type='auto', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [2, -1, 0, 3, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nAveragePrecisionResult(y_true=(5,), y_score=(5,), label_type='binary', nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BalancedAccuracyEvaluator","title":"arkas.evaluator.BalancedAccuracyEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BalancedAccuracyResult]</code></p> <p>Implement the accuracy evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BalancedAccuracyEvaluator\n&gt;&gt;&gt; evaluator = BalancedAccuracyEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBalancedAccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBalancedAccuracyResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BaseEvaluator","title":"arkas.evaluator.BaseEvaluator","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to evaluate a DataFrame.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BaseEvaluator.evaluate","title":"arkas.evaluator.BaseEvaluator.evaluate","text":"<pre><code>evaluate(data: DataFrame, lazy: bool = True) -&gt; BaseResult\n</code></pre> <p>Evaluate the result.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The data to evaluate.</p> required <code>lazy</code> <code>bool</code> <p>If <code>True</code>, it forces the computation of the result, otherwise it returns a result object that delays the evaluation of the result.</p> <code>True</code> <p>Returns:</p> Type Description <code>BaseResult</code> <p>The generated result.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BaseLazyEvaluator","title":"arkas.evaluator.BaseLazyEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code>, <code>Generic[T]</code></p> <p>Define the base class to evaluate the result lazily.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryAveragePrecisionEvaluator","title":"arkas.evaluator.BinaryAveragePrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryAveragePrecisionResult]</code></p> <p>Implement the average precision evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryAveragePrecisionEvaluator\n&gt;&gt;&gt; evaluator = BinaryAveragePrecisionEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryAveragePrecisionEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [2, -1, 0, 3, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryAveragePrecisionResult(y_true=(5,), y_score=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryClassificationEvaluator","title":"arkas.evaluator.BinaryClassificationEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryClassificationResult]</code></p> <p>Implement the average precision evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>y_score</code> <code>str | None</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> <code>None</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryClassificationEvaluator\n&gt;&gt;&gt; evaluator = BinaryClassificationEvaluator(\n...     y_true=\"target\", y_pred=\"pred\", y_score=\"score\"\n... )\n&gt;&gt;&gt; evaluator\nBinaryClassificationEvaluator(y_true='target', y_pred='pred', y_score='score', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [1, 0, 0, 1, 1],\n...         \"score\": [2, -1, 0, 3, 1],\n...         \"target\": [1, 0, 0, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryClassificationResult(y_true=(5,), y_pred=(5,), y_score=(5,), betas=(1,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryConfusionMatrixEvaluator","title":"arkas.evaluator.BinaryConfusionMatrixEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryConfusionMatrixResult]</code></p> <p>Implement the confusion matrix evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryConfusionMatrixEvaluator\n&gt;&gt;&gt; evaluator = BinaryConfusionMatrixEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryConfusionMatrixEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryConfusionMatrixResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryFbetaScoreEvaluator","title":"arkas.evaluator.BinaryFbetaScoreEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryFbetaScoreResult]</code></p> <p>Implement the F-beta evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryFbetaScoreEvaluator\n&gt;&gt;&gt; evaluator = BinaryFbetaScoreEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryFbetaScoreEvaluator(y_true='target', y_pred='pred', betas=(1,), drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(\n...     data=pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n... )\n&gt;&gt;&gt; result\nBinaryFbetaScoreResult(y_true=(5,), y_pred=(5,), betas=(1,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryJaccardEvaluator","title":"arkas.evaluator.BinaryJaccardEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryJaccardResult]</code></p> <p>Implement the Jaccard evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryJaccardEvaluator\n&gt;&gt;&gt; evaluator = BinaryJaccardEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryJaccardEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryJaccardResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryPrecisionEvaluator","title":"arkas.evaluator.BinaryPrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryPrecisionResult]</code></p> <p>Implement the precision evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryPrecisionEvaluator\n&gt;&gt;&gt; evaluator = BinaryPrecisionEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryPrecisionEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryPrecisionResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryRecallEvaluator","title":"arkas.evaluator.BinaryRecallEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryRecallResult]</code></p> <p>Implement the recall evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryRecallEvaluator\n&gt;&gt;&gt; evaluator = BinaryRecallEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryRecallEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryRecallResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryRocAucEvaluator","title":"arkas.evaluator.BinaryRocAucEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryRocAucResult]</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryRocAucEvaluator\n&gt;&gt;&gt; evaluator = BinaryRocAucEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryRocAucEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [2, -1, 0, 3, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryRocAucResult(y_true=(5,), y_score=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.EnergyDistanceEvaluator","title":"arkas.evaluator.EnergyDistanceEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[EnergyDistanceResult]</code></p> <p>Implement the energy distance between two 1D distributions evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>v_values</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import EnergyDistanceEvaluator\n&gt;&gt;&gt; evaluator = EnergyDistanceEvaluator(u_values=\"target\", v_values=\"pred\")\n&gt;&gt;&gt; evaluator\nEnergyDistanceEvaluator(u_values='target', v_values='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nEnergyDistanceResult(u_values=(5,), v_values=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.JensenShannonDivergenceEvaluator","title":"arkas.evaluator.JensenShannonDivergenceEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[JensenShannonDivergenceResult]</code></p> <p>Implement the Jensen-Shannon (JS) divergence between two distributions evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>q</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import JensenShannonDivergenceEvaluator\n&gt;&gt;&gt; evaluator = JensenShannonDivergenceEvaluator(p=\"target\", q=\"pred\")\n&gt;&gt;&gt; evaluator\nJensenShannonDivergenceEvaluator(p='target', q='pred', drop_nulls=True)\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nJensenShannonDivergenceResult(p=(5,), q=(5,))\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.KLDivEvaluator","title":"arkas.evaluator.KLDivEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[KLDivResult]</code></p> <p>Implement the Kullback-Leibler (KL) divergence between two distributions evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>q</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import KLDivEvaluator\n&gt;&gt;&gt; evaluator = KLDivEvaluator(p=\"target\", q=\"pred\")\n&gt;&gt;&gt; evaluator\nKLDivEvaluator(p='target', q='pred', drop_nulls=True)\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nKLDivResult(p=(5,), q=(5,))\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MappingEvaluator","title":"arkas.evaluator.MappingEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement an evaluator that sequentially evaluates a mapping of evaluators.</p> <p>Parameters:</p> Name Type Description Default <code>evaluators</code> <code>Mapping[Hashable, BaseEvaluator]</code> <p>The mapping of evaluators to evaluate.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import (\n...     MappingEvaluator,\n...     BinaryPrecisionEvaluator,\n...     BinaryRecallEvaluator,\n... )\n&gt;&gt;&gt; evaluator = MappingEvaluator(\n...     {\n...         \"precision\": BinaryPrecisionEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         \"recall\": BinaryRecallEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...     }\n... )\n&gt;&gt;&gt; evaluator\nMappingEvaluator(\n  (precision): BinaryPrecisionEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n  (recall): BinaryRecallEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n)\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMappingResult(count=2)\n&gt;&gt;&gt; result = evaluator.evaluate(data, lazy=False)\n&gt;&gt;&gt; result\nResult(metrics=2, figures=2)\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MeanAbsoluteErrorEvaluator","title":"arkas.evaluator.MeanAbsoluteErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MeanAbsoluteErrorResult]</code></p> <p>Implement the mean absolute error (MAE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MeanAbsoluteErrorEvaluator\n&gt;&gt;&gt; evaluator = MeanAbsoluteErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMeanAbsoluteErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMeanAbsoluteErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MeanAbsolutePercentageErrorEvaluator","title":"arkas.evaluator.MeanAbsolutePercentageErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MeanAbsolutePercentageErrorResult]</code></p> <p>Implement the mean absolute percentage error (MAPE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MeanAbsolutePercentageErrorEvaluator\n&gt;&gt;&gt; evaluator = MeanAbsolutePercentageErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMeanAbsolutePercentageErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMeanAbsolutePercentageErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MeanSquaredErrorEvaluator","title":"arkas.evaluator.MeanSquaredErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MeanSquaredErrorResult]</code></p> <p>Implement the mean squared error (MSE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MeanSquaredErrorEvaluator\n&gt;&gt;&gt; evaluator = MeanSquaredErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMeanSquaredErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMeanSquaredErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MeanSquaredLogErrorEvaluator","title":"arkas.evaluator.MeanSquaredLogErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MeanSquaredLogErrorResult]</code></p> <p>Implement the mean squared logarithmic error (MSLE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MeanSquaredLogErrorEvaluator\n&gt;&gt;&gt; evaluator = MeanSquaredLogErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMeanSquaredLogErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMeanSquaredLogErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MeanTweedieDevianceEvaluator","title":"arkas.evaluator.MeanTweedieDevianceEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MeanTweedieDevianceResult]</code></p> <p>Implement the mean Tweedie deviance regression loss evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MeanTweedieDevianceEvaluator\n&gt;&gt;&gt; evaluator = MeanTweedieDevianceEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMeanTweedieDevianceEvaluator(y_true='target', y_pred='pred', powers=(0,), drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMeanTweedieDevianceResult(y_true=(5,), y_pred=(5,), powers=(0,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MedianAbsoluteErrorEvaluator","title":"arkas.evaluator.MedianAbsoluteErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MedianAbsoluteErrorResult]</code></p> <p>Implement the median absolute error (MAE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MedianAbsoluteErrorEvaluator\n&gt;&gt;&gt; evaluator = MedianAbsoluteErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMedianAbsoluteErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMedianAbsoluteErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassAveragePrecisionEvaluator","title":"arkas.evaluator.MulticlassAveragePrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassAveragePrecisionResult]</code></p> <p>Implement the average precision evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_score</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassAveragePrecisionEvaluator\n&gt;&gt;&gt; evaluator = MulticlassAveragePrecisionEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassAveragePrecisionEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.5, 0.3],\n...             [0.3, 0.3, 0.4],\n...             [0.1, 0.2, 0.7],\n...         ],\n...         \"target\": [0, 0, 1, 1, 2, 2],\n...     },\n...     schema={\"pred\": pl.Array(pl.Float64, 3), \"target\": pl.Int64},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassAveragePrecisionResult(y_true=(6,), y_score=(6, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassConfusionMatrixEvaluator","title":"arkas.evaluator.MulticlassConfusionMatrixEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassConfusionMatrixResult]</code></p> <p>Implement the confusion matrix evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassConfusionMatrixEvaluator\n&gt;&gt;&gt; evaluator = MulticlassConfusionMatrixEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassConfusionMatrixEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [0, 0, 1, 1, 2, 2], \"target\": [0, 0, 1, 1, 2, 2]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassConfusionMatrixResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassFbetaScoreEvaluator","title":"arkas.evaluator.MulticlassFbetaScoreEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassFbetaScoreResult]</code></p> <p>Implement the F-beta evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassFbetaScoreEvaluator\n&gt;&gt;&gt; evaluator = MulticlassFbetaScoreEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassFbetaScoreEvaluator(y_true='target', y_pred='pred', betas=(1,), drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [0, 0, 1, 1, 2, 2], \"target\": [0, 0, 1, 1, 2, 2]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassFbetaScoreResult(y_true=(6,), y_pred=(6,), betas=(1,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassJaccardEvaluator","title":"arkas.evaluator.MulticlassJaccardEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassJaccardResult]</code></p> <p>Implement the Jaccard evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassJaccardEvaluator\n&gt;&gt;&gt; evaluator = MulticlassJaccardEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassJaccardEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [0, 0, 1, 1, 2, 2], \"target\": [0, 0, 1, 1, 2, 2]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassJaccardResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassPrecisionEvaluator","title":"arkas.evaluator.MulticlassPrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassPrecisionResult]</code></p> <p>Implement the precision evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassPrecisionEvaluator\n&gt;&gt;&gt; evaluator = MulticlassPrecisionEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassPrecisionEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [0, 0, 1, 1, 2, 2], \"target\": [0, 0, 1, 1, 2, 2]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassPrecisionResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassRecallEvaluator","title":"arkas.evaluator.MulticlassRecallEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassRecallResult]</code></p> <p>Implement the recall evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassRecallEvaluator\n&gt;&gt;&gt; evaluator = MulticlassRecallEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassRecallEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [0, 0, 1, 1, 2, 2], \"target\": [0, 0, 1, 1, 2, 2]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassRecallResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassRocAucEvaluator","title":"arkas.evaluator.MulticlassRocAucEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassRocAucResult]</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_score</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassRocAucEvaluator\n&gt;&gt;&gt; evaluator = MulticlassRocAucEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassRocAucEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.5, 0.3],\n...             [0.3, 0.3, 0.4],\n...             [0.1, 0.2, 0.7],\n...         ],\n...         \"target\": [0, 0, 1, 1, 2, 2],\n...     },\n...     schema={\"pred\": pl.Array(pl.Float64, 3), \"target\": pl.Int64},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassRocAucResult(y_true=(6,), y_score=(6, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelAveragePrecisionEvaluator","title":"arkas.evaluator.MultilabelAveragePrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelAveragePrecisionResult]</code></p> <p>Implement the average precision evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_score</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelAveragePrecisionEvaluator\n&gt;&gt;&gt; evaluator = MultilabelAveragePrecisionEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelAveragePrecisionEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[2, -1, 1], [-1, 1, -2], [0, 2, -3], [3, -2, 4], [1, -3, 5]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelAveragePrecisionResult(y_true=(5, 3), y_score=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelConfusionMatrixEvaluator","title":"arkas.evaluator.MultilabelConfusionMatrixEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelConfusionMatrixResult]</code></p> <p>Implement the confusion matrix evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelConfusionMatrixEvaluator\n&gt;&gt;&gt; evaluator = MultilabelConfusionMatrixEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelConfusionMatrixEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelConfusionMatrixResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelFbetaScoreEvaluator","title":"arkas.evaluator.MultilabelFbetaScoreEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelFbetaScoreResult]</code></p> <p>Implement the F-beta evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelFbetaScoreEvaluator\n&gt;&gt;&gt; evaluator = MultilabelFbetaScoreEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelFbetaScoreEvaluator(y_true='target', y_pred='pred', betas=(1,), drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelFbetaScoreResult(y_true=(5, 3), y_pred=(5, 3), betas=(1,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelJaccardEvaluator","title":"arkas.evaluator.MultilabelJaccardEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelJaccardResult]</code></p> <p>Implement the Jaccard evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelJaccardEvaluator\n&gt;&gt;&gt; evaluator = MultilabelJaccardEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelJaccardEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelJaccardResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelPrecisionEvaluator","title":"arkas.evaluator.MultilabelPrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelPrecisionResult]</code></p> <p>Implement the precision evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelPrecisionEvaluator\n&gt;&gt;&gt; evaluator = MultilabelPrecisionEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelPrecisionEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelPrecisionResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelRecallEvaluator","title":"arkas.evaluator.MultilabelRecallEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelRecallResult]</code></p> <p>Implement the recall evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelRecallEvaluator\n&gt;&gt;&gt; evaluator = MultilabelRecallEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelRecallEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelRecallResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelRocAucEvaluator","title":"arkas.evaluator.MultilabelRocAucEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelRocAucResult]</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_score</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelRocAucEvaluator\n&gt;&gt;&gt; evaluator = MultilabelRocAucEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelRocAucEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[2, -1, 1], [-1, 1, -2], [0, 2, -3], [3, -2, 4], [1, -3, 5]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelRocAucResult(y_true=(5, 3), y_score=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.PearsonCorrelationEvaluator","title":"arkas.evaluator.PearsonCorrelationEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[PearsonCorrelationResult]</code></p> <p>Implement the Pearson correlation evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import PearsonCorrelationEvaluator\n&gt;&gt;&gt; evaluator = PearsonCorrelationEvaluator(x=\"target\", y=\"pred\")\n&gt;&gt;&gt; evaluator\nPearsonCorrelationEvaluator(x='target', y='pred', alternative='two-sided', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nPearsonCorrelationResult(x=(5,), y=(5,), alternative='two-sided', nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.R2ScoreEvaluator","title":"arkas.evaluator.R2ScoreEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[R2ScoreResult]</code></p> <p>Implement the R^2 (coefficient of determination) regression score evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import R2ScoreEvaluator\n&gt;&gt;&gt; evaluator = R2ScoreEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nR2ScoreEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nR2ScoreResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.RootMeanSquaredErrorEvaluator","title":"arkas.evaluator.RootMeanSquaredErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[RootMeanSquaredErrorResult]</code></p> <p>Implement the root mean squared error (RMSE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import RootMeanSquaredErrorEvaluator\n&gt;&gt;&gt; evaluator = RootMeanSquaredErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nRootMeanSquaredErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nRootMeanSquaredErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.SequentialEvaluator","title":"arkas.evaluator.SequentialEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement an evaluator that sequentially evaluates several evaluators.</p> <p>Parameters:</p> Name Type Description Default <code>evaluators</code> <code>Sequence[BaseEvaluator | dict]</code> <p>The sequence of evaluators to evaluate.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import (\n...     SequentialEvaluator,\n...     BinaryPrecisionEvaluator,\n...     BinaryRecallEvaluator,\n... )\n&gt;&gt;&gt; evaluator = SequentialEvaluator(\n...     [\n...         BinaryPrecisionEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         BinaryRecallEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...     ]\n... )\n&gt;&gt;&gt; evaluator\nSequentialEvaluator(\n  (0): BinaryPrecisionEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n  (1): BinaryRecallEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n)\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nSequentialResult(count=2)\n&gt;&gt;&gt; result = evaluator.evaluate(data, lazy=False)\n&gt;&gt;&gt; result\nResult(metrics=3, figures=1)\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.SpearmanCorrelationEvaluator","title":"arkas.evaluator.SpearmanCorrelationEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[SpearmanCorrelationResult]</code></p> <p>Implement the Spearman correlation evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import SpearmanCorrelationEvaluator\n&gt;&gt;&gt; evaluator = SpearmanCorrelationEvaluator(x=\"target\", y=\"pred\")\n&gt;&gt;&gt; evaluator\nSpearmanCorrelationEvaluator(x='target', y='pred', alternative='two-sided', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nSpearmanCorrelationResult(x=(5,), y=(5,), alternative='two-sided', nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.WassersteinDistanceEvaluator","title":"arkas.evaluator.WassersteinDistanceEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[WassersteinDistanceResult]</code></p> <p>Implement the Wasserstein distance between two 1D distributions evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>v_values</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import WassersteinDistanceEvaluator\n&gt;&gt;&gt; evaluator = WassersteinDistanceEvaluator(u_values=\"target\", v_values=\"pred\")\n&gt;&gt;&gt; evaluator\nWassersteinDistanceEvaluator(u_values='target', v_values='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nWassersteinDistanceResult(u_values=(5,), v_values=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.is_evaluator_config","title":"arkas.evaluator.is_evaluator_config","text":"<pre><code>is_evaluator_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseEvaluator</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseEvaluator</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.evaluator import is_evaluator_config\n&gt;&gt;&gt; is_evaluator_config({\"_target_\": \"arkas.evaluator.AccuracyEvaluator\"})\nTrue\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.setup_evaluator","title":"arkas.evaluator.setup_evaluator","text":"<pre><code>setup_evaluator(\n    evaluator: BaseEvaluator | dict,\n) -&gt; BaseEvaluator\n</code></pre> <p>Set up an evaluator.</p> <p>The evaluator is instantiated from its configuration by using the <code>BaseEvaluator</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>BaseEvaluator | dict</code> <p>An evaluator or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseEvaluator</code> <p>An instantiated evaluator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.evaluator import setup_evaluator\n&gt;&gt;&gt; evaluator = setup_evaluator(\n...     {\n...         \"_target_\": \"arkas.evaluator.AccuracyEvaluator\",\n...         \"y_true\": \"target\",\n...         \"y_pred\": \"pred\",\n...     }\n... )\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator2/","title":"arkas.evaluator2","text":""},{"location":"refs/evaluator2/#arkas.evaluator2","title":"arkas.evaluator2","text":"<p>Contain data evaluators.</p>"},{"location":"refs/evaluator2/#arkas.evaluator2.AccuracyEvaluator","title":"arkas.evaluator2.AccuracyEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement the accuracy evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AccuracyState</code> <p>The state containing the ground truth and predicted labels.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import AccuracyEvaluator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n&gt;&gt;&gt; evaluator.evaluate()\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.BaseEvaluator","title":"arkas.evaluator2.BaseEvaluator","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement an evaluator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import AccuracyEvaluator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.BaseEvaluator.equal","title":"arkas.evaluator2.BaseEvaluator.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two evaluators are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other evaluator to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two evaluators are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import AccuracyEvaluator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; evaluator1 = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator2 = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator3 = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 0, 0]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator1.equal(evaluator2)\nTrue\n&gt;&gt;&gt; evaluator1.equal(evaluator3)\nFalse\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.BaseEvaluator.evaluate","title":"arkas.evaluator2.BaseEvaluator.evaluate  <code>abstractmethod</code>","text":"<pre><code>evaluate(prefix: str = '', suffix: str = '') -&gt; dict\n</code></pre> <p>Evaluate the metrics.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict</code> <p>The metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import AccuracyEvaluator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator.evaluate()\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.Evaluator","title":"arkas.evaluator2.Evaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement a simple evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>dict | None</code> <p>The dictionary of metrics.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import Evaluator\n&gt;&gt;&gt; evaluator = Evaluator({\"accuracy\": 1.0, \"total\": 42})\n&gt;&gt;&gt; evaluator\nEvaluator(count=2)\n&gt;&gt;&gt; evaluator.evaluate()\n{'accuracy': 1.0, 'total': 42}\n</code></pre>"},{"location":"refs/exporter/","title":"arkas.exporter","text":""},{"location":"refs/exporter/#arkas.exporter","title":"arkas.exporter","text":"<p>Contain output exporters.</p>"},{"location":"refs/exporter/#arkas.exporter.BaseExporter","title":"arkas.exporter.BaseExporter","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to export an output object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     exporter = MetricExporter(path=Path(tmpdir).joinpath(\"metrics.pkl\"))\n...     print(exporter)\n...     exporter.export(output)\n...\nMetricExporter(\n  (path): .../metrics.pkl\n  (saver): PickleSaver(protocol=5)\n  (exist_ok): False\n  (show_metrics): True\n)\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.BaseExporter.export","title":"arkas.exporter.BaseExporter.export  <code>abstractmethod</code>","text":"<pre><code>export(output: BaseOutput) -&gt; None\n</code></pre> <p>Export an output.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>BaseOutput</code> <p>The output object to export.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     exporter = MetricExporter(path=Path(tmpdir).joinpath(\"metrics.pkl\"))\n...     exporter.export(output)\n...\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.FigureExporter","title":"arkas.exporter.FigureExporter","text":"<p>               Bases: <code>BaseExporter</code></p> <p>Implement a simple figure exporter.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>The path where to save the figures.</p> required <code>saver</code> <code>BaseSaver | dict | None</code> <p>The figure saver or its configuration.</p> <code>None</code> <code>exist_ok</code> <code>bool</code> <p>If <code>exist_ok</code> is <code>False</code> (the default), an exception is raised if the path already exists.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import FigureExporter\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     exporter = FigureExporter(path=Path(tmpdir).joinpath(\"figures.pkl\"))\n...     exporter.export(output)\n...\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.MetricExporter","title":"arkas.exporter.MetricExporter","text":"<p>               Bases: <code>BaseExporter</code></p> <p>Implement a simple metric exporter.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>The path where to save the metrics.</p> required <code>saver</code> <code>BaseSaver | dict | None</code> <p>The metric saver or its configuration.</p> <code>None</code> <code>exist_ok</code> <code>bool</code> <p>If <code>exist_ok</code> is <code>False</code> (the default), an exception is raised if the path already exists.</p> <code>False</code> <code>show_metrics</code> <code>bool</code> <p>If <code>True</code>, the metrics are shown in the logging output.</p> <code>True</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     exporter = MetricExporter(path=Path(tmpdir).joinpath(\"metrics.pkl\"))\n...     exporter.export(output)\n...\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.ReportExporter","title":"arkas.exporter.ReportExporter","text":"<p>               Bases: <code>BaseExporter</code></p> <p>Implement a simple report exporter.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>The path where to save the reports.</p> required <code>saver</code> <code>BaseSaver | dict | None</code> <p>The report saver or its configuration.</p> <code>None</code> <code>exist_ok</code> <code>bool</code> <p>If <code>exist_ok</code> is <code>False</code> (the default), an exception is raised if the path already exists.</p> <code>False</code> <code>max_toc_depth</code> <code>int</code> <p>The maximum level to show in the table of content.</p> <code>6</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import ReportExporter\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     exporter = ReportExporter(path=Path(tmpdir).joinpath(\"report.html\"))\n...     exporter.export(output)\n...\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.SequentialExporter","title":"arkas.exporter.SequentialExporter","text":"<p>               Bases: <code>BaseExporter</code></p> <p>Implement an exporter that sequentially calls several exporters.</p> <p>Parameters:</p> Name Type Description Default <code>exporters</code> <code>Sequence[BaseExporter | dict]</code> <p>The sequence of exporters.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import (\n...     SequentialExporter,\n...     FigureExporter,\n...     MetricExporter,\n... )\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     path = Path(tmpdir)\n...     exporter = SequentialExporter(\n...         [\n...             MetricExporter(path.joinpath(\"metrics.pkl\")),\n...             FigureExporter(path.joinpath(\"figures.pkl\")),\n...         ]\n...     )\n...     print(exporter)\n...     exporter.export(output)\n...\nSequentialExporter(\n  (0): MetricExporter(\n      (path): .../metrics.pkl\n      (saver): PickleSaver(protocol=5)\n      (exist_ok): False\n      (show_metrics): True\n    )\n  (1): FigureExporter(\n      (path): .../figures.pkl\n      (saver): PickleSaver(protocol=5)\n      (exist_ok): False\n    )\n)\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.is_exporter_config","title":"arkas.exporter.is_exporter_config","text":"<pre><code>is_exporter_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseExporter</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseExporter</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.exporter import is_exporter_config\n&gt;&gt;&gt; is_exporter_config(\n...     {\n...         \"_target_\": \"arkas.exporter.MetricExporter\",\n...         \"path\": \"/path/to/data.csv\",\n...     }\n... )\nTrue\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.setup_exporter","title":"arkas.exporter.setup_exporter","text":"<pre><code>setup_exporter(\n    exporter: BaseExporter | dict,\n) -&gt; BaseExporter\n</code></pre> <p>Set up a exporter.</p> <p>The exporter is instantiated from its configuration by using the <code>BaseExporter</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>exporter</code> <code>BaseExporter | dict</code> <p>A exporter or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseExporter</code> <p>An instantiated exporter.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.exporter import setup_exporter\n&gt;&gt;&gt; exporter = setup_exporter(\n...     {\n...         \"_target_\": \"arkas.exporter.MetricExporter\",\n...         \"path\": \"/path/to/data.csv\",\n...     }\n... )\n&gt;&gt;&gt; exporter\nMetricExporter(\n  (path): /path/to/data.csv\n  (saver): PickleSaver(protocol=5)\n  (exist_ok): False\n  (show_metrics): True\n)\n</code></pre>"},{"location":"refs/hcg/","title":"arkas.hcg","text":""},{"location":"refs/hcg/#arkas.hcg","title":"arkas.hcg","text":"<p>Contain HTML Content Generators (HCGs).</p>"},{"location":"refs/hcg/#arkas.hcg.AccuracyContentGenerator","title":"arkas.hcg.AccuracyContentGenerator","text":"<p>               Bases: <code>BaseContentGenerator</code></p> <p>Implement a HTML content generator that analyzes accuracy performances.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AccuracyState</code> <p>The data structure containing the states.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.hcg import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator\nAccuracyContentGenerator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n</code></pre>"},{"location":"refs/hcg/#arkas.hcg.BaseContentGenerator","title":"arkas.hcg.BaseContentGenerator","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement a HTML Content Generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.hcg import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator\nAccuracyContentGenerator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n</code></pre>"},{"location":"refs/hcg/#arkas.hcg.BaseContentGenerator.equal","title":"arkas.hcg.BaseContentGenerator.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two content generators are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other content generator to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two content generators are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.hcg import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator1 = AccuracyContentGenerator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator2 = AccuracyContentGenerator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator3 = AccuracyContentGenerator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 0, 0]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator1.equal(generator2)\nTrue\n&gt;&gt;&gt; generator1.equal(generator3)\nFalse\n</code></pre>"},{"location":"refs/hcg/#arkas.hcg.BaseContentGenerator.generate_body","title":"arkas.hcg.BaseContentGenerator.generate_body  <code>abstractmethod</code>","text":"<pre><code>generate_body(\n    number: str = \"\",\n    tags: Sequence[str] = (),\n    depth: int = 0,\n) -&gt; str\n</code></pre> <p>Return the HTML body associated to the content.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>str</code> <p>The section number, if any.</p> <code>''</code> <code>tags</code> <code>Sequence[str]</code> <p>The tags associated to the content section, if any.</p> <code>()</code> <code>depth</code> <code>int</code> <p>The depth in the content section, if any.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p>The HTML body associated to the content section.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.hcg import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator.generate_body()\n</code></pre>"},{"location":"refs/hcg/#arkas.hcg.BaseContentGenerator.generate_toc","title":"arkas.hcg.BaseContentGenerator.generate_toc  <code>abstractmethod</code>","text":"<pre><code>generate_toc(\n    number: str = \"\",\n    tags: Sequence[str] = (),\n    depth: int = 0,\n    max_depth: int = 1,\n) -&gt; str\n</code></pre> <p>Return the HTML table of content (TOC) associated to the section.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>str</code> <p>The section number associated to the section, if any.</p> <code>''</code> <code>tags</code> <code>Sequence[str]</code> <p>The tags associated to the section, if any.</p> <code>()</code> <code>depth</code> <code>int</code> <p>The depth in the report, if any.</p> <code>0</code> <code>max_depth</code> <code>int</code> <p>The maximum depth to generate in the TOC.</p> <code>1</code> <p>Returns:</p> Type Description <code>str</code> <p>The HTML table of content associated to the section.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.hcg import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator.generate_toc()\n</code></pre>"},{"location":"refs/hcg/#arkas.hcg.ContentGenerator","title":"arkas.hcg.ContentGenerator","text":"<p>               Bases: <code>BaseContentGenerator</code></p> <p>Implement a section that analyze accuracy states.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The HTML content.</p> <code>''</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.hcg import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator\nAccuracyContentGenerator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n</code></pre>"},{"location":"refs/metric/","title":"arkas.metric","text":""},{"location":"refs/metric/#arkas.metric","title":"arkas.metric","text":"<p>Contain functions to compute metrics.</p>"},{"location":"refs/metric/#arkas.metric.accuracy","title":"arkas.metric.accuracy","text":"<pre><code>accuracy(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the accuracy metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import accuracy\n&gt;&gt;&gt; accuracy(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.average_precision","title":"arkas.metric.average_precision","text":"<pre><code>average_precision(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the average precision metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import average_precision\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; metrics = average_precision(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1])\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': 1.0, 'count': 5}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; metrics = average_precision(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_score=np.array([2, -1, 0, 3, 1]),\n...     label_type=\"binary\",\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': 1.0, 'count': 5}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; metrics = average_precision(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.3, 0.5],\n...             [0.4, 0.4, 0.2],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n...     label_type=\"multiclass\",\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': array([0.833..., 0.75 , 0.75 ]),\n 'count': 6,\n 'macro_average_precision': 0.777...,\n 'micro_average_precision': 0.75,\n 'weighted_average_precision': 0.777...}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; metrics = average_precision(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, -1], [-1, 1, 2], [0, 2, 3], [3, -2, -4], [1, -3, -5]]),\n...     label_type=\"multilabel\",\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': array([1. , 1. , 0.477...]),\n 'count': 5,\n 'macro_average_precision': 0.825...,\n 'micro_average_precision': 0.588...,\n 'weighted_average_precision': 0.804...}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.balanced_accuracy","title":"arkas.metric.balanced_accuracy","text":"<pre><code>balanced_accuracy(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the accuracy metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import balanced_accuracy\n&gt;&gt;&gt; balanced_accuracy(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'balanced_accuracy': 1.0, 'count': 5}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_average_precision","title":"arkas.metric.binary_average_precision","text":"<pre><code>binary_average_precision(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the average precision metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_average_precision\n&gt;&gt;&gt; metrics = binary_average_precision(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1])\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': 1.0, 'count': 5}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_confusion_matrix","title":"arkas.metric.binary_confusion_matrix","text":"<pre><code>binary_confusion_matrix(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the confusion matrix metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_confusion_matrix\n&gt;&gt;&gt; binary_confusion_matrix(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n{'confusion_matrix': array([[2, 0], [0, 3]]),\n 'count': 5,\n 'false_negative_rate': 0.0,\n 'false_negative': 0,\n 'false_positive_rate': 0.0,\n 'false_positive': 0,\n 'true_negative_rate': 1.0,\n 'true_negative': 2,\n 'true_positive_rate': 1.0,\n 'true_positive': 3}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_fbeta_score","title":"arkas.metric.binary_fbeta_score","text":"<pre><code>binary_fbeta_score(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    betas: Sequence[float] = (1,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the F-beta metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_fbeta_score\n&gt;&gt;&gt; binary_fbeta_score(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n... )\n{'count': 5, 'f1': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_jaccard","title":"arkas.metric.binary_jaccard","text":"<pre><code>binary_jaccard(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Jaccard metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_jaccard\n&gt;&gt;&gt; binary_jaccard(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'jaccard': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_precision","title":"arkas.metric.binary_precision","text":"<pre><code>binary_precision(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the precision metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_precision\n&gt;&gt;&gt; binary_precision(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'precision': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_recall","title":"arkas.metric.binary_recall","text":"<pre><code>binary_recall(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the recall metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_recall\n&gt;&gt;&gt; binary_recall(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'recall': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_roc_auc","title":"arkas.metric.binary_roc_auc","text":"<pre><code>binary_roc_auc(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Area Under the Receiver Operating Characteristic Curve (ROC AUC) metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p>"},{"location":"refs/metric/#arkas.metric.binary_top_k_accuracy","title":"arkas.metric.binary_top_k_accuracy","text":"<pre><code>binary_top_k_accuracy(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    k: Sequence[int] = (2,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Area Under the Top-k Accuracy classification metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>k</code> <code>Sequence[int]</code> <p>The numbers of most likely outcomes considered to find the correct label.</p> <code>(2,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p>"},{"location":"refs/metric/#arkas.metric.confusion_matrix","title":"arkas.metric.confusion_matrix","text":"<pre><code>confusion_matrix(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the confusion matrix metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import confusion_matrix\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; confusion_matrix(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n{'confusion_matrix': array([[2, 0], [0, 3]]),\n 'count': 5,\n 'false_negative_rate': 0.0,\n 'false_negative': 0,\n 'false_positive_rate': 0.0,\n 'false_positive': 0,\n 'true_negative_rate': 1.0,\n 'true_negative': 2,\n 'true_positive_rate': 1.0,\n 'true_positive': 3}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; confusion_matrix(\n...     y_true=np.array([0, 1, 1, 2, 2, 2]),\n...     y_pred=np.array([0, 1, 1, 2, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n{'confusion_matrix': array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]), 'count': 6}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; confusion_matrix(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     label_type=\"multilabel\",\n... )\n{'confusion_matrix': array([[[2, 0], [0, 3]],\n                            [[3, 0], [0, 2]],\n                            [[2, 0], [0, 3]]]),\n 'count': 5}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.energy_distance","title":"arkas.metric.energy_distance","text":"<pre><code>energy_distance(\n    u_values: ndarray,\n    v_values: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the energy distance between two 1D distributions.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>v_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import energy_distance\n&gt;&gt;&gt; energy_distance(u_values=np.array([1, 2, 3, 4, 5]), v_values=np.array([1, 2, 3, 4, 5]))\n{'count': 5, 'energy_distance': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.fbeta_score","title":"arkas.metric.fbeta_score","text":"<pre><code>fbeta_score(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    betas: Sequence[float] = (1,),\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the F-beta metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import fbeta_score\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; fbeta_score(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'f1': 1.0}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; fbeta_score(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n{'count': 5, 'f1': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; fbeta_score(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n{'count': 6,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; fbeta_score(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     label_type=\"multilabel\",\n... )\n{'count': 5,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.jaccard","title":"arkas.metric.jaccard","text":"<pre><code>jaccard(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Jaccard metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import jaccard\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; jaccard(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'jaccard': 1.0}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; jaccard(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n{'count': 5, 'jaccard': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; jaccard(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n{'count': 6,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; jaccard(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     label_type=\"multilabel\",\n... )\n{'count': 5,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.jensen_shannon_divergence","title":"arkas.metric.jensen_shannon_divergence","text":"<pre><code>jensen_shannon_divergence(\n    p: ndarray,\n    q: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Jensen-Shannon (JS) divergence between two distributions.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>ndarray</code> <p>The true probability distribution.</p> required <code>q</code> <code>ndarray</code> <p>The model probability distribution.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import jensen_shannon_divergence\n&gt;&gt;&gt; jensen_shannon_divergence(\n...     p=np.array([0.1, 0.6, 0.1, 0.2]), q=np.array([0.2, 0.5, 0.2, 0.1])\n... )\n{'size': 4, 'jensen_shannon_divergence': 0.027...}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.kl_div","title":"arkas.metric.kl_div","text":"<pre><code>kl_div(\n    p: ndarray,\n    q: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Kullback-Leibler (KL) divergence between two distributions.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>ndarray</code> <p>The true probability distribution.</p> required <code>q</code> <code>ndarray</code> <p>The model probability distribution.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import kl_div\n&gt;&gt;&gt; kl_div(p=np.array([0.1, 0.6, 0.1, 0.2]), q=np.array([0.2, 0.5, 0.2, 0.1]))\n{'size': 4, 'kl_pq': 0.109..., 'kl_qp': 0.116...}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.mean_absolute_error","title":"arkas.metric.mean_absolute_error","text":"<pre><code>mean_absolute_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the mean absolute error (MAE).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import mean_absolute_error\n&gt;&gt;&gt; mean_absolute_error(y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5]))\n{'count': 5, 'mean_absolute_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.mean_absolute_percentage_error","title":"arkas.metric.mean_absolute_percentage_error","text":"<pre><code>mean_absolute_percentage_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the mean absolute percentage error (MAPE).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import mean_absolute_percentage_error\n&gt;&gt;&gt; mean_absolute_percentage_error(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'mean_absolute_percentage_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.mean_squared_error","title":"arkas.metric.mean_squared_error","text":"<pre><code>mean_squared_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the mean squared error (MSE).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import mean_squared_error\n&gt;&gt;&gt; mean_squared_error(y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5]))\n{'count': 5, 'mean_squared_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.mean_squared_log_error","title":"arkas.metric.mean_squared_log_error","text":"<pre><code>mean_squared_log_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the mean squared logarithmic error (MSLE).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import mean_squared_log_error\n&gt;&gt;&gt; mean_squared_log_error(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'mean_squared_log_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.mean_tweedie_deviance","title":"arkas.metric.mean_tweedie_deviance","text":"<pre><code>mean_tweedie_deviance(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    powers: Sequence[float] = (0,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the mean Tweedie deviance regression loss.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>powers</code> <code>Sequence[float]</code> <p>The Tweedie power parameter. The higher power the less weight is given to extreme deviations between true and predicted targets.</p> <code>(0,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import mean_tweedie_deviance\n&gt;&gt;&gt; mean_tweedie_deviance(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'mean_tweedie_deviance_power_0': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.median_absolute_error","title":"arkas.metric.median_absolute_error","text":"<pre><code>median_absolute_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the median absolute error.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import median_absolute_error\n&gt;&gt;&gt; median_absolute_error(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'median_absolute_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_average_precision","title":"arkas.metric.multiclass_average_precision","text":"<pre><code>multiclass_average_precision(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the average precision metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_average_precision\n&gt;&gt;&gt; metrics = multiclass_average_precision(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.3, 0.5],\n...             [0.4, 0.4, 0.2],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': array([0.833..., 0.75 , 0.75 ]),\n 'count': 6,\n 'macro_average_precision': 0.777...,\n 'micro_average_precision': 0.75,\n 'weighted_average_precision': 0.777...}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_confusion_matrix","title":"arkas.metric.multiclass_confusion_matrix","text":"<pre><code>multiclass_confusion_matrix(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the confusion matrix metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_confusion_matrix\n&gt;&gt;&gt; multiclass_confusion_matrix(\n...     y_true=np.array([0, 1, 1, 2, 2, 2]), y_pred=np.array([0, 1, 1, 2, 2, 2])\n... )\n{'confusion_matrix': array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]), 'count': 6}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_fbeta_score","title":"arkas.metric.multiclass_fbeta_score","text":"<pre><code>multiclass_fbeta_score(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    betas: Sequence[float] = (1,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the F-beta metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_fbeta_score\n&gt;&gt;&gt; multiclass_fbeta_score(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n... )\n{'count': 6,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_jaccard","title":"arkas.metric.multiclass_jaccard","text":"<pre><code>multiclass_jaccard(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Jaccard metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_jaccard\n&gt;&gt;&gt; multiclass_jaccard(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]), y_pred=np.array([0, 0, 1, 1, 2, 2])\n... )\n{'count': 6,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_precision","title":"arkas.metric.multiclass_precision","text":"<pre><code>multiclass_precision(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the precision metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_precision\n&gt;&gt;&gt; multiclass_precision(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]), y_pred=np.array([0, 0, 1, 1, 2, 2])\n... )\n{'count': 6,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_recall","title":"arkas.metric.multiclass_recall","text":"<pre><code>multiclass_recall(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the recall metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_recall\n&gt;&gt;&gt; multiclass_recall(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]), y_pred=np.array([0, 0, 1, 1, 2, 2])\n... )\n{'count': 6,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_roc_auc","title":"arkas.metric.multiclass_roc_auc","text":"<pre><code>multiclass_roc_auc(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Area Under the Receiver Operating Characteristic Curve (ROC AUC) metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p>"},{"location":"refs/metric/#arkas.metric.multiclass_top_k_accuracy","title":"arkas.metric.multiclass_top_k_accuracy","text":"<pre><code>multiclass_top_k_accuracy(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    k: Sequence[int] = (2,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Area Under the Top-k Accuracy classification metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>k</code> <code>Sequence[int]</code> <p>The numbers of most likely outcomes considered to find the correct label.</p> <code>(2,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p>"},{"location":"refs/metric/#arkas.metric.multilabel_average_precision","title":"arkas.metric.multilabel_average_precision","text":"<pre><code>multilabel_average_precision(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the average precision metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_average_precision\n&gt;&gt;&gt; metrics = multilabel_average_precision(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, -1], [-1, 1, 2], [0, 2, 3], [3, -2, -4], [1, -3, -5]]),\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': array([1. , 1. , 0.477...]),\n 'count': 5,\n 'macro_average_precision': 0.825...,\n 'micro_average_precision': 0.588...,\n 'weighted_average_precision': 0.804...}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_confusion_matrix","title":"arkas.metric.multilabel_confusion_matrix","text":"<pre><code>multilabel_confusion_matrix(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the confusion matrix metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_confusion_matrix\n&gt;&gt;&gt; multilabel_confusion_matrix(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n{'confusion_matrix': array([[[2, 0], [0, 3]],\n                            [[3, 0], [0, 2]],\n                            [[2, 0], [0, 3]]]),\n 'count': 5}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_fbeta_score","title":"arkas.metric.multilabel_fbeta_score","text":"<pre><code>multilabel_fbeta_score(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    betas: Sequence[float] = (1,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the F-beta metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_fbeta_score\n&gt;&gt;&gt; multilabel_fbeta_score(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n{'count': 5,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_jaccard","title":"arkas.metric.multilabel_jaccard","text":"<pre><code>multilabel_jaccard(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Jaccard metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_jaccard\n&gt;&gt;&gt; multilabel_jaccard(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n{'count': 5,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_precision","title":"arkas.metric.multilabel_precision","text":"<pre><code>multilabel_precision(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the precision metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_precision\n&gt;&gt;&gt; multilabel_precision(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n{'count': 5,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_recall","title":"arkas.metric.multilabel_recall","text":"<pre><code>multilabel_recall(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the recall metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_recall\n&gt;&gt;&gt; multilabel_recall(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n{'count': 5,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_roc_auc","title":"arkas.metric.multilabel_roc_auc","text":"<pre><code>multilabel_roc_auc(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Area Under the Receiver Operating Characteristic Curve (ROC AUC) metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p>"},{"location":"refs/metric/#arkas.metric.ndcg","title":"arkas.metric.ndcg","text":"<pre><code>ndcg(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    k: int | None = None,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Normalized Discounted Cumulative Gain (NDCG) metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target targets of multilabel classification, or true scores of entities to be ranked. Negative values in y_true may result in an output that is not between 0 and 1. This input must be an array of shape <code>(n_samples, n_labels)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The predicted scores, can either be probability estimates, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_labels)</code>.</p> required <code>k</code> <code>int | None</code> <p>Only consider the highest <code>k</code> scores in the ranking. If <code>None</code>, use all outputs.</p> <code>None</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import ndcg\n&gt;&gt;&gt; ndcg(\n...     y_true=np.array([[1, 0, 0], [1, 2, 0], [1, 1, 2], [0, 0, 1]]),\n...     y_score=np.array(\n...         [[2.0, 1.0, 0.0], [0.0, 1.0, -1.0], [0.0, 0.0, 1.0], [1.0, 2.0, 3.0]]\n...     ),\n... )\n{'count': 4, 'ndcg': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.pearsonr","title":"arkas.metric.pearsonr","text":"<pre><code>pearsonr(\n    x: ndarray,\n    y: ndarray,\n    *,\n    alternative: str = \"two-sided\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Pearson correlation coefficient and p-value for testing non-correlation.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The first input array.</p> required <code>y</code> <code>ndarray</code> <p>The second input array.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import pearsonr\n&gt;&gt;&gt; pearsonr(x=np.array([1, 2, 3, 4, 5]), y=np.array([1, 2, 3, 4, 5]))\n{'count': 5, 'pearson_coeff': 1.0, 'pearson_pvalue': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.precision","title":"arkas.metric.precision","text":"<pre><code>precision(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the precision metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import precision\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; precision(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'precision': 1.0}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; precision(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n{'count': 5, 'precision': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; precision(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n{'count': 6,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; precision(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     label_type=\"multilabel\",\n... )\n{'count': 5,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.r2_score","title":"arkas.metric.r2_score","text":"<pre><code>r2_score(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the R^2 (coefficient of determination) regression score metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import r2_score\n&gt;&gt;&gt; r2_score(y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5]))\n{'count': 5, 'r2_score': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.recall","title":"arkas.metric.recall","text":"<pre><code>recall(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the recall metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import recall\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; recall(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'recall': 1.0}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; recall(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n{'count': 5, 'recall': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; recall(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n{'count': 6,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; recall(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     label_type=\"multilabel\",\n... )\n{'count': 5,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.regression_errors","title":"arkas.metric.regression_errors","text":"<pre><code>regression_errors(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the regression error metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import regression_errors\n&gt;&gt;&gt; regression_errors(y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5]))\n{'count': 5,\n 'mean_absolute_error': 0.0,\n 'median_absolute_error': 0.0,\n 'mean_squared_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.roc_auc","title":"arkas.metric.roc_auc","text":"<pre><code>roc_auc(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Area Under the Receiver Operating Characteristic Curve (ROC AUC) metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import roc_auc\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; metrics = roc_auc(y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1]))\n&gt;&gt;&gt; metrics\n{'count': 5, 'roc_auc': 1.0}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; metrics = roc_auc(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_score=np.array([2, -1, 0, 3, 1]),\n...     label_type=\"binary\",\n... )\n&gt;&gt;&gt; metrics\n{'count': 5, 'roc_auc': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; metrics = roc_auc(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.3, 0.5],\n...             [0.4, 0.4, 0.2],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n...     label_type=\"multiclass\",\n... )\n&gt;&gt;&gt; metrics\n{'count': 6,\n 'macro_roc_auc': 0.833...,\n 'micro_roc_auc': 0.826...,\n 'roc_auc': array([0.9375, 0.8125, 0.75  ]),\n 'weighted_roc_auc': 0.833...}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; metrics = roc_auc(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, -1], [-1, 1, 2], [0, 2, 3], [3, -2, -4], [1, -3, -5]]),\n...     label_type=\"multilabel\",\n... )\n&gt;&gt;&gt; metrics\n{'count': 5,\n 'macro_roc_auc': 0.666...,\n 'micro_roc_auc': 0.544...,\n 'roc_auc': array([1., 1., 0.]),\n 'weighted_roc_auc': 0.625}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.root_mean_squared_error","title":"arkas.metric.root_mean_squared_error","text":"<pre><code>root_mean_squared_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the root mean squared error (RMSE).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import root_mean_squared_error\n&gt;&gt;&gt; root_mean_squared_error(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'root_mean_squared_error': 0.0}\n</code></pre> Note <p>Require <code>sklearn&gt;=1.4.0</code></p>"},{"location":"refs/metric/#arkas.metric.spearmanr","title":"arkas.metric.spearmanr","text":"<pre><code>spearmanr(\n    x: ndarray,\n    y: ndarray,\n    *,\n    alternative: str = \"two-sided\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Spearman correlation coefficient and p-value for testing non-correlation.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The first input array.</p> required <code>y</code> <code>ndarray</code> <p>The second input array.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import spearmanr\n&gt;&gt;&gt; spearmanr(\n...     x=np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n...     y=np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n... )\n{'count': 9, 'spearman_coeff': 1.0, 'spearman_pvalue': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.top_k_accuracy","title":"arkas.metric.top_k_accuracy","text":"<pre><code>top_k_accuracy(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    k: Sequence[int] = (2,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Area Under the Top-k Accuracy classification metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. The binary case expects scores with shape <code>(n_samples,)</code> while the multiclass case expects scores with shape <code>(n_samples, n_classes)</code>.</p> required <code>k</code> <code>Sequence[int]</code> <p>The numbers of most likely outcomes considered to find the correct label.</p> <code>(2,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import top_k_accuracy\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; metrics = top_k_accuracy(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1]), k=[1, 2]\n... )\n&gt;&gt;&gt; metrics\n{'count': 5, 'top_1_accuracy': 1.0, 'top_2_accuracy': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; metrics = top_k_accuracy(\n...     y_true=np.array([0, 1, 2, 2]),\n...     y_score=np.array(\n...         [[0.5, 0.2, 0.2], [0.3, 0.4, 0.2], [0.2, 0.4, 0.3], [0.7, 0.2, 0.1]]\n...     ),\n...     k=[1, 2, 3],\n... )\n&gt;&gt;&gt; metrics\n{'count': 4, 'top_1_accuracy': 0.5, 'top_2_accuracy': 0.75, 'top_3_accuracy': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.wasserstein_distance","title":"arkas.metric.wasserstein_distance","text":"<pre><code>wasserstein_distance(\n    u_values: ndarray,\n    v_values: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Wasserstein distance between two 1D discrete distributions.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>ndarray</code> <p>An array that contains a sample from a probability distribution or the support (set of all possible values) of a probability distribution. Each element is an observation or possible value.</p> required <code>v_values</code> <code>ndarray</code> <p>An array that contains a sample from or the support of a second distribution.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import wasserstein_distance\n&gt;&gt;&gt; wasserstein_distance(\n...     u_values=np.array([1, 2, 3, 4, 5]), v_values=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'wasserstein_distance': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils","title":"arkas.metric.utils","text":"<p>Contain utility functions to compute metrics.</p>"},{"location":"refs/metric/#arkas.metric.utils.check_array_ndim","title":"arkas.metric.utils.check_array_ndim","text":"<pre><code>check_array_ndim(arr: ndarray, ndim: int) -&gt; None\n</code></pre> <p>Check if the number of array dimensions is matching the target number of dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>The array to check.</p> required <code>ndim</code> <code>int</code> <p>The targeted number of array dimensions.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the number of array dimensions does not match.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import check_array_ndim\n&gt;&gt;&gt; check_array_ndim(np.ones((2, 3)), ndim=2)\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_label_type","title":"arkas.metric.utils.check_label_type","text":"<pre><code>check_label_type(label_type: str) -&gt; None\n</code></pre> <p>Check if the label type value is valid or not.</p> <p>Parameters:</p> Name Type Description Default <code>label_type</code> <code>str</code> <p>The type of labels. The valid values are <code>'binary'</code>, <code>'multiclass'</code>, <code>'multilabel'</code>, and <code>'auto'</code>.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if an invalid value is passed to <code>label_type</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.metric.utils import check_label_type\n&gt;&gt;&gt; check_label_type(label_type=\"binary\")\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_nan_policy","title":"arkas.metric.utils.check_nan_policy","text":"<pre><code>check_nan_policy(nan_policy: str) -&gt; None\n</code></pre> <p>Check the NaN policy.</p> <p>Parameters:</p> Name Type Description Default <code>nan_policy</code> <code>str</code> <p>The NaN policy.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>nan_policy</code> is not <code>'omit'</code>, <code>'propagate'</code>, or <code>'raise'</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.metric.utils import check_nan_policy\n&gt;&gt;&gt; check_nan_policy(nan_policy=\"omit\")\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_nan_pred","title":"arkas.metric.utils.check_nan_pred","text":"<pre><code>check_nan_pred(y_true: ndarray, y_pred: ndarray) -&gt; None\n</code></pre> <p>Check if any array elements in <code>y_true</code> or <code>y_pred</code> arrays is a NaN value.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p><code>'y_true'</code> or <code>'y_pred'</code> has a NaN value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import check_nan_pred\n&gt;&gt;&gt; y_true = np.array([1, 0, 0, 1])\n&gt;&gt;&gt; y_pred = np.array([0, 1, 0, 1])\n&gt;&gt;&gt; check_nan_pred(y_true, y_pred)\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_same_shape","title":"arkas.metric.utils.check_same_shape","text":"<pre><code>check_same_shape(arrays: Iterable[ndarray]) -&gt; None\n</code></pre> <p>Check if arrays have the same shape.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[ndarray]</code> <p>The arrays to check.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the arrays have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import check_same_shape\n&gt;&gt;&gt; check_same_shape([np.array([1, 0, 0, 1]), np.array([0, 1, 0, 1])])\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_same_shape_pred","title":"arkas.metric.utils.check_same_shape_pred","text":"<pre><code>check_same_shape_pred(\n    y_true: ndarray, y_pred: ndarray\n) -&gt; None\n</code></pre> <p>Check if <code>y_true</code> and <code>y_pred</code> arrays have the same shape.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p><code>'y_true'</code> and <code>'y_pred'</code> have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import check_same_shape_pred\n&gt;&gt;&gt; y_true = np.array([1, 0, 0, 1])\n&gt;&gt;&gt; y_pred = np.array([0, 1, 0, 1])\n&gt;&gt;&gt; check_same_shape_pred(y_true, y_pred)\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_same_shape_score","title":"arkas.metric.utils.check_same_shape_score","text":"<pre><code>check_same_shape_score(\n    y_true: ndarray, y_score: ndarray\n) -&gt; None\n</code></pre> <p>Check if <code>y_true</code> and <code>y_score</code> arrays have the same shape.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p><code>'y_true'</code> and <code>'y_score'</code> have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import check_same_shape_score\n&gt;&gt;&gt; y_true = np.array([1, 0, 0, 1])\n&gt;&gt;&gt; y_score = np.array([0, 1, 0, 1])\n&gt;&gt;&gt; check_same_shape_score(y_true, y_score)\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.contains_nan","title":"arkas.metric.utils.contains_nan","text":"<pre><code>contains_nan(\n    arr: ndarray,\n    nan_policy: str = \"propagate\",\n    name: str = \"input array\",\n) -&gt; bool\n</code></pre> <p>Indicate if the given array contains at least one NaN value.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>The array to check.</p> required <code>nan_policy</code> <code>str</code> <p>The NaN policy. The valid values are <code>'omit'</code>, <code>'propagate'</code>, or <code>'raise'</code>.</p> <code>'propagate'</code> <code>name</code> <code>str</code> <p>An optional name to be more precise about the array when the exception is raised.</p> <code>'input array'</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the array contains at least one NaN value.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the array contains at least one NaN value and <code>nan_policy</code> is <code>'raise'</code>.</p>"},{"location":"refs/metric/#arkas.metric.utils.multi_isnan","title":"arkas.metric.utils.multi_isnan","text":"<pre><code>multi_isnan(arrays: Sequence[ndarray]) -&gt; ndarray\n</code></pre> <p>Test element-wise for NaN for all input arrays and return result as a boolean array.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Sequence[ndarray]</code> <p>The input arrays to test. All the arrays must have the same shape.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A boolean array. <code>True</code> where any array is NaN, <code>False</code> otherwise.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import multi_isnan\n&gt;&gt;&gt; mask = multi_isnan(\n...     [np.array([1, 0, 0, 1, float(\"nan\")]), np.array([1, float(\"nan\"), 0, 1, 1])]\n... )\n&gt;&gt;&gt; mask\narray([False,  True, False, False,  True])\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_pred","title":"arkas.metric.utils.preprocess_pred","text":"<pre><code>preprocess_pred(\n    y_true: ndarray, y_pred: ndarray, drop_nan: bool = False\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Preprocess <code>y_true</code> and <code>y_pred</code> arrays.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_pred</code> arrays.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if an invalid value is passed to <code>nan</code>.</p> <code>RuntimeError</code> <p><code>'y_true'</code> and <code>'y_pred'</code> have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_pred\n&gt;&gt;&gt; y_true = np.array([1, 0, 0, 1, 1, float(\"nan\")])\n&gt;&gt;&gt; y_pred = np.array([0, 1, 0, 1, float(\"nan\"), 1])\n&gt;&gt;&gt; preprocess_pred(y_true, y_pred)\n(array([ 1.,  0.,  0.,  1.,  1., nan]), array([ 0.,  1.,  0.,  1., nan,  1.]))\n&gt;&gt;&gt; preprocess_pred(y_true, y_pred, drop_nan=True)\n(array([1., 0., 0., 1.]), array([0., 1., 0., 1.]))\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_pred_multilabel","title":"arkas.metric.utils.preprocess_pred_multilabel","text":"<pre><code>preprocess_pred_multilabel(\n    y_true: ndarray, y_pred: ndarray, drop_nan: bool = False\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Preprocess <code>y_true</code> and <code>y_pred</code> arrays.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_pred</code> arrays.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if an invalid value is passed to <code>nan</code>.</p> <code>RuntimeError</code> <p><code>'y_true'</code> and <code>'y_pred'</code> have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_pred_multilabel\n&gt;&gt;&gt; y_true = np.array([[1, float(\"nan\"), 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]])\n&gt;&gt;&gt; y_pred = np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, float(\"nan\")]])\n&gt;&gt;&gt; preprocess_pred_multilabel(y_true, y_pred)\n(array([[ 1., nan,  1.],\n        [ 0.,  1.,  0.],\n        [ 0.,  1.,  0.],\n        [ 1.,  0.,  1.],\n        [ 1.,  0.,  1.]]),\n array([[ 1.,  0.,  1.],\n        [ 0.,  1.,  0.],\n        [ 0.,  1.,  0.],\n        [ 1.,  0.,  1.],\n        [ 1.,  0., nan]]))\n&gt;&gt;&gt; preprocess_pred_multilabel(y_true, y_pred, drop_nan=True)\n(array([[0., 1., 0.],\n        [0., 1., 0.],\n        [1., 0., 1.]]),\n array([[0., 1., 0.],\n        [0., 1., 0.],\n        [1., 0., 1.]]))\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_same_shape_arrays","title":"arkas.metric.utils.preprocess_same_shape_arrays","text":"<pre><code>preprocess_same_shape_arrays(\n    arrays: Sequence[ndarray], drop_nan: bool = False\n) -&gt; tuple[ndarray, ...]\n</code></pre> <p>Preprocess a sequence of same shape arrays.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Sequence[ndarray]</code> <p>The arrays to preprocess.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ...]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_pred</code> arrays.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the arrays have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_same_shape_arrays\n&gt;&gt;&gt; arrays = [\n...     np.array([1, 0, 0, 1, 1, float(\"nan\")]),\n...     np.array([0, 1, 0, 1, float(\"nan\"), 1]),\n... ]\n&gt;&gt;&gt; preprocess_same_shape_arrays(arrays)\n(array([ 1.,  0.,  0.,  1.,  1., nan]), array([ 0.,  1.,  0.,  1., nan,  1.]))\n&gt;&gt;&gt; preprocess_same_shape_arrays(arrays, drop_nan=True)\n(array([1., 0., 0., 1.]), array([0., 1., 0., 1.]))\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_score_binary","title":"arkas.metric.utils.preprocess_score_binary","text":"<pre><code>preprocess_score_binary(\n    y_true: ndarray,\n    y_score: ndarray,\n    drop_nan: bool = False,\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Preprocess <code>y_true</code> and <code>y_score</code> arrays for the binary classification case.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_score</code> arrays.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_score_binary\n&gt;&gt;&gt; y_true = np.array([1, 0, 0, 1, 1, float(\"nan\")])\n&gt;&gt;&gt; y_score = np.array([0, 1, 0, 1, float(\"nan\"), 1])\n&gt;&gt;&gt; preprocess_score_binary(y_true, y_score)\n(array([ 1.,  0.,  0.,  1.,  1., nan]), array([ 0.,  1.,  0.,  1., nan,  1.]))\n&gt;&gt;&gt; preprocess_score_binary(y_true, y_score, drop_nan=True)\n(array([1., 0., 0., 1.]), array([0., 1., 0., 1.]))\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_score_multiclass","title":"arkas.metric.utils.preprocess_score_multiclass","text":"<pre><code>preprocess_score_multiclass(\n    y_true: ndarray,\n    y_score: ndarray,\n    drop_nan: bool = False,\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Preprocess <code>y_true</code> and <code>y_score</code> arrays for the multiclass classification case.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, 1)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_score</code> arrays.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_score_multiclass\n&gt;&gt;&gt; y_true = np.array([0, 0, 1, 1, 2, float(\"nan\")])\n&gt;&gt;&gt; y_score = np.array(\n...     [\n...         [0.7, 0.2, 0.1],\n...         [0.4, 0.3, 0.3],\n...         [0.1, 0.8, float(\"nan\")],\n...         [0.2, 0.3, 0.5],\n...         [0.4, 0.4, 0.2],\n...         [0.1, 0.2, 0.7],\n...     ]\n... )\n&gt;&gt;&gt; preprocess_score_multiclass(y_true, y_score)\n(array([ 0.,  0.,  1.,  1.,  2., nan]),\n array([[0.7, 0.2, 0.1],\n        [0.4, 0.3, 0.3],\n        [0.1, 0.8, nan],\n        [0.2, 0.3, 0.5],\n        [0.4, 0.4, 0.2],\n        [0.1, 0.2, 0.7]]))\n&gt;&gt;&gt; preprocess_score_multiclass(y_true, y_score, drop_nan=True)\n(array([0., 0., 1., 2.]),\n array([[0.7, 0.2, 0.1],\n        [0.4, 0.3, 0.3],\n        [0.2, 0.3, 0.5],\n        [0.4, 0.4, 0.2]]))\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_score_multilabel","title":"arkas.metric.utils.preprocess_score_multilabel","text":"<pre><code>preprocess_score_multilabel(\n    y_true: ndarray,\n    y_score: ndarray,\n    drop_nan: bool = False,\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Preprocess <code>y_true</code> and <code>y_score</code> arrays for the multilabel classification case.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> or <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> or <code>(n_samples,)</code>.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_score</code> arrays.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_score_multilabel\n&gt;&gt;&gt; y_true = np.array([[1, float(\"nan\"), 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]])\n&gt;&gt;&gt; y_score = np.array(\n...     [[2, -1, -1], [-1, 1, 2], [0, 2, 3], [3, -2, -4], [1, float(\"nan\"), -5]]\n... )\n&gt;&gt;&gt; preprocess_score_multilabel(y_true, y_score)\n(array([[ 1., nan,  1.],\n        [ 0.,  1.,  0.],\n        [ 0.,  1.,  0.],\n        [ 1.,  0.,  1.],\n        [ 1.,  0.,  1.]]),\n array([[ 2., -1., -1.],\n        [-1.,  1.,  2.],\n        [ 0.,  2.,  3.],\n        [ 3., -2., -4.],\n        [ 1., nan, -5.]]))\n&gt;&gt;&gt; preprocess_score_multilabel(y_true, y_score, drop_nan=True)\n(array([[0., 1., 0.],\n        [0., 1., 0.],\n        [1., 0., 1.]]),\n array([[-1.,  1.,  2.],\n        [ 0.,  2.,  3.],\n        [ 3., -2., -4.]]))\n</code></pre>"},{"location":"refs/output/","title":"arkas.output","text":""},{"location":"refs/output/#arkas.output","title":"arkas.output","text":"<p>Contain data outputs.</p>"},{"location":"refs/output/#arkas.output.AccuracyOutput","title":"arkas.output.AccuracyOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement the accuracy output.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AccuracyState</code> <p>The state containing the ground truth and predicted labels.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output\nAccuracyOutput(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n&gt;&gt;&gt; output.get_evaluator()\nAccuracyEvaluator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.BaseLazyOutput","title":"arkas.output.BaseLazyOutput","text":"<p>               Bases: <code>BaseOutput</code></p> <p>Define a base class that partially implements the lazy computation logic.</p>"},{"location":"refs/output/#arkas.output.BaseOutput","title":"arkas.output.BaseOutput","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement an output.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output\nAccuracyOutput(\n  (state): AccuracyOutput(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.BaseOutput.equal","title":"arkas.output.BaseOutput.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two outputs are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other output to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two outputs are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output1 = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output2 = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output3 = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 0, 0]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output1.equal(output2)\nTrue\n&gt;&gt;&gt; output1.equal(output3)\nFalse\n</code></pre>"},{"location":"refs/output/#arkas.output.BaseOutput.get_content_generator","title":"arkas.output.BaseOutput.get_content_generator  <code>abstractmethod</code>","text":"<pre><code>get_content_generator() -&gt; BaseContentGenerator\n</code></pre> <p>Get the HTML content generator associated to the output.</p> <p>Returns:</p> Type Description <code>BaseContentGenerator</code> <p>The HTML content generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output.get_content_generator()\nAccuracyContentGenerator(\n  (state): AccuracyOutput(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.BaseOutput.get_evaluator","title":"arkas.output.BaseOutput.get_evaluator  <code>abstractmethod</code>","text":"<pre><code>get_evaluator(lazy: bool = True) -&gt; BaseEvaluator\n</code></pre> <p>Get the evaluator associated to the output.</p> <p>Parameters:</p> Name Type Description Default <code>lazy</code> <code>bool</code> <p>If <code>True</code>, it forces the computation of the metrics, otherwise it returns an evaluator object that contains the logic to evaluate the metrics.</p> <code>True</code> <p>Returns:</p> Type Description <code>BaseEvaluator</code> <p>The evaluator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output.get_evaluator()\nAccuracyEvaluator(\n  (state): AccuracyOutput(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n  (nan_policy): propagate\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.BaseOutput.get_plotter","title":"arkas.output.BaseOutput.get_plotter  <code>abstractmethod</code>","text":"<pre><code>get_plotter(lazy: bool = True) -&gt; BasePlotter\n</code></pre> <p>Get the plotter associated to the output.</p> <p>Parameters:</p> Name Type Description Default <code>lazy</code> <code>bool</code> <p>If <code>True</code>, it forces the computation of the figures, otherwise it returns a plotter object that contains the logic to generate the figures.</p> <code>True</code> <p>Returns:</p> Type Description <code>BasePlotter</code> <p>The plotter.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/output/#arkas.output.EmptyOutput","title":"arkas.output.EmptyOutput","text":"<p>               Bases: <code>Output</code></p> <p>Implement the accuracy output.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import EmptyOutput\n&gt;&gt;&gt; output = EmptyOutput()\n&gt;&gt;&gt; output\nEmptyOutput()\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/output/#arkas.output.Output","title":"arkas.output.Output","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement a simple output.</p> <p>Parameters:</p> Name Type Description Default <code>generator</code> <code>BaseContentGenerator</code> <p>The HTML content generator.</p> required <code>evaluator</code> <code>BaseEvaluator</code> <p>The evaluator.</p> required <code>plotter</code> <code>BasePlotter</code> <p>The plotter.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import Output\n&gt;&gt;&gt; from arkas.hcg import ContentGenerator\n&gt;&gt;&gt; from arkas.evaluator2 import Evaluator\n&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; output = Output(\n...     generator=ContentGenerator(\"meow\"), evaluator=Evaluator(), plotter=Plotter()\n... )\n&gt;&gt;&gt; output\nOutput(\n  (generator): ContentGenerator()\n  (evaluator): Evaluator(count=0)\n  (plotter): Plotter(count=0)\n)\n&gt;&gt;&gt; output.get_content_generator()\nContentGenerator()\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/plot/","title":"arkas.plot","text":""},{"location":"refs/plot/#arkas.plot","title":"arkas.plot","text":"<p>Contain plotting functionalities.</p>"},{"location":"refs/plot/#arkas.plot.binary_precision_recall_curve","title":"arkas.plot.binary_precision_recall_curve","text":"<pre><code>binary_precision_recall_curve(\n    ax: Axes,\n    y_true: ndarray,\n    y_pred: ndarray,\n    **kwargs: Any\n) -&gt; None\n</code></pre> <p>Plot the precision-recall curve for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes of the matplotlib figure to update.</p> required <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> with <code>0</code> and <code>1</code> values.</p> required <code>**kwargs</code> <code>Any</code> <p>Arbitrary keyword arguments that are passed to <code>PrecisionRecallDisplay.from_predictions</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import binary_precision_recall_curve\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; binary_precision_recall_curve(\n...     ax=ax, y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n</code></pre>"},{"location":"refs/plot/#arkas.plot.binary_roc_curve","title":"arkas.plot.binary_roc_curve","text":"<pre><code>binary_roc_curve(\n    ax: Axes,\n    y_true: ndarray,\n    y_score: ndarray,\n    **kwargs: Any\n) -&gt; None\n</code></pre> <p>Plot the Receiver Operating Characteristic Curve (ROC) for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes of the matplotlib figure to update.</p> required <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>**kwargs</code> <code>Any</code> <p>Arbitrary keyword arguments that are passed to <code>RocCurveDisplay.from_predictions</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import binary_roc_curve\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; binary_roc_curve(\n...     ax=ax, y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1])\n... )\n</code></pre>"},{"location":"refs/plotter/","title":"arkas.plotter","text":""},{"location":"refs/plotter/#arkas.plotter","title":"arkas.plotter","text":"<p>Contain data plotters.</p>"},{"location":"refs/plotter/#arkas.plotter.BasePlotter","title":"arkas.plotter.BasePlotter","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement a plotter.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; plotter = Plotter()\n&gt;&gt;&gt; plotter\nPlotter(count=0)\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.BasePlotter.equal","title":"arkas.plotter.BasePlotter.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two plotters are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other plotter to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two plotters are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; plotter1 = Plotter()\n&gt;&gt;&gt; plotter2 = Plotter()\n&gt;&gt;&gt; plotter3 = Plotter({\"fig\": None})\n&gt;&gt;&gt; plotter1.equal(plotter2)\nTrue\n&gt;&gt;&gt; plotter1.equal(plotter3)\nFalse\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.BasePlotter.plot","title":"arkas.plotter.BasePlotter.plot  <code>abstractmethod</code>","text":"<pre><code>plot(prefix: str = '', suffix: str = '') -&gt; dict\n</code></pre> <p>Generate the figures.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary with the generated figures.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; plotter = Plotter()\n&gt;&gt;&gt; plotter.plot()\n{}\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.Plotter","title":"arkas.plotter.Plotter","text":"<p>               Bases: <code>BasePlotter</code></p> <p>Implement a simple plotter.</p> <p>Parameters:</p> Name Type Description Default <code>figures</code> <code>dict | None</code> <p>The dictionary of figures.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; plotter = Plotter()\n&gt;&gt;&gt; plotter\nPlotter(count=0)\n&gt;&gt;&gt; plotter.plot()\n{}\n</code></pre>"},{"location":"refs/reporter/","title":"arkas.reporter","text":""},{"location":"refs/reporter/#arkas.reporter","title":"arkas.reporter","text":"<p>Contain reporters.</p>"},{"location":"refs/reporter/#arkas.reporter.BaseReporter","title":"arkas.reporter.BaseReporter","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to generate a HTML report.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.reporter import EvalReporter\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     reporter = EvalReporter(\n...         ingestor=Ingestor(\n...             pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         evaluator=AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         report_path=Path(tmpdir).joinpath(\"report.html\"),\n...     )\n...     reporter.generate()\n...\n</code></pre>"},{"location":"refs/reporter/#arkas.reporter.BaseReporter.generate","title":"arkas.reporter.BaseReporter.generate  <code>abstractmethod</code>","text":"<pre><code>generate() -&gt; None\n</code></pre> <p>Generate a HTML report.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.reporter import EvalReporter\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     reporter = EvalReporter(\n...         ingestor=Ingestor(\n...             pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         evaluator=AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         report_path=Path(tmpdir).joinpath(\"report.html\"),\n...     )\n...     reporter.generate()\n...\n</code></pre>"},{"location":"refs/reporter/#arkas.reporter.EvalReporter","title":"arkas.reporter.EvalReporter","text":"<p>               Bases: <code>BaseReporter</code></p> <p>Implement a simple reporter that evaluates results and writes them in a HTML file.</p> <p>Parameters:</p> Name Type Description Default <code>ingestor</code> <code>BaseIngestor | dict</code> <p>The ingestor or its configuration.</p> required <code>transformer</code> <code>BaseTransformer | dict</code> <p>The data transformer or its configuration.</p> required <code>evaluator</code> <code>BaseEvaluator | dict</code> <p>The evaluator or its configuration.</p> required <code>report_path</code> <code>Path | str</code> <p>The path where to save the HTML report.</p> required <code>max_toc_depth</code> <code>int</code> <p>The maximum level to show in the table of content.</p> <code>6</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.reporter import EvalReporter\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     reporter = EvalReporter(\n...         ingestor=Ingestor(\n...             pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         evaluator=AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         report_path=Path(tmpdir).joinpath(\"report.html\"),\n...     )\n...     reporter.generate()\n...\n</code></pre>"},{"location":"refs/reporter/#arkas.reporter.Reporter","title":"arkas.reporter.Reporter","text":"<p>               Bases: <code>BaseReporter</code></p> <p>Implement a simple reporter that generates a HTML file and save it.</p> <p>Parameters:</p> Name Type Description Default <code>report_path</code> <code>Path | str</code> <p>The path where to save the HTML report.</p> required <code>max_toc_depth</code> <code>int</code> <p>The maximum level to show in the table of content.</p> <code>6</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.hcg import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.reporter import Reporter\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     reporter = Reporter(\n...         report_path=Path(tmpdir).joinpath(\"report.html\"),\n...     )\n...     reporter.generate(generator)\n...\n</code></pre>"},{"location":"refs/reporter/#arkas.reporter.is_reporter_config","title":"arkas.reporter.is_reporter_config","text":"<pre><code>is_reporter_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseReporter</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseReporter</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.reporter import is_reporter_config\n&gt;&gt;&gt; is_reporter_config(\n...     {\n...         \"_target_\": \"arkas.reporter.EvalReporter\",\n...         \"ingestor\": {\n...             \"_target_\": \"grizz.ingestor.CsvIngestor\",\n...             \"path\": \"/path/to/data.csv\",\n...         },\n...         \"transformer\": {\"_target_\": \"grizz.transformer.DropDuplicate\"},\n...         \"evaluator\": {\n...             \"_target_\": \"arkas.evaluator.AccuracyEvaluator\",\n...             \"y_true\": \"target\",\n...             \"y_pred\": \"pred\",\n...         },\n...         \"report_path\": \"/path/to/report.html\",\n...     }\n... )\nTrue\n</code></pre>"},{"location":"refs/reporter/#arkas.reporter.setup_reporter","title":"arkas.reporter.setup_reporter","text":"<pre><code>setup_reporter(\n    reporter: BaseReporter | dict,\n) -&gt; BaseReporter\n</code></pre> <p>Set up a reporter.</p> <p>The reporter is instantiated from its configuration by using the <code>BaseReporter</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>reporter</code> <code>BaseReporter | dict</code> <p>A reporter or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseReporter</code> <p>An instantiated reporter.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.reporter import setup_reporter\n&gt;&gt;&gt; reporter = setup_reporter(\n...     {\n...         \"_target_\": \"arkas.reporter.EvalReporter\",\n...         \"ingestor\": {\n...             \"_target_\": \"grizz.ingestor.CsvIngestor\",\n...             \"path\": \"/path/to/data.csv\",\n...         },\n...         \"transformer\": {\"_target_\": \"grizz.transformer.DropDuplicate\"},\n...         \"evaluator\": {\n...             \"_target_\": \"arkas.evaluator.AccuracyEvaluator\",\n...             \"y_true\": \"target\",\n...             \"y_pred\": \"pred\",\n...         },\n...         \"report_path\": \"/path/to/report.html\",\n...     }\n... )\n&gt;&gt;&gt; reporter\nEvalReporter(\n  (ingestor): CsvIngestor(path=/path/to/data.csv)\n  (transformer): DropDuplicateTransformer(columns=None, exclude_columns=(), missing_policy='raise')\n  (evaluator): AccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n  (report_path): /path/to/report.html\n  (max_toc_depth): 6\n)\n</code></pre>"},{"location":"refs/result/","title":"arkas.result","text":""},{"location":"refs/result/#arkas.result","title":"arkas.result","text":"<p>Contain results.</p>"},{"location":"refs/result/#arkas.result.AccuracyResult","title":"arkas.result.AccuracyResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the accuracy result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; result = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.AveragePrecisionResult","title":"arkas.result.AveragePrecisionResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the average precision result.</p> <p>This result can be used in 3 different settings:</p> <ul> <li>binary: <code>y_true</code> must be an array of shape <code>(*)</code>     with <code>0</code> and <code>1</code> values, and <code>y_score</code> must be an array     of shape <code>(*)</code>.</li> <li>multiclass: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with values in <code>{0, ..., n_classes-1}</code>, and <code>y_score</code> must     be an array of shape <code>(n_samples, n_classes)</code>.</li> <li>multilabel: <code>y_true</code> must be an array of shape     <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values, and     <code>y_score</code> must be an array of shape     <code>(n_samples, n_classes)</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, <code>'multilabel'</code>, and <code>'auto'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>. If <code>'auto'</code>, it tries to automatically find the label type from the arrays' shape.</p> <code>'auto'</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AveragePrecisionResult\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; result = AveragePrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_score=np.array([2, -1, 0, 3, 1]),\n...     label_type=\"binary\",\n... )\n&gt;&gt;&gt; result\nAveragePrecisionResult(y_true=(5,), y_score=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': 1.0, 'count': 5}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; result = AveragePrecisionResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, -1], [-1, 1, 2], [0, 2, 3], [3, -2, -4], [1, -3, -5]]),\n...     label_type=\"multilabel\",\n... )\n&gt;&gt;&gt; result\nAveragePrecisionResult(y_true=(5, 3), y_score=(5, 3), label_type='multilabel', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': array([1. , 1. , 0.477...]),\n 'count': 5,\n 'macro_average_precision': 0.825...,\n 'micro_average_precision': 0.588...,\n 'weighted_average_precision': 0.804...}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; result = AveragePrecisionResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.3, 0.5],\n...             [0.4, 0.4, 0.2],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n...     label_type=\"multiclass\",\n... )\n&gt;&gt;&gt; result\nAveragePrecisionResult(y_true=(6,), y_score=(6, 3), label_type='multiclass', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': array([0.833..., 0.75 , 0.75 ]),\n 'count': 6,\n 'macro_average_precision': 0.777...,\n 'micro_average_precision': 0.75,\n 'weighted_average_precision': 0.777...}\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; result = AveragePrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_score=np.array([2, -1, 0, 3, 1]),\n... )\n&gt;&gt;&gt; result\nAveragePrecisionResult(y_true=(5,), y_score=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': 1.0, 'count': 5}\n</code></pre>"},{"location":"refs/result/#arkas.result.BalancedAccuracyResult","title":"arkas.result.BalancedAccuracyResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the balanced accuracy result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; result = BalancedAccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBalancedAccuracyResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'balanced_accuracy': 1.0, 'count': 5}\n</code></pre>"},{"location":"refs/result/#arkas.result.BaseResult","title":"arkas.result.BaseResult","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to manage results.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; result = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BaseResult.compute_metrics","title":"arkas.result.BaseResult.compute_metrics  <code>abstractmethod</code>","text":"<pre><code>compute_metrics(prefix: str = '', suffix: str = '') -&gt; dict\n</code></pre> <p>Return the metrics associated to the result.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict</code> <p>The metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; result = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BaseResult.equal","title":"arkas.result.BaseResult.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two results are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other result to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two results are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; res1 = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; res2 = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; res3 = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 0, 0]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; res1.equal(res2)\nTrue\n&gt;&gt;&gt; res1.equal(res3)\nFalse\n</code></pre>"},{"location":"refs/result/#arkas.result.BaseResult.generate_figures","title":"arkas.result.BaseResult.generate_figures  <code>abstractmethod</code>","text":"<pre><code>generate_figures(\n    prefix: str = \"\", suffix: str = \"\"\n) -&gt; dict[str, Figure]\n</code></pre> <p>Return the figures associated to the result.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict[str, Figure]</code> <p>The figures.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; result = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result.generate_figures()\n{}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryAveragePrecisionResult","title":"arkas.result.BinaryAveragePrecisionResult","text":"<p>               Bases: <code>BaseAveragePrecisionResult</code></p> <p>Implement the average precision result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryAveragePrecisionResult\n&gt;&gt;&gt; result = BinaryAveragePrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1])\n... )\n&gt;&gt;&gt; result\nBinaryAveragePrecisionResult(y_true=(5,), y_score=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': 1.0, 'count': 5}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryClassificationResult","title":"arkas.result.BinaryClassificationResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the default binary classification result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target binary labels. This input must be an array of shape <code>(n_samples,)</code> where the values are <code>0</code> or <code>1</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted binary labels. This input must be an array of shape <code>(n_samples,)</code> where the values are <code>0</code> or <code>1</code>.</p> required <code>y_score</code> <code>ndarray | None</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> <code>None</code> <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryClassificationResult\n&gt;&gt;&gt; result = BinaryClassificationResult(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_score=np.array([2, -1, 0, 3, 1]),\n... )\n&gt;&gt;&gt; result\nBinaryClassificationResult(y_true=(5,), y_pred=(5,), y_score=(5,), betas=(1,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 1.0,\n 'count_correct': 5,\n 'count_incorrect': 0,\n 'count': 5,\n 'error': 0.0,\n 'balanced_accuracy': 1.0,\n 'confusion_matrix': array([[2, 0], [0, 3]]),\n 'false_negative_rate': 0.0,\n 'false_negative': 0,\n 'false_positive_rate': 0.0,\n 'false_positive': 0,\n 'true_negative_rate': 1.0,\n 'true_negative': 2,\n 'true_positive_rate': 1.0,\n 'true_positive': 3,\n 'f1': 1.0,\n 'jaccard': 1.0,\n 'precision': 1.0,\n 'recall': 1.0,\n 'average_precision': 1.0,\n 'roc_auc': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryConfusionMatrixResult","title":"arkas.result.BinaryConfusionMatrixResult","text":"<p>               Bases: <code>BaseConfusionMatrixResult</code></p> <p>Implement the confusion matrix result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryConfusionMatrixResult\n&gt;&gt;&gt; result = BinaryConfusionMatrixResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBinaryConfusionMatrixResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'confusion_matrix': array([[2, 0], [0, 3]]),\n 'count': 5,\n 'false_negative_rate': 0.0,\n 'false_negative': 0,\n 'false_positive_rate': 0.0,\n 'false_positive': 0,\n 'true_negative_rate': 1.0,\n 'true_negative': 2,\n 'true_positive_rate': 1.0,\n 'true_positive': 3}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryFbetaScoreResult","title":"arkas.result.BinaryFbetaScoreResult","text":"<p>               Bases: <code>BaseFbetaScoreResult</code></p> <p>Implement the F-beta result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryFbetaScoreResult\n&gt;&gt;&gt; result = BinaryFbetaScoreResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBinaryFbetaScoreResult(y_true=(5,), y_pred=(5,), betas=(1,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'f1': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryJaccardResult","title":"arkas.result.BinaryJaccardResult","text":"<p>               Bases: <code>BaseJaccardResult</code></p> <p>Implement the Jaccard result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryJaccardResult\n&gt;&gt;&gt; result = BinaryJaccardResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBinaryJaccardResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'jaccard': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryPrecisionResult","title":"arkas.result.BinaryPrecisionResult","text":"<p>               Bases: <code>BasePrecisionResult</code></p> <p>Implement the precision result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryPrecisionResult\n&gt;&gt;&gt; result = BinaryPrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBinaryPrecisionResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryRecallResult","title":"arkas.result.BinaryRecallResult","text":"<p>               Bases: <code>BaseRecallResult</code></p> <p>Implement the recall result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryRecallResult\n&gt;&gt;&gt; result = BinaryRecallResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBinaryRecallResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'recall': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryRocAucResult","title":"arkas.result.BinaryRocAucResult","text":"<p>               Bases: <code>BaseRocAucResult</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryRocAucResult\n&gt;&gt;&gt; result = BinaryRocAucResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1])\n... )\n&gt;&gt;&gt; result\nBinaryRocAucResult(y_true=(5,), y_score=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'roc_auc': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.EmptyResult","title":"arkas.result.EmptyResult","text":"<p>               Bases: <code>Result</code></p> <p>Implement an empty result.</p> <p>This result is designed to be used when it is possible to evaluate a result.</p>"},{"location":"refs/result/#arkas.result.EnergyDistanceResult","title":"arkas.result.EnergyDistanceResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the energy distance between two 1D distributions result.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>v_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import EnergyDistanceResult\n&gt;&gt;&gt; result = EnergyDistanceResult(\n...     u_values=np.array([1, 2, 3, 4, 5]), v_values=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nEnergyDistanceResult(u_values=(5,), v_values=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'energy_distance': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.JensenShannonDivergenceResult","title":"arkas.result.JensenShannonDivergenceResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the Jensen-Shannon (JS) divergence between two 1D distributions result.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>ndarray</code> <p>The true probability distribution.</p> required <code>q</code> <code>ndarray</code> <p>The model probability distribution.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import JensenShannonDivergenceResult\n&gt;&gt;&gt; result = JensenShannonDivergenceResult(\n...     p=np.array([0.1, 0.6, 0.1, 0.2]), q=np.array([0.2, 0.5, 0.2, 0.1])\n... )\n&gt;&gt;&gt; result\nJensenShannonDivergenceResult(p=(4,), q=(4,))\n&gt;&gt;&gt; result.compute_metrics()\n{'size': 4, 'jensen_shannon_divergence': 0.027...}\n</code></pre>"},{"location":"refs/result/#arkas.result.KLDivResult","title":"arkas.result.KLDivResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the Kullback-Leibler (KL) divergence between two 1D distributions result.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>ndarray</code> <p>The true probability distribution.</p> required <code>q</code> <code>ndarray</code> <p>The model probability distribution.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import KLDivResult\n&gt;&gt;&gt; result = KLDivResult(p=np.array([0.1, 0.6, 0.1, 0.2]), q=np.array([0.2, 0.5, 0.2, 0.1]))\n&gt;&gt;&gt; result\nKLDivResult(p=(4,), q=(4,))\n&gt;&gt;&gt; result.compute_metrics()\n{'size': 4, 'kl_pq': 0.109..., 'kl_qp': 0.116...}\n</code></pre>"},{"location":"refs/result/#arkas.result.MappingResult","title":"arkas.result.MappingResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement a result that combines a mapping of result objects into a single result object.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Mapping[str, BaseResult]</code> <p>The mapping of result objects to combine.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MappingResult, Result\n&gt;&gt;&gt; result = MappingResult(\n...     {\n...         \"class1\": Result(metrics={\"accuracy\": 62.0, \"count\": 42}),\n...         \"class2\": Result(metrics={\"accuracy\": 42.0, \"count\": 42}),\n...     }\n... )\n&gt;&gt;&gt; result\nMappingResult(count=2)\n&gt;&gt;&gt; result.compute_metrics()\n{'class1': {'accuracy': 62.0, 'count': 42}, 'class2': {'accuracy': 42.0, 'count': 42}}\n</code></pre>"},{"location":"refs/result/#arkas.result.MeanAbsoluteErrorResult","title":"arkas.result.MeanAbsoluteErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean absolute error (MAE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MeanAbsoluteErrorResult\n&gt;&gt;&gt; result = MeanAbsoluteErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMeanAbsoluteErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'mean_absolute_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MeanAbsolutePercentageErrorResult","title":"arkas.result.MeanAbsolutePercentageErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean absolute percentage error (MAPE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MeanAbsolutePercentageErrorResult\n&gt;&gt;&gt; result = MeanAbsolutePercentageErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMeanAbsolutePercentageErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'mean_absolute_percentage_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MeanSquaredErrorResult","title":"arkas.result.MeanSquaredErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean squared error (MSE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MeanSquaredErrorResult\n&gt;&gt;&gt; result = MeanSquaredErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMeanSquaredErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'mean_squared_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MeanSquaredLogErrorResult","title":"arkas.result.MeanSquaredLogErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean squared logarithmic error (MSLE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MeanSquaredLogErrorResult\n&gt;&gt;&gt; result = MeanSquaredLogErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMeanSquaredLogErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'mean_squared_log_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MeanTweedieDevianceResult","title":"arkas.result.MeanTweedieDevianceResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean Tweedie deviance regression loss result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>powers</code> <code>Sequence[float]</code> <p>The Tweedie power parameter. The higher power the less weight is given to extreme deviations between true and predicted targets.</p> <code>(0,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MeanTweedieDevianceResult\n&gt;&gt;&gt; result = MeanTweedieDevianceResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMeanTweedieDevianceResult(y_true=(5,), y_pred=(5,), powers=(0,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'mean_tweedie_deviance_power_0': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MedianAbsoluteErrorResult","title":"arkas.result.MedianAbsoluteErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the median absolute error (MAE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MedianAbsoluteErrorResult\n&gt;&gt;&gt; result = MedianAbsoluteErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMedianAbsoluteErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'median_absolute_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassAveragePrecisionResult","title":"arkas.result.MulticlassAveragePrecisionResult","text":"<p>               Bases: <code>BaseAveragePrecisionResult</code></p> <p>Implement the average precision result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassAveragePrecisionResult\n&gt;&gt;&gt; result = MulticlassAveragePrecisionResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.5, 0.3],\n...             [0.3, 0.3, 0.4],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n... )\n&gt;&gt;&gt; result\nMulticlassAveragePrecisionResult(y_true=(6,), y_score=(6, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': array([1., 1., 1.]),\n 'count': 6,\n 'macro_average_precision': 1.0,\n 'micro_average_precision': 1.0,\n 'weighted_average_precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassConfusionMatrixResult","title":"arkas.result.MulticlassConfusionMatrixResult","text":"<p>               Bases: <code>BaseConfusionMatrixResult</code></p> <p>Implement the confusion matrix result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassConfusionMatrixResult\n&gt;&gt;&gt; result = MulticlassConfusionMatrixResult(\n...     y_true=np.array([0, 1, 1, 2, 2, 2]),\n...     y_pred=np.array([0, 1, 1, 2, 2, 2]),\n... )\n&gt;&gt;&gt; result\nMulticlassConfusionMatrixResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'confusion_matrix': array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]), 'count': 6}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassFbetaScoreResult","title":"arkas.result.MulticlassFbetaScoreResult","text":"<p>               Bases: <code>BaseFbetaScoreResult</code></p> <p>Implement the F-beta result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassFbetaScoreResult\n&gt;&gt;&gt; result = MulticlassFbetaScoreResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n... )\n&gt;&gt;&gt; result\nMulticlassFbetaScoreResult(y_true=(6,), y_pred=(6,), betas=(1,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassJaccardResult","title":"arkas.result.MulticlassJaccardResult","text":"<p>               Bases: <code>BaseJaccardResult</code></p> <p>Implement the Jaccard result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassJaccardResult\n&gt;&gt;&gt; result = MulticlassJaccardResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n... )\n&gt;&gt;&gt; result\nMulticlassJaccardResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassPrecisionResult","title":"arkas.result.MulticlassPrecisionResult","text":"<p>               Bases: <code>BasePrecisionResult</code></p> <p>Implement the precision result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassPrecisionResult\n&gt;&gt;&gt; result = MulticlassPrecisionResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n... )\n&gt;&gt;&gt; result\nMulticlassPrecisionResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassRecallResult","title":"arkas.result.MulticlassRecallResult","text":"<p>               Bases: <code>BaseRecallResult</code></p> <p>Implement the recall result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassRecallResult\n&gt;&gt;&gt; result = MulticlassRecallResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n... )\n&gt;&gt;&gt; result\nMulticlassRecallResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassRocAucResult","title":"arkas.result.MulticlassRocAucResult","text":"<p>               Bases: <code>BaseRocAucResult</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassRocAucResult\n&gt;&gt;&gt; result = MulticlassRocAucResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.5, 0.3],\n...             [0.3, 0.3, 0.4],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n... )\n&gt;&gt;&gt; result\nMulticlassRocAucResult(y_true=(6,), y_score=(6, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'macro_roc_auc': 1.0,\n 'micro_roc_auc': 1.0,\n 'roc_auc': array([1., 1., 1.]),\n 'weighted_roc_auc': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelAveragePrecisionResult","title":"arkas.result.MultilabelAveragePrecisionResult","text":"<p>               Bases: <code>BaseAveragePrecisionResult</code></p> <p>Implement the average precision result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelAveragePrecisionResult\n&gt;&gt;&gt; result = MultilabelAveragePrecisionResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, 1], [-1, 1, -2], [0, 2, -3], [3, -2, 4], [1, -3, 5]]),\n... )\n&gt;&gt;&gt; result\nMultilabelAveragePrecisionResult(y_true=(5, 3), y_score=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': array([1., 1., 1.]),\n 'count': 5,\n 'macro_average_precision': 1.0,\n 'micro_average_precision': 1.0,\n 'weighted_average_precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelConfusionMatrixResult","title":"arkas.result.MultilabelConfusionMatrixResult","text":"<p>               Bases: <code>BaseConfusionMatrixResult</code></p> <p>Implement the confusion matrix result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelConfusionMatrixResult\n&gt;&gt;&gt; result = MultilabelConfusionMatrixResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n&gt;&gt;&gt; result\nMultilabelConfusionMatrixResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'confusion_matrix': array([[[2, 0], [0, 3]],\n                            [[3, 0], [0, 2]],\n                            [[2, 0], [0, 3]]]),\n 'count': 5}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelFbetaScoreResult","title":"arkas.result.MultilabelFbetaScoreResult","text":"<p>               Bases: <code>BaseFbetaScoreResult</code></p> <p>Implement the F-beta result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelFbetaScoreResult\n&gt;&gt;&gt; result = MultilabelFbetaScoreResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n&gt;&gt;&gt; result\nMultilabelFbetaScoreResult(y_true=(5, 3), y_pred=(5, 3), betas=(1,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelJaccardResult","title":"arkas.result.MultilabelJaccardResult","text":"<p>               Bases: <code>BaseJaccardResult</code></p> <p>Implement the Jaccard result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelJaccardResult\n&gt;&gt;&gt; result = MultilabelJaccardResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n&gt;&gt;&gt; result\nMultilabelJaccardResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelPrecisionResult","title":"arkas.result.MultilabelPrecisionResult","text":"<p>               Bases: <code>BasePrecisionResult</code></p> <p>Implement the precision result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelPrecisionResult\n&gt;&gt;&gt; result = MultilabelPrecisionResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n&gt;&gt;&gt; result\nMultilabelPrecisionResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelRecallResult","title":"arkas.result.MultilabelRecallResult","text":"<p>               Bases: <code>BaseRecallResult</code></p> <p>Implement the recall result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelRecallResult\n&gt;&gt;&gt; result = MultilabelRecallResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n&gt;&gt;&gt; result\nMultilabelRecallResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelRocAucResult","title":"arkas.result.MultilabelRocAucResult","text":"<p>               Bases: <code>BaseRocAucResult</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelRocAucResult\n&gt;&gt;&gt; result = MultilabelRocAucResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, 1], [-1, 1, -2], [0, 2, -3], [3, -2, 4], [1, -3, 5]]),\n... )\n&gt;&gt;&gt; result\nMultilabelRocAucResult(y_true=(5, 3), y_score=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'macro_roc_auc': 1.0,\n 'micro_roc_auc': 1.0,\n 'roc_auc': array([1., 1., 1.]),\n 'weighted_roc_auc': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.PearsonCorrelationResult","title":"arkas.result.PearsonCorrelationResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the Pearson correlation result.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The first input array.</p> required <code>y</code> <code>ndarray</code> <p>The second input array.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import PearsonCorrelationResult\n&gt;&gt;&gt; result = PearsonCorrelationResult(\n...     x=np.array([1, 2, 3, 4, 5]), y=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nPearsonCorrelationResult(x=(5,), y=(5,), alternative='two-sided', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'pearson_coeff': 1.0, 'pearson_pvalue': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.PrecisionResult","title":"arkas.result.PrecisionResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the precision result.</p> <p>This result can be used in 3 different settings:</p> <ul> <li>binary: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with <code>0</code> and <code>1</code> values, and <code>y_pred</code> must be an array     of shape <code>(n_samples,)</code>.</li> <li>multiclass: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with values in <code>{0, ..., n_classes-1}</code>, and <code>y_pred</code> must     be an array of shape <code>(n_samples,)</code>.</li> <li>multilabel: <code>y_true</code> must be an array of shape     <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values, and     <code>y_pred</code> must be an array of shape     <code>(n_samples, n_classes)</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import PrecisionResult\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; result = PrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n&gt;&gt;&gt; result\nPrecisionResult(y_true=(5,), y_pred=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'precision': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; result = PrecisionResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]]),\n...     label_type=\"multilabel\",\n... )\n&gt;&gt;&gt; result\nPrecisionResult(y_true=(5, 3), y_pred=(5, 3), label_type='multilabel', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'macro_precision': 0.666...,\n 'micro_precision': 0.714...,\n 'precision': array([1., 1., 0.]),\n 'weighted_precision': 0.625}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; result = PrecisionResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n&gt;&gt;&gt; result\nPrecisionResult(y_true=(6,), y_pred=(6,), label_type='multiclass', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; result = PrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nPrecisionResult(y_true=(5,), y_pred=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.R2ScoreResult","title":"arkas.result.R2ScoreResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the R^2 (coefficient of determination) regression score result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import R2ScoreResult\n&gt;&gt;&gt; result = R2ScoreResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nR2ScoreResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'r2_score': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.RecallResult","title":"arkas.result.RecallResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the recall result.</p> <p>This result can be used in 3 different settings:</p> <ul> <li>binary: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with <code>0</code> and <code>1</code> values, and <code>y_pred</code> must be an array     of shape <code>(n_samples,)</code>.</li> <li>multiclass: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with values in <code>{0, ..., n_classes-1}</code>, and <code>y_pred</code> must     be an array of shape <code>(n_samples,)</code>.</li> <li>multilabel: <code>y_true</code> must be an array of shape     <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values, and     <code>y_pred</code> must be an array of shape     <code>(n_samples, n_classes)</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import RecallResult\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; result = RecallResult(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n&gt;&gt;&gt; result\nRecallResult(y_true=(5,), y_pred=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'recall': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; result = RecallResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]]),\n...     label_type=\"multilabel\",\n... )\n&gt;&gt;&gt; result\nRecallResult(y_true=(5, 3), y_pred=(5, 3), label_type='multilabel', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'macro_recall': 0.666...,\n 'micro_recall': 0.625,\n 'recall': array([1., 1., 0.]),\n 'weighted_recall': 0.625}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; result = RecallResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n&gt;&gt;&gt; result\nRecallResult(y_true=(6,), y_pred=(6,), label_type='multiclass', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; result = RecallResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nRecallResult(y_true=(5,), y_pred=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'recall': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.RegressionErrorResult","title":"arkas.result.RegressionErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement a \"universal\" regression error result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import RegressionErrorResult\n&gt;&gt;&gt; result = RegressionErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nRegressionErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'mean_absolute_error': 0.0,\n 'median_absolute_error': 0.0,\n 'mean_squared_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.Result","title":"arkas.result.Result","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement a simple result.</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>dict | None</code> <p>The metrics.</p> <code>None</code> <code>figures</code> <code>dict | None</code> <p>The figures.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.result import Result\n&gt;&gt;&gt; result = Result(metrics={\"accuracy\": 1.0, \"count\": 42}, figures={})\n&gt;&gt;&gt; result\nResult(metrics=2, figures=0)\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 1.0, 'count': 42}\n</code></pre>"},{"location":"refs/result/#arkas.result.RootMeanSquaredErrorResult","title":"arkas.result.RootMeanSquaredErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean squared error (MSE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import RootMeanSquaredErrorResult\n&gt;&gt;&gt; result = RootMeanSquaredErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nRootMeanSquaredErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'root_mean_squared_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.SequentialResult","title":"arkas.result.SequentialResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement a result to merge multiple result objects into a single result object.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Sequence[BaseResult]</code> <p>The results to merge. This order is used to merge the metrics and figures if they have duplicate keys, i.e. only the last value for each key is kept.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import SequentialResult, Result\n&gt;&gt;&gt; result = SequentialResult(\n...     [\n...         Result(metrics={\"accuracy\": 62.0, \"count\": 42}),\n...         Result(metrics={\"ap\": 0.42, \"count\": 42}),\n...     ]\n... )\n&gt;&gt;&gt; result\nSequentialResult(count=2)\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 62.0, 'count': 42, 'ap': 0.42}\n</code></pre>"},{"location":"refs/result/#arkas.result.SpearmanCorrelationResult","title":"arkas.result.SpearmanCorrelationResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the Spearman correlation result.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The first input array.</p> required <code>y</code> <code>ndarray</code> <p>The second input array.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import SpearmanCorrelationResult\n&gt;&gt;&gt; result = SpearmanCorrelationResult(\n...     x=np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n...     y=np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n... )\n&gt;&gt;&gt; result\nSpearmanCorrelationResult(x=(9,), y=(9,), alternative='two-sided', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 9, 'spearman_coeff': 1.0, 'spearman_pvalue': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.WassersteinDistanceResult","title":"arkas.result.WassersteinDistanceResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the Wasserstein distance between two 1D distributions result.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>v_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import WassersteinDistanceResult\n&gt;&gt;&gt; result = WassersteinDistanceResult(\n...     u_values=np.array([1, 2, 3, 4, 5]), v_values=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nWassersteinDistanceResult(u_values=(5,), v_values=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'wasserstein_distance': 0.0}\n</code></pre>"},{"location":"refs/runner/","title":"arkas.runner","text":""},{"location":"refs/runner/#arkas.runner","title":"arkas.runner","text":"<p>Contain runners.</p>"},{"location":"refs/runner/#arkas.runner.AnalysisRunner","title":"arkas.runner.AnalysisRunner","text":"<p>               Bases: <code>BaseRunner</code></p> <p>Implement a runner to analyze data.</p> <p>Parameters:</p> Name Type Description Default <code>ingestor</code> <code>BaseIngestor | dict</code> <p>The data ingestor or its configuration.</p> required <code>transformer</code> <code>BaseTransformer | dict</code> <p>The data transformer or its configuration.</p> required <code>analyzer</code> <code>BaseAnalyzer | dict</code> <p>The analyzer or its configuration.</p> required <code>exporter</code> <code>BaseExporter | dict</code> <p>The output exporter or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; from arkas.runner import AnalysisRunner\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     runner = AnalysisRunner(\n...         ingestor=Ingestor(\n...             pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             )\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         analyzer=AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\"),\n...         exporter=MetricExporter(Path(tmpdir).joinpath(\"metrics.pkl\")),\n...     )\n...     print(runner)\n...     runner.run()\n...\nAnalysisRunner(\n  (ingestor): Ingestor(shape=(5, 2))\n  (transformer): SequentialTransformer()\n  (analyzer): AccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n  (exporter): MetricExporter(\n      (path): .../metrics.pkl\n      (saver): PickleSaver(protocol=5)\n      (exist_ok): False\n      (show_metrics): True\n    )\n)\n</code></pre>"},{"location":"refs/runner/#arkas.runner.BaseRunner","title":"arkas.runner.BaseRunner","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement a runner.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; from arkas.runner import AnalysisRunner\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     runner = AnalysisRunner(\n...         ingestor=Ingestor(\n...             pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             )\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         analyzer=AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\"),\n...         exporter=MetricExporter(Path(tmpdir).joinpath(\"metrics.pkl\")),\n...     )\n...     print(runner)\n...     runner.run()\n...\nAnalysisRunner(\n  (ingestor): Ingestor(shape=(5, 2))\n  (transformer): SequentialTransformer()\n  (analyzer): AccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n  (exporter): MetricExporter(\n      (path): .../metrics.pkl\n      (saver): PickleSaver(protocol=5)\n      (exist_ok): False\n      (show_metrics): True\n    )\n)\n</code></pre>"},{"location":"refs/runner/#arkas.runner.BaseRunner.run","title":"arkas.runner.BaseRunner.run  <code>abstractmethod</code>","text":"<pre><code>run() -&gt; Any\n</code></pre> <p>Execute the logic of the runner.</p> <p>Returns:</p> Type Description <code>Any</code> <p>Any artifact of the runner</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; from arkas.runner import AnalysisRunner\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     runner = AnalysisRunner(\n...         ingestor=Ingestor(\n...             pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             )\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         analyzer=AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\"),\n...         exporter=MetricExporter(Path(tmpdir).joinpath(\"metrics.pkl\")),\n...     )\n...     runner.run()\n...\n</code></pre>"},{"location":"refs/runner/#arkas.runner.EvaluationRunner","title":"arkas.runner.EvaluationRunner","text":"<p>               Bases: <code>BaseRunner</code></p> <p>Implement a simple evaluation runner.</p> <p>Parameters:</p> Name Type Description Default <code>ingestor</code> <code>BaseIngestor | dict</code> <p>The data ingestor or its configuration.</p> required <code>transformer</code> <code>BaseTransformer | dict</code> <p>The data transformer or its configuration.</p> required <code>evaluator</code> <code>BaseEvaluator | dict</code> <p>The evaluator or its configuration.</p> required <code>saver</code> <code>BaseSaver | dict</code> <p>The metric saver or its configuration.</p> required <code>path</code> <code>Path | str</code> <p>The path where to save the metrics.</p> required <code>show_metrics</code> <code>bool</code> <p>If <code>True</code>, the metrics are shown in the logging output.</p> <code>True</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from iden.io import PickleSaver\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; from arkas.runner import EvaluationRunner\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     path = Path(tmpdir).joinpath(\"metrics.pkl\")\n...     runner = EvaluationRunner(\n...         ingestor=Ingestor(\n...             pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             )\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         evaluator=AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         saver=PickleSaver(),\n...         path=path,\n...     )\n...     print(runner)\n...     runner.run()\n...\nEvaluationRunner(\n  (ingestor): Ingestor(shape=(5, 2))\n  (transformer): SequentialTransformer()\n  (evaluator): AccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n  (saver): PickleSaver(protocol=5)\n  (path): .../metrics.pkl\n  (show_metrics): True\n)\n</code></pre>"},{"location":"refs/runner/#arkas.runner.is_runner_config","title":"arkas.runner.is_runner_config","text":"<pre><code>is_runner_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseRunner</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseRunner</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.runner import is_runner_config\n&gt;&gt;&gt; is_runner_config(\n...     {\n...         \"_target_\": \"arkas.runner.AnalysisRunner\",\n...         \"ingestor\": {\n...             \"_target_\": \"grizz.ingestor.Ingestor\",\n...             \"frame\": pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             ),\n...         },\n...         \"transformer\": {\"_target_\": \"grizz.transformer.DropDuplicate\"},\n...         \"analyzer\": {\n...             \"_target_\": \"arkas.analyzer.AccuracyAnalyzer\",\n...             \"y_true\": \"target\",\n...             \"y_pred\": \"pred\",\n...         },\n...         \"exporter\": {\n...             \"_target_\": \"arkas.exporter.MetricExporter\",\n...             \"path\": \"/path/to/data.csv\",\n...         },\n...     }\n... )\nTrue\n</code></pre>"},{"location":"refs/runner/#arkas.runner.setup_runner","title":"arkas.runner.setup_runner","text":"<pre><code>setup_runner(runner: BaseRunner | dict) -&gt; BaseRunner\n</code></pre> <p>Set up a runner.</p> <p>The runner is instantiated from its configuration by using the <code>BaseRunner</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>runner</code> <code>BaseRunner | dict</code> <p>Specifies a runner or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseRunner</code> <p>An instantiated runner.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.runner import setup_runner\n&gt;&gt;&gt; runner = setup_runner(\n...     {\n...         \"_target_\": \"arkas.runner.AnalysisRunner\",\n...         \"ingestor\": {\n...             \"_target_\": \"grizz.ingestor.Ingestor\",\n...             \"frame\": pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             ),\n...         },\n...         \"transformer\": {\"_target_\": \"grizz.transformer.DropDuplicate\"},\n...         \"analyzer\": {\n...             \"_target_\": \"arkas.analyzer.AccuracyAnalyzer\",\n...             \"y_true\": \"target\",\n...             \"y_pred\": \"pred\",\n...         },\n...         \"exporter\": {\n...             \"_target_\": \"arkas.exporter.MetricExporter\",\n...             \"path\": \"/path/to/data.csv\",\n...         },\n...     }\n... )\n&gt;&gt;&gt; runner\nAnalysisRunner(\n  (ingestor): Ingestor(shape=(5, 2))\n  (transformer): DropDuplicateTransformer(columns=None, exclude_columns=(), missing_policy='raise')\n  (analyzer): AccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n  (exporter): MetricExporter(\n      (path): /path/to/data.csv\n      (saver): PickleSaver(protocol=5)\n      (exist_ok): False\n      (show_metrics): True\n    )\n)\n</code></pre>"},{"location":"refs/section/","title":"arkas.section","text":""},{"location":"refs/section/#arkas.section","title":"arkas.section","text":"<p>Contain sections.</p>"},{"location":"refs/section/#arkas.section.AccuracySection","title":"arkas.section.AccuracySection","text":"<p>               Bases: <code>BaseSection</code></p> <p>Implement a section that analyze accuracy results.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>BaseResult</code> <p>The data structure containing the results.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.section import AccuracySection\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; section = AccuracySection(\n...     result=AccuracyResult(\n...         y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n...     )\n... )\n&gt;&gt;&gt; section\nAccuracySection(\n  (result): AccuracyResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n)\n&gt;&gt;&gt; section.generate_html_body()\n</code></pre>"},{"location":"refs/section/#arkas.section.BaseSection","title":"arkas.section.BaseSection","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to manage sections.</p>"},{"location":"refs/section/#arkas.section.BaseSection.equal","title":"arkas.section.BaseSection.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any) -&gt; bool\n</code></pre> <p>Indicate if two sections are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other section to compare.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two sections are equal, otherwise <code>False</code>.</p>"},{"location":"refs/section/#arkas.section.BaseSection.generate_html_body","title":"arkas.section.BaseSection.generate_html_body  <code>abstractmethod</code>","text":"<pre><code>generate_html_body(\n    number: str = \"\",\n    tags: Sequence[str] = (),\n    depth: int = 0,\n) -&gt; str\n</code></pre> <p>Return the HTML body associated to the section.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>str</code> <p>The section number.</p> <code>''</code> <code>tags</code> <code>Sequence[str]</code> <p>The tags associated to the section.</p> <code>()</code> <code>depth</code> <code>int</code> <p>The depth in the report.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p>The HTML body associated to the section.</p>"},{"location":"refs/section/#arkas.section.BaseSection.generate_html_toc","title":"arkas.section.BaseSection.generate_html_toc  <code>abstractmethod</code>","text":"<pre><code>generate_html_toc(\n    number: str = \"\",\n    tags: Sequence[str] = (),\n    depth: int = 0,\n    max_depth: int = 1,\n) -&gt; str\n</code></pre> <p>Return the HTML table of content (TOC) associated to the section.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>str</code> <p>The section number associated to the section.</p> <code>''</code> <code>tags</code> <code>Sequence[str]</code> <p>The tags associated to the section.</p> <code>()</code> <code>depth</code> <code>int</code> <p>The depth in the report.</p> <code>0</code> <code>max_depth</code> <code>int</code> <p>The maximum depth to generate in the TOC.</p> <code>1</code> <p>Returns:</p> Type Description <code>str</code> <p>The HTML table of content associated to the section.</p>"},{"location":"refs/section/#arkas.section.BinaryPrecisionSection","title":"arkas.section.BinaryPrecisionSection","text":"<p>               Bases: <code>BaseSection</code></p> <p>Implement a section that analyze precision results.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>BaseResult</code> <p>The data structure containing the results.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.section import BinaryPrecisionSection\n&gt;&gt;&gt; from arkas.result import BinaryPrecisionResult\n&gt;&gt;&gt; section = BinaryPrecisionSection(\n...     result=BinaryPrecisionResult(\n...         y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n...     )\n... )\n&gt;&gt;&gt; section\nBinaryPrecisionSection(\n  (result): BinaryPrecisionResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n)\n&gt;&gt;&gt; section.generate_html_body()\n</code></pre>"},{"location":"refs/section/#arkas.section.ContentSection","title":"arkas.section.ContentSection","text":"<p>               Bases: <code>BaseSection</code></p> <p>Implement a section that generates the given custom content.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content to use in the HTML code.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.section import ContentSection\n&gt;&gt;&gt; section = ContentSection(content=\"meow\")\n&gt;&gt;&gt; section\nContentSection()\n&gt;&gt;&gt; section.generate_html_body()\n</code></pre>"},{"location":"refs/section/#arkas.section.ResultSection","title":"arkas.section.ResultSection","text":"<p>               Bases: <code>BaseSection</code></p> <p>Implement a section that show the results in a HTML format.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>BaseResult</code> <p>The data structure containing the results.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.section import ResultSection\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; section = ResultSection(\n...     result=AccuracyResult(\n...         y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n...     )\n... )\n&gt;&gt;&gt; section\nResultSection(\n  (result): AccuracyResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n)\n&gt;&gt;&gt; section.generate_html_body()\n</code></pre>"},{"location":"refs/state/","title":"arkas.state","text":""},{"location":"refs/state/#arkas.state","title":"arkas.state","text":"<p>Contain states.</p>"},{"location":"refs/state/#arkas.state.AccuracyState","title":"arkas.state.AccuracyState","text":"<p>               Bases: <code>BaseState</code></p> <p>Implement the accuracy state.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_true_name</code> <code>str</code> <p>The name associated to the ground truth target labels.</p> required <code>y_pred_name</code> <code>str</code> <p>The name associated to the predicted labels.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; state = AccuracyState(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n&gt;&gt;&gt; state\nAccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n</code></pre>"},{"location":"refs/state/#arkas.state.BaseState","title":"arkas.state.BaseState","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement a state.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; state = AccuracyState(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n&gt;&gt;&gt; state\nAccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred')\n</code></pre>"},{"location":"refs/state/#arkas.state.BaseState.clone","title":"arkas.state.BaseState.clone  <code>abstractmethod</code>","text":"<pre><code>clone(deep: bool = True) -&gt; Self\n</code></pre> <p>Return a copy of the state.</p> <p>Parameters:</p> Name Type Description Default <code>deep</code> <code>bool</code> <p>If <code>True</code>, it returns a deep copy of the state, otherwise it returns a shallow copy.</p> <code>True</code> <p>Returns:</p> Type Description <code>Self</code> <p>A copy of the state.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; state = AccuracyState(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n... cloned_state = state.clone()\n</code></pre>"},{"location":"refs/state/#arkas.state.BaseState.equal","title":"arkas.state.BaseState.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two states are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other state to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two states are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; state1 = AccuracyState(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n&gt;&gt;&gt; state2 = AccuracyState(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n&gt;&gt;&gt; state3 = AccuracyState(\n...     y_true=np.array([1, 0, 0, 0, 0]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n&gt;&gt;&gt; state1.equal(state2)\nTrue\n&gt;&gt;&gt; state1.equal(state3)\nFalse\n</code></pre>"},{"location":"refs/utils/","title":"arkas.utils","text":""},{"location":"refs/utils/#arkas.utils","title":"arkas.utils","text":"<p>Contain utility functions.</p>"},{"location":"refs/utils/#arkas.utils.factory","title":"arkas.utils.factory","text":"<p>Contain a function to instantiate an object from its configuration.</p>"},{"location":"refs/utils/#arkas.utils.factory.setup_object","title":"arkas.utils.factory.setup_object","text":"<pre><code>setup_object(obj_or_config: T | dict) -&gt; T\n</code></pre> <p>Set up an object from its configuration.</p> <p>Parameters:</p> Name Type Description Default <code>obj_or_config</code> <code>T | dict</code> <p>The object or its configuration.</p> required <p>Returns:</p> Type Description <code>T</code> <p>The instantiated object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.factory import setup_object\n&gt;&gt;&gt; obj = setup_object({\"_target_\": \"collections.deque\", \"iterable\": [1, 2, 1, 3]})\n&gt;&gt;&gt; obj\ndeque([1, 2, 1, 3])\n&gt;&gt;&gt; setup_object(obj)  # Do nothing because the object is already instantiated\ndeque([1, 2, 1, 3])\n</code></pre>"},{"location":"refs/utils/#arkas.utils.figure","title":"arkas.utils.figure","text":"<p>Contain utility functions to manage matplotlib figures.</p>"},{"location":"refs/utils/#arkas.utils.figure.figure2html","title":"arkas.utils.figure.figure2html","text":"<pre><code>figure2html(\n    fig: Figure | None,\n    reactive: bool = True,\n    close_fig: bool = False,\n) -&gt; str\n</code></pre> <p>Convert a matplotlib figure to a string that can be used in a HTML file.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Figure | None</code> <p>The figure to convert.</p> required <code>reactive</code> <code>bool</code> <p>If <code>True</code>, the generated is configured to be reactive to the screen size.</p> <code>True</code> <code>close_fig</code> <code>bool</code> <p>If <code>True</code>, the figure is closed after it is converted to HTML format.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The converted figure to a string.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.utils.figure import figure2html\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; string = figure2html(fig)\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports","title":"arkas.utils.imports","text":"<p>Implement some utility functions to manage optional dependencies.</p>"},{"location":"refs/utils/#arkas.utils.imports.check_colorlog","title":"arkas.utils.imports.check_colorlog","text":"<pre><code>check_colorlog() -&gt; None\n</code></pre> <p>Check if the <code>colorlog</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>colorlog</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_colorlog\n&gt;&gt;&gt; check_colorlog()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_hya","title":"arkas.utils.imports.check_hya","text":"<pre><code>check_hya() -&gt; None\n</code></pre> <p>Check if the <code>hya</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>hya</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_hya\n&gt;&gt;&gt; check_hya()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_hydra","title":"arkas.utils.imports.check_hydra","text":"<pre><code>check_hydra() -&gt; None\n</code></pre> <p>Check if the <code>hydra</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>hydra</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_hydra\n&gt;&gt;&gt; check_hydra()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_markdown","title":"arkas.utils.imports.check_markdown","text":"<pre><code>check_markdown() -&gt; None\n</code></pre> <p>Check if the <code>markdown</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>markdown</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_markdown\n&gt;&gt;&gt; check_markdown()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_omegaconf","title":"arkas.utils.imports.check_omegaconf","text":"<pre><code>check_omegaconf() -&gt; None\n</code></pre> <p>Check if the <code>omegaconf</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>omegaconf</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_omegaconf\n&gt;&gt;&gt; check_omegaconf()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_scipy","title":"arkas.utils.imports.check_scipy","text":"<pre><code>check_scipy() -&gt; None\n</code></pre> <p>Check if the <code>scipy</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>scipy</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_scipy\n&gt;&gt;&gt; check_scipy()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.colorlog_available","title":"arkas.utils.imports.colorlog_available","text":"<pre><code>colorlog_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>colorlog</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>colorlog</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import colorlog_available\n&gt;&gt;&gt; @colorlog_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.hya_available","title":"arkas.utils.imports.hya_available","text":"<pre><code>hya_available(fn: Callable[..., Any]) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>hya</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>hya</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import hya_available\n&gt;&gt;&gt; @hya_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.hydra_available","title":"arkas.utils.imports.hydra_available","text":"<pre><code>hydra_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>hydra</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>hydra</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import hydra_available\n&gt;&gt;&gt; @hydra_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_colorlog_available","title":"arkas.utils.imports.is_colorlog_available","text":"<pre><code>is_colorlog_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>colorlog</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>colorlog</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_colorlog_available\n&gt;&gt;&gt; is_colorlog_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_hya_available","title":"arkas.utils.imports.is_hya_available","text":"<pre><code>is_hya_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>hya</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>hya</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_hya_available\n&gt;&gt;&gt; is_hya_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_hydra_available","title":"arkas.utils.imports.is_hydra_available","text":"<pre><code>is_hydra_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>hydra</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>hydra</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_hydra_available\n&gt;&gt;&gt; is_hydra_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_markdown_available","title":"arkas.utils.imports.is_markdown_available","text":"<pre><code>is_markdown_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>markdown</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>markdown</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_markdown_available\n&gt;&gt;&gt; is_markdown_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_omegaconf_available","title":"arkas.utils.imports.is_omegaconf_available","text":"<pre><code>is_omegaconf_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>omegaconf</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>omegaconf</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_omegaconf_available\n&gt;&gt;&gt; is_omegaconf_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_scipy_available","title":"arkas.utils.imports.is_scipy_available","text":"<pre><code>is_scipy_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>scipy</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>scipy</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_scipy_available\n&gt;&gt;&gt; is_scipy_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.markdown_available","title":"arkas.utils.imports.markdown_available","text":"<pre><code>markdown_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>markdown</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>markdown</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import markdown_available\n&gt;&gt;&gt; @markdown_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.omegaconf_available","title":"arkas.utils.imports.omegaconf_available","text":"<pre><code>omegaconf_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>omegaconf</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>omegaconf</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import omegaconf_available\n&gt;&gt;&gt; @omegaconf_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.scipy_available","title":"arkas.utils.imports.scipy_available","text":"<pre><code>scipy_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>scipy</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>scipy</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import scipy_available\n&gt;&gt;&gt; @scipy_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.text","title":"arkas.utils.text","text":"<p>Contain text utility functions.</p>"},{"location":"refs/utils/#arkas.utils.text.markdown_to_html","title":"arkas.utils.text.markdown_to_html","text":"<pre><code>markdown_to_html(\n    text: str, ignore_error: bool = False\n) -&gt; str\n</code></pre> <p>Convert a markdown text to HTML text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The markdown text to convert.</p> required <code>ignore_error</code> <code>bool</code> <p>If <code>False</code>, an error is raised if <code>markdown</code> is not installed, otherwise the input text is returned.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The converted text if <code>markdown</code> is installed, otherwise the input text.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.text import markdown_to_html\n&gt;&gt;&gt; out = markdown_to_html(\"- a\\n- b\\n- c\")\n&gt;&gt;&gt; print(out)\n&lt;ul&gt;\n&lt;li&gt;a&lt;/li&gt;\n&lt;li&gt;b&lt;/li&gt;\n&lt;li&gt;c&lt;/li&gt;\n&lt;/ul&gt;\n</code></pre>"}]}