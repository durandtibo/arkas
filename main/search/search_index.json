{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#overview","title":"Overview","text":"<p>TODO</p>"},{"location":"#motivation","title":"Motivation","text":"<p>TODO</p>"},{"location":"#api-stability","title":"API stability","text":"<p> While <code>arkas</code> is in development stage, no API is guaranteed to be stable from one release to the next. In fact, it is very likely that the API will change multiple times before a stable 1.0.0 release. In practice, this means that upgrading <code>arkas</code> to a new version will possibly break any code that was using the old version of <code>arkas</code>.</p>"},{"location":"#license","title":"License","text":"<p><code>arkas</code> is licensed under BSD 3-Clause \"New\" or \"Revised\" license available in LICENSE file.</p>"},{"location":"get_started/","title":"Get Started","text":"<p>It is highly recommended to install in a virtual environment to keep your system in order.</p>"},{"location":"get_started/#installing-with-pip-recommended","title":"Installing with <code>pip</code> (recommended)","text":"<p>The following command installs the latest version of the library:</p> <pre><code>pip install arkas\n</code></pre> <p>To make the package as slim as possible, only the packages required to use <code>arkas</code> are installed. It is possible to install all the optional dependencies by running the following command:</p> <pre><code>pip install 'arkas[all]'\n</code></pre> <p>This command also installed NumPy and PyTorch. It is also possible to install the optional packages manually or to select the packages to install. In the following example, only NumPy is installed:</p> <pre><code>pip install arkas numpy\n</code></pre>"},{"location":"get_started/#installing-from-source","title":"Installing from source","text":"<p>To install <code>arkas</code> from source, you can follow the steps below. First, you will need to install <code>poetry</code>. <code>poetry</code> is used to manage and install the dependencies. If <code>poetry</code> is already installed on your machine, you can skip this step. There are several ways to install <code>poetry</code> so you can use the one that you prefer. You can check the <code>poetry</code> installation by running the following command:</p> <pre><code>poetry --version\n</code></pre> <p>Then, you can clone the git repository:</p> <pre><code>git clone git@github.com:durandtibo/arkas.git\n</code></pre> <p>It is recommended to create a Python 3.8+ virtual environment. This step is optional so you can skip it. To create a virtual environment, you can use the following command:</p> <pre><code>make conda\n</code></pre> <p>It automatically creates a conda virtual environment. When the virtual environment is created, you can activate it with the following command:</p> <pre><code>conda activate arkas\n</code></pre> <p>This example uses <code>conda</code> to create a virtual environment, but you can use other tools or configurations. Then, you should install the required package to use <code>arkas</code> with the following command:</p> <pre><code>make install\n</code></pre> <p>This command will install all the required packages. You can also use this command to update the required packages. This command will check if there is a more recent package available and will install it. Finally, you can test the installation with the following command:</p> <pre><code>make unit-test-cov\n</code></pre>"},{"location":"refs/analyzer/","title":"arkas.analyzer","text":""},{"location":"refs/analyzer/#arkas.analyzer","title":"arkas.analyzer","text":"<p>Contain DataFrame analyzers.</p>"},{"location":"refs/analyzer/#arkas.analyzer.AccuracyAnalyzer","title":"arkas.analyzer.AccuracyAnalyzer","text":"<p>               Bases: <code>BaseTruePredAnalyzer</code></p> <p>Implement the accuracy analyzer.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; analyzer = AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; analyzer\nAccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n&gt;&gt;&gt; frame = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nAccuracyOutput(\n  (state): AccuracyState(y_true=(6,), y_pred=(6,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BalancedAccuracyAnalyzer","title":"arkas.analyzer.BalancedAccuracyAnalyzer","text":"<p>               Bases: <code>BaseTruePredAnalyzer</code></p> <p>Implement the balanced accuracy analyzer.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import BalancedAccuracyAnalyzer\n&gt;&gt;&gt; analyzer = BalancedAccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; analyzer\nBalancedAccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n&gt;&gt;&gt; frame = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nBalancedAccuracyOutput(\n  (state): AccuracyState(y_true=(6,), y_pred=(6,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BaseAnalyzer","title":"arkas.analyzer.BaseAnalyzer","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to analyze a DataFrame.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; analyzer = AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; analyzer\nAccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; output = analyzer.analyze(data)\n&gt;&gt;&gt; output\nAccuracyOutput(\n  (state): AccuracyState(y_true=(6,), y_pred=(6,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BaseAnalyzer.analyze","title":"arkas.analyzer.BaseAnalyzer.analyze  <code>abstractmethod</code>","text":"<pre><code>analyze(frame: DataFrame, lazy: bool = True) -&gt; BaseOutput\n</code></pre> <p>Analyze the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The DataFrame to analyze.</p> required <code>lazy</code> <code>bool</code> <p>If <code>True</code>, it forces the computation of the output, otherwise it returns an output object that contains the logic.</p> <code>True</code> <p>Returns:</p> Type Description <code>BaseOutput</code> <p>The generated output.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; analyzer = AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; output = analyzer.analyze(data)\n&gt;&gt;&gt; output\nAccuracyOutput(\n  (state): AccuracyState(y_true=(6,), y_pred=(6,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BaseInNLazyAnalyzer","title":"arkas.analyzer.BaseInNLazyAnalyzer","text":"<p>               Bases: <code>BaseAnalyzer</code></p> <p>Define a base class to implement analyzers that analyze DataFrames by using multiple input columns.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str] | None</code> <p>The columns to analyze. If <code>None</code>, it analyzes all the columns.</p> <code>None</code> <code>exclude_columns</code> <code>Sequence[str]</code> <p>The columns to exclude from the input <code>columns</code>. If any column is not found, it will be ignored during the filtering process.</p> <code>()</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import ColumnCooccurrenceAnalyzer\n&gt;&gt;&gt; analyzer = ColumnCooccurrenceAnalyzer()\n&gt;&gt;&gt; analyzer\nColumnCooccurrenceAnalyzer(columns=None, exclude_columns=(), missing_policy='raise', ignore_self=False, figure_config=None)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [0, 0, 0, 0, 1, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nColumnCooccurrenceOutput(\n  (state): ColumnCooccurrenceState(matrix=(3, 3), figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BaseInNLazyAnalyzer.find_columns","title":"arkas.analyzer.BaseInNLazyAnalyzer.find_columns","text":"<pre><code>find_columns(frame: DataFrame) -&gt; tuple[str, ...]\n</code></pre> <p>Find the columns to transform.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The input DataFrame. Sometimes the columns to transform are found by analyzing the input DataFrame.</p> required <p>Returns:</p> Type Description <code>tuple[str, ...]</code> <p>The columns to transform.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import ColumnCooccurrenceAnalyzer\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [0, 0, 0, 0, 1, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; analyzer = ColumnCooccurrenceAnalyzer(columns=[\"col2\", \"col3\"])\n&gt;&gt;&gt; analyzer.find_columns(frame)\n('col2', 'col3')\n&gt;&gt;&gt; analyzer = ColumnCooccurrenceAnalyzer()\n&gt;&gt;&gt; analyzer.find_columns(frame)\n('col1', 'col2', 'col3')\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BaseInNLazyAnalyzer.find_common_columns","title":"arkas.analyzer.BaseInNLazyAnalyzer.find_common_columns","text":"<pre><code>find_common_columns(frame: DataFrame) -&gt; tuple[str, ...]\n</code></pre> <p>Find the common columns between the DataFrame columns and the input columns.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The input DataFrame. Sometimes the columns to transform are found by analyzing the input DataFrame.</p> required <p>Returns:</p> Type Description <code>tuple[str, ...]</code> <p>The common columns.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import ColumnCooccurrenceAnalyzer\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [0, 0, 0, 0, 1, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; analyzer = ColumnCooccurrenceAnalyzer(columns=[\"col2\", \"col3\", \"col5\"])\n&gt;&gt;&gt; analyzer.find_common_columns(frame)\n('col2', 'col3')\n&gt;&gt;&gt; analyzer = ColumnCooccurrenceAnalyzer()\n&gt;&gt;&gt; analyzer.find_common_columns(frame)\n('col1', 'col2', 'col3')\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BaseInNLazyAnalyzer.find_missing_columns","title":"arkas.analyzer.BaseInNLazyAnalyzer.find_missing_columns","text":"<pre><code>find_missing_columns(frame: DataFrame) -&gt; tuple[str, ...]\n</code></pre> <p>Find the missing columns.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The input DataFrame. Sometimes the columns to transform are found by analyzing the input DataFrame.</p> required <p>Returns:</p> Type Description <code>tuple[str, ...]</code> <p>The missing columns.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import ColumnCooccurrenceAnalyzer\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [0, 0, 0, 0, 1, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; analyzer = ColumnCooccurrenceAnalyzer(columns=[\"col2\", \"col3\", \"col5\"])\n&gt;&gt;&gt; analyzer.find_missing_columns(frame)\n('col5',)\n&gt;&gt;&gt; analyzer = ColumnCooccurrenceAnalyzer()\n&gt;&gt;&gt; analyzer.find_missing_columns(frame)\n()\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BaseInNLazyAnalyzer.get_args","title":"arkas.analyzer.BaseInNLazyAnalyzer.get_args","text":"<pre><code>get_args() -&gt; dict\n</code></pre> <p>Get the arguments of the analyzer.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The arguments.</p>"},{"location":"refs/analyzer/#arkas.analyzer.BaseLazyAnalyzer","title":"arkas.analyzer.BaseLazyAnalyzer","text":"<p>               Bases: <code>BaseAnalyzer</code></p> <p>Define a base class to implement a lazy analyzer.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import SummaryAnalyzer\n&gt;&gt;&gt; analyzer = SummaryAnalyzer()\n&gt;&gt;&gt; analyzer\nSummaryAnalyzer(top=5, sort=False)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 0, 1],\n...         \"col2\": [1, 0, 1, 0],\n...         \"col3\": [1, 1, 1, 1],\n...     },\n...     schema={\"col1\": pl.Int64, \"col2\": pl.Int64, \"col3\": pl.Int64},\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nSummaryOutput(shape=(4, 3), top=5)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.BaseTruePredAnalyzer","title":"arkas.analyzer.BaseTruePredAnalyzer","text":"<p>               Bases: <code>BaseAnalyzer</code></p> <p>Define a base class to implement <code>polars.DataFrame</code> analyzer that takes two input columns: <code>y_true</code> and <code>y_pred</code>.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> required <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> required"},{"location":"refs/analyzer/#arkas.analyzer.ColumnCooccurrenceAnalyzer","title":"arkas.analyzer.ColumnCooccurrenceAnalyzer","text":"<p>               Bases: <code>BaseInNLazyAnalyzer</code></p> <p>Implement a pairwise column co-occurrence analyzer.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str] | None</code> <p>The columns to analyze. If <code>None</code>, it analyzes all the columns.</p> <code>None</code> <code>exclude_columns</code> <code>Sequence[str]</code> <p>The columns to exclude from the input <code>columns</code>. If any column is not found, it will be ignored during the filtering process.</p> <code>()</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <code>ignore_self</code> <code>bool</code> <p>If <code>True</code>, the diagonal of the co-occurrence matrix (a.k.a. self-co-occurrence) is set to 0.</p> <code>False</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>The figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import ColumnCooccurrenceAnalyzer\n&gt;&gt;&gt; analyzer = ColumnCooccurrenceAnalyzer()\n&gt;&gt;&gt; analyzer\nColumnCooccurrenceAnalyzer(columns=None, exclude_columns=(), missing_policy='raise', ignore_self=False, figure_config=None)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [0, 0, 0, 0, 1, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nColumnCooccurrenceOutput(\n  (state): ColumnCooccurrenceState(matrix=(3, 3), figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.ColumnCorrelationAnalyzer","title":"arkas.analyzer.ColumnCorrelationAnalyzer","text":"<p>               Bases: <code>BaseInNLazyAnalyzer</code></p> <p>Implement an analyzer to analyze the correlation between numeric columns.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str] | None</code> <p>The columns to analyze. If <code>None</code>, it analyzes all the columns.</p> <code>None</code> <code>exclude_columns</code> <code>Sequence[str]</code> <p>The columns to exclude from the input <code>columns</code>. If any column is not found, it will be ignored during the filtering process.</p> <code>()</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import ColumnCorrelationAnalyzer\n&gt;&gt;&gt; analyzer = ColumnCorrelationAnalyzer(target_column=\"col3\")\n&gt;&gt;&gt; analyzer\nColumnCorrelationAnalyzer(target_column='col3', columns=None, exclude_columns=(), missing_policy='raise')\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...         \"col2\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...     },\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nColumnCorrelationOutput(\n  (state): TargetDataFrameState(dataframe=(7, 3), target_column='col3', nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.ContentAnalyzer","title":"arkas.analyzer.ContentAnalyzer","text":"<p>               Bases: <code>BaseLazyAnalyzer</code></p> <p>Implement an analyzer that generates an output with the given custom content.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content to use in the HTML code.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import ContentAnalyzer\n&gt;&gt;&gt; analyzer = ContentAnalyzer(content=\"meow\")\n&gt;&gt;&gt; analyzer\nContentAnalyzer()\n&gt;&gt;&gt; frame = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nContentOutput(\n  (content): ContentGenerator()\n  (evaluator): Evaluator(count=0)\n  (plotter): Plotter(count=0)\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.ContinuousColumnAnalyzer","title":"arkas.analyzer.ContinuousColumnAnalyzer","text":"<p>               Bases: <code>BaseLazyAnalyzer</code></p> <p>Implement an analyzer that analyzes a column with continuous values.</p> <p>Parameters:</p> Name Type Description Default <code>column</code> <code>str</code> <p>The column to analyze.</p> required <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>The figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import ContinuousColumnAnalyzer\n&gt;&gt;&gt; analyzer = ContinuousColumnAnalyzer(column=\"col1\")\n&gt;&gt;&gt; analyzer\nContinuousColumnAnalyzer(column='col1', figure_config=None)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 0, 1],\n...         \"col2\": [1, 0, 1, 0],\n...         \"col3\": [1, 1, 1, 1],\n...     },\n...     schema={\"col1\": pl.Int64, \"col2\": pl.Int64, \"col3\": pl.Int64},\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nContinuousSeriesOutput(\n  (state): SeriesState(name='col1', values=(4,), figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.CorrelationAnalyzer","title":"arkas.analyzer.CorrelationAnalyzer","text":"<p>               Bases: <code>BaseLazyAnalyzer</code></p> <p>Implement an analyzer that analyzes the correlation between two columns.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>str</code> <p>The first column.</p> required <code>y</code> <code>str</code> <p>The second column.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>The figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import CorrelationAnalyzer\n&gt;&gt;&gt; analyzer = CorrelationAnalyzer(x=\"col1\", y=\"col2\")\n&gt;&gt;&gt; analyzer\nCorrelationAnalyzer(x='col1', y='col2', drop_nulls=True, missing_policy='raise', nan_policy='propagate', figure_config=None)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...         \"col2\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...     },\n...     schema={\"col1\": pl.Float64, \"col2\": pl.Float64, \"col3\": pl.Float64},\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nCorrelationOutput(\n  (state): DataFrameState(dataframe=(7, 2), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.MappingAnalyzer","title":"arkas.analyzer.MappingAnalyzer","text":"<p>               Bases: <code>BaseAnalyzer</code></p> <p>Implement an analyzer that processes a mapping of analyzers.</p> <p>Parameters:</p> Name Type Description Default <code>analyzers</code> <code>Mapping[str, BaseAnalyzer]</code> <p>The mapping of analyzers.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import (\n...     MappingAnalyzer,\n...     AccuracyAnalyzer,\n...     BalancedAccuracyAnalyzer,\n... )\n&gt;&gt;&gt; analyzer = MappingAnalyzer(\n...     {\n...         \"one\": AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\"),\n...         \"two\": BalancedAccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\"),\n...     }\n... )\n&gt;&gt;&gt; analyzer\nMappingAnalyzer(\n  (one): AccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n  (two): BalancedAccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n)\n&gt;&gt;&gt; frame = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nOutputDict(count=2)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.NullValueAnalyzer","title":"arkas.analyzer.NullValueAnalyzer","text":"<p>               Bases: <code>BaseInNLazyAnalyzer</code></p> <p>Implement an analyzer that plots the content of each column.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str] | None</code> <p>The columns to analyze. If <code>None</code>, it analyzes all the columns.</p> <code>None</code> <code>exclude_columns</code> <code>Sequence[str]</code> <p>The columns to exclude from the input <code>columns</code>. If any column is not found, it will be ignored during the filtering process.</p> <code>()</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>The figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import NullValueAnalyzer\n&gt;&gt;&gt; analyzer = NullValueAnalyzer()\n&gt;&gt;&gt; analyzer\nNullValueAnalyzer(columns=None, exclude_columns=(), missing_policy='raise', figure_config=None)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, None],\n...         \"col2\": [0, 1, None, None, 0, 1, 0],\n...         \"col3\": [None, 0, 0, 0, None, 1, None],\n...     }\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nNullValueOutput(\n  (state): NullValueState(num_columns=3, figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.NumericSummaryAnalyzer","title":"arkas.analyzer.NumericSummaryAnalyzer","text":"<p>               Bases: <code>BaseInNLazyAnalyzer</code></p> <p>Implement an analyzer to show a summary of the numeric columns of a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str] | None</code> <p>The columns to analyze. If <code>None</code>, it analyzes all the columns.</p> <code>None</code> <code>exclude_columns</code> <code>Sequence[str]</code> <p>The columns to exclude from the input <code>columns</code>. If any column is not found, it will be ignored during the filtering process.</p> <code>()</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import NumericSummaryAnalyzer\n&gt;&gt;&gt; analyzer = NumericSummaryAnalyzer()\n&gt;&gt;&gt; analyzer\nNumericSummaryAnalyzer(columns=None, exclude_columns=(), missing_policy='raise')\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...     },\n...     schema={\"col1\": pl.Int64, \"col2\": pl.Int32, \"col3\": pl.Float64},\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nNumericSummaryOutput(\n  (state): DataFrameState(dataframe=(7, 3), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.PlotColumnAnalyzer","title":"arkas.analyzer.PlotColumnAnalyzer","text":"<p>               Bases: <code>BaseInNLazyAnalyzer</code></p> <p>Implement an analyzer that plots the content of each column.</p> <p>Parameters:</p> Name Type Description Default <code>columns</code> <code>Sequence[str] | None</code> <p>The columns to analyze. If <code>None</code>, it analyzes all the columns.</p> <code>None</code> <code>exclude_columns</code> <code>Sequence[str]</code> <p>The columns to exclude from the input <code>columns</code>. If any column is not found, it will be ignored during the filtering process.</p> <code>()</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>The figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import PlotColumnAnalyzer\n&gt;&gt;&gt; analyzer = PlotColumnAnalyzer()\n&gt;&gt;&gt; analyzer\nPlotColumnAnalyzer(columns=None, exclude_columns=(), missing_policy='raise', figure_config=None)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 0, 1],\n...         \"col2\": [1, 0, 1, 0],\n...         \"col3\": [1, 1, 1, 1],\n...     },\n...     schema={\"col1\": pl.Int64, \"col2\": pl.Int64, \"col3\": pl.Int64},\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nPlotColumnOutput(\n  (state): DataFrameState(dataframe=(4, 3), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.ScatterColumnAnalyzer","title":"arkas.analyzer.ScatterColumnAnalyzer","text":"<p>               Bases: <code>BaseLazyAnalyzer</code></p> <p>Implement an analyzer that plots the content of each column.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>str</code> <p>The x-axis data column.</p> required <code>y</code> <code>str</code> <p>The y-axis data column.</p> required <code>color</code> <code>str | None</code> <p>An optional color axis data column.</p> <code>None</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>The figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import ScatterColumnAnalyzer\n&gt;&gt;&gt; analyzer = ScatterColumnAnalyzer(x=\"col1\", y=\"col2\")\n&gt;&gt;&gt; analyzer\nScatterColumnAnalyzer(x='col1', y='col2', color=None, figure_config=None)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 0, 1],\n...         \"col2\": [1, 0, 1, 0],\n...         \"col3\": [1, 1, 1, 1],\n...     },\n...     schema={\"col1\": pl.Int64, \"col2\": pl.Int64, \"col3\": pl.Int64},\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nScatterColumnOutput(\n  (state): ScatterDataFrameState(dataframe=(4, 2), x='col1', y='col2', color=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.SummaryAnalyzer","title":"arkas.analyzer.SummaryAnalyzer","text":"<p>               Bases: <code>BaseLazyAnalyzer</code></p> <p>Implement an analyzer to show a summary of the DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>top</code> <code>int</code> <p>The number of most frequent values to show.</p> <code>5</code> <code>sort</code> <code>bool</code> <p>If <code>True</code>, sort the columns by alphabetical order.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import SummaryAnalyzer\n&gt;&gt;&gt; analyzer = SummaryAnalyzer()\n&gt;&gt;&gt; analyzer\nSummaryAnalyzer(top=5, sort=False)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 0, 1],\n...         \"col2\": [1, 0, 1, 0],\n...         \"col3\": [1, 1, 1, 1],\n...     },\n...     schema={\"col1\": pl.Int64, \"col2\": pl.Int64, \"col3\": pl.Int64},\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nSummaryOutput(shape=(4, 3), top=5)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.TemporalNullValueAnalyzer","title":"arkas.analyzer.TemporalNullValueAnalyzer","text":"<p>               Bases: <code>BaseInNLazyAnalyzer</code></p> <p>Implement an analyzer that analyzes the number of null values in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>temporal_column</code> <code>str</code> <p>The temporal column in the DataFrame.</p> required <code>period</code> <code>str</code> <p>The temporal period e.g. monthly or daily.</p> required <code>columns</code> <code>Sequence[str] | None</code> <p>The columns to analyze. If <code>None</code>, it analyzes all the columns.</p> <code>None</code> <code>exclude_columns</code> <code>Sequence[str]</code> <p>The columns to exclude from the input <code>columns</code>. If any column is not found, it will be ignored during the filtering process.</p> <code>()</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>The figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import TemporalNullValueAnalyzer\n&gt;&gt;&gt; analyzer = TemporalNullValueAnalyzer(temporal_column=\"datetime\", period=\"1d\")\n&gt;&gt;&gt; analyzer\nTemporalNullValueAnalyzer(columns=None, exclude_columns=(), missing_policy='raise', temporal_column='datetime', period='1d', figure_config=None)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0],\n...         \"col2\": [0, 1, 0, 1],\n...         \"col3\": [1, 0, 0, 0],\n...         \"datetime\": [\n...             datetime(year=2020, month=1, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=2, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=3, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=4, day=3, tzinfo=timezone.utc),\n...         ],\n...     },\n...     schema={\n...         \"col1\": pl.Int64,\n...         \"col2\": pl.Int64,\n...         \"col3\": pl.Int64,\n...         \"datetime\": pl.Datetime(time_unit=\"us\", time_zone=\"UTC\"),\n...     },\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nTemporalNullValueOutput(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period='1d', nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.TemporalPlotColumnAnalyzer","title":"arkas.analyzer.TemporalPlotColumnAnalyzer","text":"<p>               Bases: <code>BaseInNLazyAnalyzer</code></p> <p>Implement an analyzer that plots the content of each column.</p> <p>Parameters:</p> Name Type Description Default <code>temporal_column</code> <code>str</code> <p>The temporal column in the DataFrame.</p> required <code>period</code> <code>str | None</code> <p>An optional temporal period e.g. monthly or daily.</p> <code>None</code> <code>columns</code> <code>Sequence[str] | None</code> <p>The columns to analyze. If <code>None</code>, it analyzes all the columns.</p> <code>None</code> <code>exclude_columns</code> <code>Sequence[str]</code> <p>The columns to exclude from the input <code>columns</code>. If any column is not found, it will be ignored during the filtering process.</p> <code>()</code> <code>missing_policy</code> <code>str</code> <p>The policy on how to handle missing columns. The following options are available: <code>'ignore'</code>, <code>'warn'</code>, and <code>'raise'</code>. If <code>'raise'</code>, an exception is raised if at least one column is missing. If <code>'warn'</code>, a warning is raised if at least one column is missing and the missing columns are ignored. If <code>'ignore'</code>, the missing columns are ignored and no warning message appears.</p> <code>'raise'</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>The figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import TemporalPlotColumnAnalyzer\n&gt;&gt;&gt; analyzer = TemporalPlotColumnAnalyzer(temporal_column=\"datetime\")\n&gt;&gt;&gt; analyzer\nTemporalPlotColumnAnalyzer(columns=None, exclude_columns=(), missing_policy='raise', temporal_column='datetime', period=None, figure_config=None)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0],\n...         \"col2\": [0, 1, 0, 1],\n...         \"col3\": [1, 0, 0, 0],\n...         \"datetime\": [\n...             datetime(year=2020, month=1, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=2, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=3, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=4, day=3, tzinfo=timezone.utc),\n...         ],\n...     },\n...     schema={\n...         \"col1\": pl.Int64,\n...         \"col2\": pl.Int64,\n...         \"col3\": pl.Int64,\n...         \"datetime\": pl.Datetime(time_unit=\"us\", time_zone=\"UTC\"),\n...     },\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nTemporalPlotColumnOutput(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.TransformAnalyzer","title":"arkas.analyzer.TransformAnalyzer","text":"<p>               Bases: <code>BaseAnalyzer</code></p> <p>Implement an analyzer that transforms the data before to analyze them.</p> <p>Parameters:</p> Name Type Description Default <code>transformer</code> <code>BaseTransformer | dict</code> <p>The transformer or its configuration.</p> required <code>analyzer</code> <code>BaseAnalyzer | dict</code> <p>The analyzer or its configuration.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer, TransformAnalyzer\n&gt;&gt;&gt; from grizz.transformer import DropNullRow\n&gt;&gt;&gt; analyzer = TransformAnalyzer(\n...     transformer=DropNullRow(), analyzer=AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\")\n... )\n&gt;&gt;&gt; analyzer\nTransformAnalyzer(\n  (transformer): DropNullRowTransformer(columns=None, exclude_columns=(), missing_policy='raise')\n  (analyzer): AccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n)\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\"pred\": [3, 2, 0, 1, 0, 1, None], \"target\": [3, 2, 0, 1, 0, 1, None]}\n... )\n&gt;&gt;&gt; output = analyzer.analyze(frame)\n&gt;&gt;&gt; output\nAccuracyOutput(\n  (state): AccuracyState(y_true=(6,), y_pred=(6,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.is_analyzer_config","title":"arkas.analyzer.is_analyzer_config","text":"<pre><code>is_analyzer_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseAnalyzer</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseAnalyzer</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.analyzer import is_analyzer_config\n&gt;&gt;&gt; is_analyzer_config({\"_target_\": \"arkas.analyzer.AccuracyAnalyzer\"})\nTrue\n</code></pre>"},{"location":"refs/analyzer/#arkas.analyzer.setup_analyzer","title":"arkas.analyzer.setup_analyzer","text":"<pre><code>setup_analyzer(\n    analyzer: BaseAnalyzer | dict,\n) -&gt; BaseAnalyzer\n</code></pre> <p>Set up an analyzer.</p> <p>The analyzer is instantiated from its configuration by using the <code>BaseAnalyzer</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>analyzer</code> <code>BaseAnalyzer | dict</code> <p>An analyzer or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseAnalyzer</code> <p>An instantiated analyzer.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.analyzer import setup_analyzer\n&gt;&gt;&gt; analyzer = setup_analyzer(\n...     {\n...         \"_target_\": \"arkas.analyzer.AccuracyAnalyzer\",\n...         \"y_true\": \"target\",\n...         \"y_pred\": \"pred\",\n...     }\n... )\n&gt;&gt;&gt; analyzer\nAccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n</code></pre>"},{"location":"refs/content/","title":"arkas.content","text":""},{"location":"refs/content/#arkas.content","title":"arkas.content","text":"<p>Contain HTML content generators.</p>"},{"location":"refs/content/#arkas.content.AccuracyContentGenerator","title":"arkas.content.AccuracyContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a HTML content generator that analyzes accuracy performances.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AccuracyState</code> <p>The state containing the ground truth and predicted labels.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.content import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator\nAccuracyContentGenerator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.BalancedAccuracyContentGenerator","title":"arkas.content.BalancedAccuracyContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a HTML content generator that analyzes balanced accuracy performances.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AccuracyState</code> <p>The data structure containing the states.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.content import BalancedAccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator = BalancedAccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator\nBalancedAccuracyContentGenerator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.BaseContentGenerator","title":"arkas.content.BaseContentGenerator","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement a HTML Content Generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.content import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator\nAccuracyContentGenerator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.BaseContentGenerator.compute","title":"arkas.content.BaseContentGenerator.compute  <code>abstractmethod</code>","text":"<pre><code>compute() -&gt; BaseContentGenerator\n</code></pre> <p>Compute the content and return a new content generator.</p> <p>Returns:</p> Type Description <code>BaseContentGenerator</code> <p>A new content generator with the computed content.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.content import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator\nAccuracyContentGenerator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n&gt;&gt;&gt; generator2 = generator.compute()\n&gt;&gt;&gt; generator2\nContentGenerator()\n</code></pre>"},{"location":"refs/content/#arkas.content.BaseContentGenerator.equal","title":"arkas.content.BaseContentGenerator.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two content generators are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other content generator to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two content generators are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.content import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator1 = AccuracyContentGenerator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator2 = AccuracyContentGenerator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator3 = AccuracyContentGenerator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 0, 0]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator1.equal(generator2)\nTrue\n&gt;&gt;&gt; generator1.equal(generator3)\nFalse\n</code></pre>"},{"location":"refs/content/#arkas.content.BaseContentGenerator.generate_body","title":"arkas.content.BaseContentGenerator.generate_body  <code>abstractmethod</code>","text":"<pre><code>generate_body(\n    number: str = \"\",\n    tags: Sequence[str] = (),\n    depth: int = 0,\n) -&gt; str\n</code></pre> <p>Return the HTML body associated to the content.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>str</code> <p>The section number, if any.</p> <code>''</code> <code>tags</code> <code>Sequence[str]</code> <p>The tags associated to the content section, if any.</p> <code>()</code> <code>depth</code> <code>int</code> <p>The depth in the content section, if any.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p>The HTML body associated to the content section.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.content import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator.generate_body()\n</code></pre>"},{"location":"refs/content/#arkas.content.BaseContentGenerator.generate_toc","title":"arkas.content.BaseContentGenerator.generate_toc  <code>abstractmethod</code>","text":"<pre><code>generate_toc(\n    number: str = \"\",\n    tags: Sequence[str] = (),\n    depth: int = 0,\n    max_depth: int = 1,\n) -&gt; str\n</code></pre> <p>Return the HTML table of content (TOC) associated to the section.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>str</code> <p>The section number associated to the section, if any.</p> <code>''</code> <code>tags</code> <code>Sequence[str]</code> <p>The tags associated to the section, if any.</p> <code>()</code> <code>depth</code> <code>int</code> <p>The depth in the report, if any.</p> <code>0</code> <code>max_depth</code> <code>int</code> <p>The maximum depth to generate in the TOC.</p> <code>1</code> <p>Returns:</p> Type Description <code>str</code> <p>The HTML table of content associated to the section.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.content import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; generator.generate_toc()\n</code></pre>"},{"location":"refs/content/#arkas.content.ColumnCooccurrenceContentGenerator","title":"arkas.content.ColumnCooccurrenceContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a content generator that returns pairwise column co- occurrence.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>ColumnCooccurrenceState</code> <p>The state with the co-occurrence matrix.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.content import ColumnCooccurrenceContentGenerator\n&gt;&gt;&gt; from arkas.state import ColumnCooccurrenceState\n&gt;&gt;&gt; content = ColumnCooccurrenceContentGenerator(\n...     ColumnCooccurrenceState(matrix=np.ones((3, 3)), columns=[\"a\", \"b\", \"c\"])\n... )\n&gt;&gt;&gt; content\nColumnCooccurrenceContentGenerator(\n  (state): ColumnCooccurrenceState(matrix=(3, 3), figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.ColumnCorrelationContentGenerator","title":"arkas.content.ColumnCorrelationContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a content generator that analyzes the correlation between 1 target column and other columns.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>TargetDataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.content import ColumnCorrelationContentGenerator\n&gt;&gt;&gt; from arkas.state import TargetDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...         \"col2\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...     },\n... )\n&gt;&gt;&gt; content = ColumnCorrelationContentGenerator(\n...     TargetDataFrameState(frame, target_column=\"col3\")\n... )\n&gt;&gt;&gt; content\nColumnCorrelationContentGenerator(\n  (state): TargetDataFrameState(dataframe=(7, 3), target_column='col3', nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.ContentGenerator","title":"arkas.content.ContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a section that analyze accuracy states.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The HTML content.</p> <code>''</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.content import ContentGenerator\n&gt;&gt;&gt; generator = ContentGenerator(\"meow\")\n&gt;&gt;&gt; generator\nContentGenerator()\n&gt;&gt;&gt; generator.generate_content()\n'meow'\n</code></pre>"},{"location":"refs/content/#arkas.content.ContentGeneratorDict","title":"arkas.content.ContentGeneratorDict","text":"<p>               Bases: <code>BaseContentGenerator</code></p> <p>Implement a content generator that combines a mapping of content generators.</p> <p>Parameters:</p> Name Type Description Default <code>generators</code> <code>Mapping[str, BaseContentGenerator]</code> <p>The mapping of content generators.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.content import ContentGeneratorDict, ContentGenerator\n&gt;&gt;&gt; content = ContentGeneratorDict(\n...     {\n...         \"one\": ContentGenerator(),\n...         \"two\": ContentGenerator(\"meow\"),\n...     }\n... )\n&gt;&gt;&gt; content\nContentGeneratorDict(\n  (one): ContentGenerator()\n  (two): ContentGenerator()\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.ContinuousSeriesContentGenerator","title":"arkas.content.ContinuousSeriesContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a content generator that analyzes a Series with continuous values.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>SeriesState</code> <p>The state containing the Series to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.content import ContinuousSeriesContentGenerator\n&gt;&gt;&gt; from arkas.state import SeriesState\n&gt;&gt;&gt; content = ContinuousSeriesContentGenerator(\n...     SeriesState(pl.Series(\"col1\", [1, 2, 3, 4, 5, 6, 7]))\n... )\n&gt;&gt;&gt; content\nContinuousSeriesContentGenerator(\n  (state): SeriesState(name='col1', values=(7,), figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.CorrelationContentGenerator","title":"arkas.content.CorrelationContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a content generator that analyzes the correlation between two columns.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>DataFrameState</code> <p>The state containing the DataFrame to analyze. The DataFrame must have only 2 columns, which are the two columns to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.content import CorrelationContentGenerator\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...         \"col2\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0],\n...     },\n... )\n&gt;&gt;&gt; content = CorrelationContentGenerator(DataFrameState(frame))\n&gt;&gt;&gt; content\nCorrelationContentGenerator(\n  (state): DataFrameState(dataframe=(7, 2), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.NullValueContentGenerator","title":"arkas.content.NullValueContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a content generator that analyzes the number of null values per column.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>NullValueState</code> <p>The state containing the number of null values per column.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.content import NullValueContentGenerator\n&gt;&gt;&gt; from arkas.state import NullValueState\n&gt;&gt;&gt; content = NullValueContentGenerator(\n...     NullValueState(\n...         null_count=np.array([0, 1, 2]),\n...         total_count=np.array([5, 5, 5]),\n...         columns=[\"col1\", \"col2\", \"col3\"],\n...     )\n... )\n&gt;&gt;&gt; content\nNullValueContentGenerator(\n  (state): NullValueState(num_columns=3, figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.NumericSummaryContentGenerator","title":"arkas.content.NumericSummaryContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a content generator that summarizes the numeric columns of a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>DataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.content import NumericSummaryContentGenerator\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; dataframe = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...     }\n... )\n&gt;&gt;&gt; content = NumericSummaryContentGenerator(DataFrameState(dataframe))\n&gt;&gt;&gt; content\nNumericSummaryContentGenerator(\n  (state): DataFrameState(dataframe=(7, 3), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.PlotColumnContentGenerator","title":"arkas.content.PlotColumnContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a content generator that plots the content of each column.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>DataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.content import PlotColumnContentGenerator\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; dataframe = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [0, 0, 0, 0, 1, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; content = PlotColumnContentGenerator(DataFrameState(dataframe))\n&gt;&gt;&gt; content\nPlotColumnContentGenerator(\n  (state): DataFrameState(dataframe=(7, 3), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.ScatterColumnContentGenerator","title":"arkas.content.ScatterColumnContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a content generator that plots the content of each column.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>ScatterDataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.content import ScatterColumnContentGenerator\n&gt;&gt;&gt; from arkas.state import ScatterDataFrameState\n&gt;&gt;&gt; dataframe = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [0, 0, 0, 0, 1, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; content = ScatterColumnContentGenerator(\n...     ScatterDataFrameState(dataframe, x=\"col1\", y=\"col2\")\n... )\n&gt;&gt;&gt; content\nScatterColumnContentGenerator(\n  (state): ScatterDataFrameState(dataframe=(7, 3), x='col1', y='col2', color=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.SummaryContentGenerator","title":"arkas.content.SummaryContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a content generator that returns a summary of a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The DataFrame to analyze.</p> required <code>top</code> <code>int</code> <p>The number of most frequent values to show.</p> <code>5</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.content import SummaryContentGenerator\n&gt;&gt;&gt; content = SummaryContentGenerator(\n...     frame=pl.DataFrame(\n...         {\n...             \"col1\": [1.2, 4.2, 4.2, 2.2],\n...             \"col2\": [1, 1, 1, 1],\n...             \"col3\": [1, 2, 2, 2],\n...         },\n...         schema={\"col1\": pl.Float64, \"col2\": pl.Int64, \"col3\": pl.Int64},\n...     )\n... )\n&gt;&gt;&gt; content\nSummaryContentGenerator(shape=(4, 3), top=5)\n</code></pre>"},{"location":"refs/content/#arkas.content.SummaryContentGenerator.frame","title":"arkas.content.SummaryContentGenerator.frame  <code>property</code>","text":"<pre><code>frame: DataFrame\n</code></pre> <p>The DataFrame to analyze.</p>"},{"location":"refs/content/#arkas.content.TemporalNullValueContentGenerator","title":"arkas.content.TemporalNullValueContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a content generator that analyzes the temporal distribution of null values.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>TemporalDataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.content import TemporalNullValueContentGenerator\n&gt;&gt;&gt; from arkas.state import TemporalDataFrameState\n&gt;&gt;&gt; dataframe = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0],\n...         \"col2\": [0, 1, 0, 1],\n...         \"col3\": [1, 0, 0, 0],\n...         \"datetime\": [\n...             datetime(year=2020, month=1, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=2, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=3, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=4, day=3, tzinfo=timezone.utc),\n...         ],\n...     },\n...     schema={\n...         \"col1\": pl.Int64,\n...         \"col2\": pl.Int64,\n...         \"col3\": pl.Int64,\n...         \"datetime\": pl.Datetime(time_unit=\"us\", time_zone=\"UTC\"),\n...     },\n... )\n&gt;&gt;&gt; content = TemporalNullValueContentGenerator(\n...     TemporalDataFrameState(dataframe, temporal_column=\"datetime\")\n... )\n&gt;&gt;&gt; content\nTemporalNullValueContentGenerator(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/content/#arkas.content.TemporalPlotColumnContentGenerator","title":"arkas.content.TemporalPlotColumnContentGenerator","text":"<p>               Bases: <code>BaseSectionContentGenerator</code></p> <p>Implement a content generator that plots the content of each column.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>TemporalDataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.content import TemporalPlotColumnContentGenerator\n&gt;&gt;&gt; from arkas.state import TemporalDataFrameState\n&gt;&gt;&gt; dataframe = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0],\n...         \"col2\": [0, 1, 0, 1],\n...         \"col3\": [1, 0, 0, 0],\n...         \"datetime\": [\n...             datetime(year=2020, month=1, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=2, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=3, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=4, day=3, tzinfo=timezone.utc),\n...         ],\n...     },\n...     schema={\n...         \"col1\": pl.Int64,\n...         \"col2\": pl.Int64,\n...         \"col3\": pl.Int64,\n...         \"datetime\": pl.Datetime(time_unit=\"us\", time_zone=\"UTC\"),\n...     },\n... )\n&gt;&gt;&gt; content = TemporalPlotColumnContentGenerator(\n...     TemporalDataFrameState(dataframe, temporal_column=\"datetime\")\n... )\n&gt;&gt;&gt; content\nTemporalPlotColumnContentGenerator(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/evaluator/","title":"arkas.evaluator","text":""},{"location":"refs/evaluator/#arkas.evaluator","title":"arkas.evaluator","text":"<p>Contain evaluators.</p>"},{"location":"refs/evaluator/#arkas.evaluator.AccuracyEvaluator","title":"arkas.evaluator.AccuracyEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[AccuracyResult]</code></p> <p>Implement the accuracy evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.AveragePrecisionEvaluator","title":"arkas.evaluator.AveragePrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[AveragePrecisionResult]</code></p> <p>Implement the average precision evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, <code>'multilabel'</code>, and <code>'auto'</code>. If <code>'auto'</code>, it tries to automatically find the label type from the arrays' shape.</p> <code>'auto'</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_score</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AveragePrecisionEvaluator\n&gt;&gt;&gt; evaluator = AveragePrecisionEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nAveragePrecisionEvaluator(y_true='target', y_score='pred', label_type='auto', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [2, -1, 0, 3, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nAveragePrecisionResult(y_true=(5,), y_score=(5,), label_type='binary', nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BalancedAccuracyEvaluator","title":"arkas.evaluator.BalancedAccuracyEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BalancedAccuracyResult]</code></p> <p>Implement the accuracy evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BalancedAccuracyEvaluator\n&gt;&gt;&gt; evaluator = BalancedAccuracyEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBalancedAccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBalancedAccuracyResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BaseEvaluator","title":"arkas.evaluator.BaseEvaluator","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to evaluate a DataFrame.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BaseEvaluator.evaluate","title":"arkas.evaluator.BaseEvaluator.evaluate","text":"<pre><code>evaluate(data: DataFrame, lazy: bool = True) -&gt; BaseResult\n</code></pre> <p>Evaluate the result.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>DataFrame</code> <p>The data to evaluate.</p> required <code>lazy</code> <code>bool</code> <p>If <code>True</code>, it forces the computation of the result, otherwise it returns a result object that delays the evaluation of the result.</p> <code>True</code> <p>Returns:</p> Type Description <code>BaseResult</code> <p>The generated result.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BaseLazyEvaluator","title":"arkas.evaluator.BaseLazyEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code>, <code>Generic[T]</code></p> <p>Define the base class to evaluate the result lazily.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryAveragePrecisionEvaluator","title":"arkas.evaluator.BinaryAveragePrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryAveragePrecisionResult]</code></p> <p>Implement the average precision evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryAveragePrecisionEvaluator\n&gt;&gt;&gt; evaluator = BinaryAveragePrecisionEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryAveragePrecisionEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [2, -1, 0, 3, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryAveragePrecisionResult(y_true=(5,), y_score=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryClassificationEvaluator","title":"arkas.evaluator.BinaryClassificationEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryClassificationResult]</code></p> <p>Implement the average precision evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>y_score</code> <code>str | None</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> <code>None</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryClassificationEvaluator\n&gt;&gt;&gt; evaluator = BinaryClassificationEvaluator(\n...     y_true=\"target\", y_pred=\"pred\", y_score=\"score\"\n... )\n&gt;&gt;&gt; evaluator\nBinaryClassificationEvaluator(y_true='target', y_pred='pred', y_score='score', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [1, 0, 0, 1, 1],\n...         \"score\": [2, -1, 0, 3, 1],\n...         \"target\": [1, 0, 0, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryClassificationResult(y_true=(5,), y_pred=(5,), y_score=(5,), betas=(1,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryConfusionMatrixEvaluator","title":"arkas.evaluator.BinaryConfusionMatrixEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryConfusionMatrixResult]</code></p> <p>Implement the confusion matrix evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryConfusionMatrixEvaluator\n&gt;&gt;&gt; evaluator = BinaryConfusionMatrixEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryConfusionMatrixEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryConfusionMatrixResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryFbetaScoreEvaluator","title":"arkas.evaluator.BinaryFbetaScoreEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryFbetaScoreResult]</code></p> <p>Implement the F-beta evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryFbetaScoreEvaluator\n&gt;&gt;&gt; evaluator = BinaryFbetaScoreEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryFbetaScoreEvaluator(y_true='target', y_pred='pred', betas=(1,), drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(\n...     data=pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n... )\n&gt;&gt;&gt; result\nBinaryFbetaScoreResult(y_true=(5,), y_pred=(5,), betas=(1,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryJaccardEvaluator","title":"arkas.evaluator.BinaryJaccardEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryJaccardResult]</code></p> <p>Implement the Jaccard evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryJaccardEvaluator\n&gt;&gt;&gt; evaluator = BinaryJaccardEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryJaccardEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryJaccardResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryPrecisionEvaluator","title":"arkas.evaluator.BinaryPrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryPrecisionResult]</code></p> <p>Implement the precision evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryPrecisionEvaluator\n&gt;&gt;&gt; evaluator = BinaryPrecisionEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryPrecisionEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryPrecisionResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryRecallEvaluator","title":"arkas.evaluator.BinaryRecallEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryRecallResult]</code></p> <p>Implement the recall evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryRecallEvaluator\n&gt;&gt;&gt; evaluator = BinaryRecallEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryRecallEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryRecallResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.BinaryRocAucEvaluator","title":"arkas.evaluator.BinaryRocAucEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[BinaryRocAucResult]</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) evaluator for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import BinaryRocAucEvaluator\n&gt;&gt;&gt; evaluator = BinaryRocAucEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nBinaryRocAucEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [2, -1, 0, 3, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nBinaryRocAucResult(y_true=(5,), y_score=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.EnergyDistanceEvaluator","title":"arkas.evaluator.EnergyDistanceEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[EnergyDistanceResult]</code></p> <p>Implement the energy distance between two 1D distributions evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>v_values</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import EnergyDistanceEvaluator\n&gt;&gt;&gt; evaluator = EnergyDistanceEvaluator(u_values=\"target\", v_values=\"pred\")\n&gt;&gt;&gt; evaluator\nEnergyDistanceEvaluator(u_values='target', v_values='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nEnergyDistanceResult(u_values=(5,), v_values=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.EvaluatorDict","title":"arkas.evaluator.EvaluatorDict","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement an evaluator that sequentially evaluates a mapping of evaluators.</p> <p>Parameters:</p> Name Type Description Default <code>evaluators</code> <code>Mapping[Hashable, BaseEvaluator]</code> <p>The mapping of evaluators to evaluate.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import (\n...     EvaluatorDict,\n...     BinaryPrecisionEvaluator,\n...     BinaryRecallEvaluator,\n... )\n&gt;&gt;&gt; evaluator = EvaluatorDict(\n...     {\n...         \"precision\": BinaryPrecisionEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         \"recall\": BinaryRecallEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...     }\n... )\n&gt;&gt;&gt; evaluator\nEvaluatorDict(\n  (precision): BinaryPrecisionEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n  (recall): BinaryRecallEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n)\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMappingResult(count=2)\n&gt;&gt;&gt; result = evaluator.evaluate(data, lazy=False)\n&gt;&gt;&gt; result\nResult(metrics=2, figures=2)\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.JensenShannonDivergenceEvaluator","title":"arkas.evaluator.JensenShannonDivergenceEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[JensenShannonDivergenceResult]</code></p> <p>Implement the Jensen-Shannon (JS) divergence between two distributions evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>q</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import JensenShannonDivergenceEvaluator\n&gt;&gt;&gt; evaluator = JensenShannonDivergenceEvaluator(p=\"target\", q=\"pred\")\n&gt;&gt;&gt; evaluator\nJensenShannonDivergenceEvaluator(p='target', q='pred', drop_nulls=True)\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nJensenShannonDivergenceResult(p=(5,), q=(5,))\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.KLDivEvaluator","title":"arkas.evaluator.KLDivEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[KLDivResult]</code></p> <p>Implement the Kullback-Leibler (KL) divergence between two distributions evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>q</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import KLDivEvaluator\n&gt;&gt;&gt; evaluator = KLDivEvaluator(p=\"target\", q=\"pred\")\n&gt;&gt;&gt; evaluator\nKLDivEvaluator(p='target', q='pred', drop_nulls=True)\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nKLDivResult(p=(5,), q=(5,))\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MeanAbsoluteErrorEvaluator","title":"arkas.evaluator.MeanAbsoluteErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MeanAbsoluteErrorResult]</code></p> <p>Implement the mean absolute error (MAE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MeanAbsoluteErrorEvaluator\n&gt;&gt;&gt; evaluator = MeanAbsoluteErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMeanAbsoluteErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMeanAbsoluteErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MeanAbsolutePercentageErrorEvaluator","title":"arkas.evaluator.MeanAbsolutePercentageErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MeanAbsolutePercentageErrorResult]</code></p> <p>Implement the mean absolute percentage error (MAPE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MeanAbsolutePercentageErrorEvaluator\n&gt;&gt;&gt; evaluator = MeanAbsolutePercentageErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMeanAbsolutePercentageErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMeanAbsolutePercentageErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MeanSquaredErrorEvaluator","title":"arkas.evaluator.MeanSquaredErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MeanSquaredErrorResult]</code></p> <p>Implement the mean squared error (MSE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MeanSquaredErrorEvaluator\n&gt;&gt;&gt; evaluator = MeanSquaredErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMeanSquaredErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMeanSquaredErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MeanSquaredLogErrorEvaluator","title":"arkas.evaluator.MeanSquaredLogErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MeanSquaredLogErrorResult]</code></p> <p>Implement the mean squared logarithmic error (MSLE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MeanSquaredLogErrorEvaluator\n&gt;&gt;&gt; evaluator = MeanSquaredLogErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMeanSquaredLogErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMeanSquaredLogErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MeanTweedieDevianceEvaluator","title":"arkas.evaluator.MeanTweedieDevianceEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MeanTweedieDevianceResult]</code></p> <p>Implement the mean Tweedie deviance regression loss evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MeanTweedieDevianceEvaluator\n&gt;&gt;&gt; evaluator = MeanTweedieDevianceEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMeanTweedieDevianceEvaluator(y_true='target', y_pred='pred', powers=(0,), drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMeanTweedieDevianceResult(y_true=(5,), y_pred=(5,), powers=(0,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MedianAbsoluteErrorEvaluator","title":"arkas.evaluator.MedianAbsoluteErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MedianAbsoluteErrorResult]</code></p> <p>Implement the median absolute error (MAE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MedianAbsoluteErrorEvaluator\n&gt;&gt;&gt; evaluator = MedianAbsoluteErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMedianAbsoluteErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMedianAbsoluteErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassAveragePrecisionEvaluator","title":"arkas.evaluator.MulticlassAveragePrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassAveragePrecisionResult]</code></p> <p>Implement the average precision evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_score</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassAveragePrecisionEvaluator\n&gt;&gt;&gt; evaluator = MulticlassAveragePrecisionEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassAveragePrecisionEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.5, 0.3],\n...             [0.3, 0.3, 0.4],\n...             [0.1, 0.2, 0.7],\n...         ],\n...         \"target\": [0, 0, 1, 1, 2, 2],\n...     },\n...     schema={\"pred\": pl.Array(pl.Float64, 3), \"target\": pl.Int64},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassAveragePrecisionResult(y_true=(6,), y_score=(6, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassConfusionMatrixEvaluator","title":"arkas.evaluator.MulticlassConfusionMatrixEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassConfusionMatrixResult]</code></p> <p>Implement the confusion matrix evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassConfusionMatrixEvaluator\n&gt;&gt;&gt; evaluator = MulticlassConfusionMatrixEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassConfusionMatrixEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [0, 0, 1, 1, 2, 2], \"target\": [0, 0, 1, 1, 2, 2]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassConfusionMatrixResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassFbetaScoreEvaluator","title":"arkas.evaluator.MulticlassFbetaScoreEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassFbetaScoreResult]</code></p> <p>Implement the F-beta evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassFbetaScoreEvaluator\n&gt;&gt;&gt; evaluator = MulticlassFbetaScoreEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassFbetaScoreEvaluator(y_true='target', y_pred='pred', betas=(1,), drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [0, 0, 1, 1, 2, 2], \"target\": [0, 0, 1, 1, 2, 2]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassFbetaScoreResult(y_true=(6,), y_pred=(6,), betas=(1,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassJaccardEvaluator","title":"arkas.evaluator.MulticlassJaccardEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassJaccardResult]</code></p> <p>Implement the Jaccard evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassJaccardEvaluator\n&gt;&gt;&gt; evaluator = MulticlassJaccardEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassJaccardEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [0, 0, 1, 1, 2, 2], \"target\": [0, 0, 1, 1, 2, 2]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassJaccardResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassPrecisionEvaluator","title":"arkas.evaluator.MulticlassPrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassPrecisionResult]</code></p> <p>Implement the precision evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassPrecisionEvaluator\n&gt;&gt;&gt; evaluator = MulticlassPrecisionEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassPrecisionEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [0, 0, 1, 1, 2, 2], \"target\": [0, 0, 1, 1, 2, 2]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassPrecisionResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassRecallEvaluator","title":"arkas.evaluator.MulticlassRecallEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassRecallResult]</code></p> <p>Implement the recall evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassRecallEvaluator\n&gt;&gt;&gt; evaluator = MulticlassRecallEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassRecallEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [0, 0, 1, 1, 2, 2], \"target\": [0, 0, 1, 1, 2, 2]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassRecallResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MulticlassRocAucEvaluator","title":"arkas.evaluator.MulticlassRocAucEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MulticlassRocAucResult]</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) evaluator for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_score</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MulticlassRocAucEvaluator\n&gt;&gt;&gt; evaluator = MulticlassRocAucEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nMulticlassRocAucEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.5, 0.3],\n...             [0.3, 0.3, 0.4],\n...             [0.1, 0.2, 0.7],\n...         ],\n...         \"target\": [0, 0, 1, 1, 2, 2],\n...     },\n...     schema={\"pred\": pl.Array(pl.Float64, 3), \"target\": pl.Int64},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMulticlassRocAucResult(y_true=(6,), y_score=(6, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelAveragePrecisionEvaluator","title":"arkas.evaluator.MultilabelAveragePrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelAveragePrecisionResult]</code></p> <p>Implement the average precision evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_score</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelAveragePrecisionEvaluator\n&gt;&gt;&gt; evaluator = MultilabelAveragePrecisionEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelAveragePrecisionEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[2, -1, 1], [-1, 1, -2], [0, 2, -3], [3, -2, 4], [1, -3, 5]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelAveragePrecisionResult(y_true=(5, 3), y_score=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelConfusionMatrixEvaluator","title":"arkas.evaluator.MultilabelConfusionMatrixEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelConfusionMatrixResult]</code></p> <p>Implement the confusion matrix evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelConfusionMatrixEvaluator\n&gt;&gt;&gt; evaluator = MultilabelConfusionMatrixEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelConfusionMatrixEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelConfusionMatrixResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelFbetaScoreEvaluator","title":"arkas.evaluator.MultilabelFbetaScoreEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelFbetaScoreResult]</code></p> <p>Implement the F-beta evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelFbetaScoreEvaluator\n&gt;&gt;&gt; evaluator = MultilabelFbetaScoreEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelFbetaScoreEvaluator(y_true='target', y_pred='pred', betas=(1,), drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelFbetaScoreResult(y_true=(5, 3), y_pred=(5, 3), betas=(1,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelJaccardEvaluator","title":"arkas.evaluator.MultilabelJaccardEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelJaccardResult]</code></p> <p>Implement the Jaccard evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelJaccardEvaluator\n&gt;&gt;&gt; evaluator = MultilabelJaccardEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelJaccardEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelJaccardResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelPrecisionEvaluator","title":"arkas.evaluator.MultilabelPrecisionEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelPrecisionResult]</code></p> <p>Implement the precision evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelPrecisionEvaluator\n&gt;&gt;&gt; evaluator = MultilabelPrecisionEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelPrecisionEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelPrecisionResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelRecallEvaluator","title":"arkas.evaluator.MultilabelRecallEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelRecallResult]</code></p> <p>Implement the recall evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted labels.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelRecallEvaluator\n&gt;&gt;&gt; evaluator = MultilabelRecallEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelRecallEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelRecallResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.MultilabelRocAucEvaluator","title":"arkas.evaluator.MultilabelRocAucEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[MultilabelRocAucResult]</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) evaluator for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target labels.</p> required <code>y_score</code> <code>str</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_score</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import MultilabelRocAucEvaluator\n&gt;&gt;&gt; evaluator = MultilabelRocAucEvaluator(y_true=\"target\", y_score=\"pred\")\n&gt;&gt;&gt; evaluator\nMultilabelRocAucEvaluator(y_true='target', y_score='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame(\n...     {\n...         \"pred\": [[2, -1, 1], [-1, 1, -2], [0, 2, -3], [3, -2, 4], [1, -3, 5]],\n...         \"target\": [[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]],\n...     },\n...     schema={\"pred\": pl.Array(pl.Int64, 3), \"target\": pl.Array(pl.Int64, 3)},\n... )\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nMultilabelRocAucResult(y_true=(5, 3), y_score=(5, 3), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.PearsonCorrelationEvaluator","title":"arkas.evaluator.PearsonCorrelationEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[PearsonCorrelationResult]</code></p> <p>Implement the Pearson correlation evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import PearsonCorrelationEvaluator\n&gt;&gt;&gt; evaluator = PearsonCorrelationEvaluator(x=\"target\", y=\"pred\")\n&gt;&gt;&gt; evaluator\nPearsonCorrelationEvaluator(x='target', y='pred', alternative='two-sided', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nPearsonCorrelationResult(x=(5,), y=(5,), alternative='two-sided', nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.R2ScoreEvaluator","title":"arkas.evaluator.R2ScoreEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[R2ScoreResult]</code></p> <p>Implement the R^2 (coefficient of determination) regression score evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import R2ScoreEvaluator\n&gt;&gt;&gt; evaluator = R2ScoreEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nR2ScoreEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nR2ScoreResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.RootMeanSquaredErrorEvaluator","title":"arkas.evaluator.RootMeanSquaredErrorEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[RootMeanSquaredErrorResult]</code></p> <p>Implement the root mean squared error (RMSE) evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y_pred</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>y_true</code> or <code>y_pred</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import RootMeanSquaredErrorEvaluator\n&gt;&gt;&gt; evaluator = RootMeanSquaredErrorEvaluator(y_true=\"target\", y_pred=\"pred\")\n&gt;&gt;&gt; evaluator\nRootMeanSquaredErrorEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nRootMeanSquaredErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.SequentialEvaluator","title":"arkas.evaluator.SequentialEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement an evaluator that sequentially evaluates several evaluators.</p> <p>Parameters:</p> Name Type Description Default <code>evaluators</code> <code>Sequence[BaseEvaluator | dict]</code> <p>The sequence of evaluators to evaluate.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import (\n...     SequentialEvaluator,\n...     BinaryPrecisionEvaluator,\n...     BinaryRecallEvaluator,\n... )\n&gt;&gt;&gt; evaluator = SequentialEvaluator(\n...     [\n...         BinaryPrecisionEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         BinaryRecallEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...     ]\n... )\n&gt;&gt;&gt; evaluator\nSequentialEvaluator(\n  (0): BinaryPrecisionEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n  (1): BinaryRecallEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n)\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 0, 0, 1, 1], \"target\": [1, 0, 0, 1, 1]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nSequentialResult(count=2)\n&gt;&gt;&gt; result = evaluator.evaluate(data, lazy=False)\n&gt;&gt;&gt; result\nResult(metrics=3, figures=1)\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.SpearmanCorrelationEvaluator","title":"arkas.evaluator.SpearmanCorrelationEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[SpearmanCorrelationResult]</code></p> <p>Implement the Spearman correlation evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>str</code> <p>The key or column name of the ground truth target values.</p> required <code>y</code> <code>str</code> <p>The key or column name of the predicted values.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import SpearmanCorrelationEvaluator\n&gt;&gt;&gt; evaluator = SpearmanCorrelationEvaluator(x=\"target\", y=\"pred\")\n&gt;&gt;&gt; evaluator\nSpearmanCorrelationEvaluator(x='target', y='pred', alternative='two-sided', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nSpearmanCorrelationResult(x=(5,), y=(5,), alternative='two-sided', nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.WassersteinDistanceEvaluator","title":"arkas.evaluator.WassersteinDistanceEvaluator","text":"<p>               Bases: <code>BaseLazyEvaluator[WassersteinDistanceResult]</code></p> <p>Implement the Wasserstein distance between two 1D distributions evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>v_values</code> <code>str</code> <p>The values observed in the (empirical) distribution.</p> required <code>drop_nulls</code> <code>bool</code> <p>If <code>True</code>, the rows with null values in <code>x</code> or <code>y</code> columns are dropped.</p> <code>True</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import WassersteinDistanceEvaluator\n&gt;&gt;&gt; evaluator = WassersteinDistanceEvaluator(u_values=\"target\", v_values=\"pred\")\n&gt;&gt;&gt; evaluator\nWassersteinDistanceEvaluator(u_values='target', v_values='pred', drop_nulls=True, nan_policy='propagate')\n&gt;&gt;&gt; data = pl.DataFrame({\"pred\": [1, 2, 3, 4, 5], \"target\": [1, 2, 3, 4, 5]})\n&gt;&gt;&gt; result = evaluator.evaluate(data)\n&gt;&gt;&gt; result\nWassersteinDistanceResult(u_values=(5,), v_values=(5,), nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.is_evaluator_config","title":"arkas.evaluator.is_evaluator_config","text":"<pre><code>is_evaluator_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseEvaluator</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseEvaluator</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.evaluator import is_evaluator_config\n&gt;&gt;&gt; is_evaluator_config({\"_target_\": \"arkas.evaluator.AccuracyEvaluator\"})\nTrue\n</code></pre>"},{"location":"refs/evaluator/#arkas.evaluator.setup_evaluator","title":"arkas.evaluator.setup_evaluator","text":"<pre><code>setup_evaluator(\n    evaluator: BaseEvaluator | dict,\n) -&gt; BaseEvaluator\n</code></pre> <p>Set up an evaluator.</p> <p>The evaluator is instantiated from its configuration by using the <code>BaseEvaluator</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>evaluator</code> <code>BaseEvaluator | dict</code> <p>An evaluator or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseEvaluator</code> <p>An instantiated evaluator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.evaluator import setup_evaluator\n&gt;&gt;&gt; evaluator = setup_evaluator(\n...     {\n...         \"_target_\": \"arkas.evaluator.AccuracyEvaluator\",\n...         \"y_true\": \"target\",\n...         \"y_pred\": \"pred\",\n...     }\n... )\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n</code></pre>"},{"location":"refs/evaluator2/","title":"arkas.evaluator2","text":""},{"location":"refs/evaluator2/#arkas.evaluator2","title":"arkas.evaluator2","text":"<p>Contain data evaluators.</p>"},{"location":"refs/evaluator2/#arkas.evaluator2.AccuracyEvaluator","title":"arkas.evaluator2.AccuracyEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement the accuracy evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AccuracyState</code> <p>The state containing the ground truth and predicted labels.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import AccuracyEvaluator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n&gt;&gt;&gt; evaluator.evaluate()\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.BalancedAccuracyEvaluator","title":"arkas.evaluator2.BalancedAccuracyEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement the balanced accuracy evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AccuracyState</code> <p>The state containing the ground truth and predicted labels.</p> required <code>nan_policy</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import BalancedAccuracyEvaluator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; evaluator = BalancedAccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator\nBalancedAccuracyEvaluator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n&gt;&gt;&gt; evaluator.evaluate()\n{'balanced_accuracy': 1.0, 'count': 5}\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.BaseEvaluator","title":"arkas.evaluator2.BaseEvaluator","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement an evaluator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import AccuracyEvaluator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator\nAccuracyEvaluator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.BaseEvaluator.compute","title":"arkas.evaluator2.BaseEvaluator.compute  <code>abstractmethod</code>","text":"<pre><code>compute() -&gt; BaseEvaluator\n</code></pre> <p>Compute the metrics and return a new evaluator.</p> <p>Returns:</p> Type Description <code>BaseEvaluator</code> <p>A new evaluator with the computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import AccuracyEvaluator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator2 = evaluator.compute()\n&gt;&gt;&gt; evaluator2\nEvaluator(count=5)\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.BaseEvaluator.equal","title":"arkas.evaluator2.BaseEvaluator.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two evaluators are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other evaluator to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two evaluators are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import AccuracyEvaluator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; evaluator1 = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator2 = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator3 = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 0, 0]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator1.equal(evaluator2)\nTrue\n&gt;&gt;&gt; evaluator1.equal(evaluator3)\nFalse\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.BaseEvaluator.evaluate","title":"arkas.evaluator2.BaseEvaluator.evaluate  <code>abstractmethod</code>","text":"<pre><code>evaluate(prefix: str = '', suffix: str = '') -&gt; dict\n</code></pre> <p>Evaluate the metrics.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict</code> <p>The metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import AccuracyEvaluator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; evaluator = AccuracyEvaluator(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator.evaluate()\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.ColumnCooccurrenceEvaluator","title":"arkas.evaluator2.ColumnCooccurrenceEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement the pairwise column co-occurrence evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>ColumnCooccurrenceState</code> <p>The state with the co-occurrence matrix.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import ColumnCooccurrenceEvaluator\n&gt;&gt;&gt; from arkas.state import ColumnCooccurrenceState\n&gt;&gt;&gt; evaluator = ColumnCooccurrenceEvaluator(\n...     ColumnCooccurrenceState(matrix=np.ones((3, 3)), columns=[\"a\", \"b\", \"c\"])\n... )\n&gt;&gt;&gt; evaluator\nColumnCooccurrenceEvaluator(\n  (state): ColumnCooccurrenceState(matrix=(3, 3), figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; evaluator.evaluate()\n{'column_cooccurrence': array([[1., 1., 1.],\n       [1., 1., 1.],\n       [1., 1., 1.]])}\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.ColumnCorrelationEvaluator","title":"arkas.evaluator2.ColumnCorrelationEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement the column correlation evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>TargetDataFrameState</code> <p>The state with the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator2 import ColumnCorrelationEvaluator\n&gt;&gt;&gt; from arkas.state import TargetDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...         \"col2\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...     },\n... )\n&gt;&gt;&gt; evaluator = ColumnCorrelationEvaluator(\n...     TargetDataFrameState(frame, target_column=\"col3\")\n... )\n&gt;&gt;&gt; evaluator\nColumnCorrelationEvaluator(\n  (state): TargetDataFrameState(dataframe=(7, 3), target_column='col3', nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; evaluator.evaluate()\n{'correlation_col1': {'count': 7, 'pearson_coeff': 1.0, 'pearson_pvalue': 0.0, 'spearman_coeff': 1.0, 'spearman_pvalue': 0.0},\n 'correlation_col2': {'count': 7, 'pearson_coeff': -1.0, 'pearson_pvalue': 0.0, 'spearman_coeff': -1.0, 'spearman_pvalue': 0.0}}\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.CorrelationEvaluator","title":"arkas.evaluator2.CorrelationEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement the pairwise column correlation evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>DataFrameState</code> <p>The state with the DataFrame to analyze. The DataFrame must have only 2 columns, which are the two columns to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator2 import CorrelationEvaluator\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...         \"col3\": [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0],\n...     },\n... )\n&gt;&gt;&gt; evaluator = CorrelationEvaluator(DataFrameState(frame))\n&gt;&gt;&gt; evaluator\nCorrelationEvaluator(\n  (state): DataFrameState(dataframe=(7, 2), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; evaluator.evaluate()\n{'count': 7, 'pearson_coeff': 1.0, 'pearson_pvalue': 0.0, 'spearman_coeff': 1.0, 'spearman_pvalue': 0.0}\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.Evaluator","title":"arkas.evaluator2.Evaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement a simple evaluator.</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>dict | None</code> <p>The dictionary of metrics.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import Evaluator\n&gt;&gt;&gt; evaluator = Evaluator({\"accuracy\": 1.0, \"total\": 42})\n&gt;&gt;&gt; evaluator\nEvaluator(count=2)\n&gt;&gt;&gt; evaluator.evaluate()\n{'accuracy': 1.0, 'total': 42}\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.EvaluatorDict","title":"arkas.evaluator2.EvaluatorDict","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement an evaluator that sequentially evaluates a mapping of evaluators.</p> <p>Parameters:</p> Name Type Description Default <code>evaluators</code> <code>Mapping[Hashable, BaseEvaluator]</code> <p>The mapping of evaluators to evaluate.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.evaluator2 import EvaluatorDict, AccuracyEvaluator, Evaluator\n&gt;&gt;&gt; evaluator = EvaluatorDict(\n...     {\n...         \"one\": AccuracyEvaluator(\n...             AccuracyState(\n...                 y_true=np.array([1, 0, 0, 1, 1]),\n...                 y_pred=np.array([1, 0, 0, 1, 1]),\n...                 y_true_name=\"target\",\n...                 y_pred_name=\"pred\",\n...             )\n...         ),\n...         \"two\": Evaluator({\"accuracy\": 1.0, \"total\": 42}),\n...     }\n... )\n&gt;&gt;&gt; evaluator\nEvaluatorDict(\n  (one): AccuracyEvaluator(\n      (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n    )\n  (two): Evaluator(count=2)\n)\n&gt;&gt;&gt; metrics = evaluator.evaluate()\n&gt;&gt;&gt; metrics\n{'one': {'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0},\n 'two': {'accuracy': 1.0, 'total': 42}}\n</code></pre>"},{"location":"refs/evaluator2/#arkas.evaluator2.PrecisionEvaluator","title":"arkas.evaluator2.PrecisionEvaluator","text":"<p>               Bases: <code>BaseEvaluator</code></p> <p>Implement the precision evaluator.</p> <p>This evaluator can be used in 3 different settings:</p> <ul> <li>binary: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with <code>0</code> and <code>1</code> values, and <code>y_pred</code> must be an array     of shape <code>(n_samples,)</code>.</li> <li>multiclass: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with values in <code>{0, ..., n_classes-1}</code>, and <code>y_pred</code> must     be an array of shape <code>(n_samples,)</code>.</li> <li>multilabel: <code>y_true</code> must be an array of shape     <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values, and     <code>y_pred</code> must be an array of shape     <code>(n_samples, n_classes)</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>PrecisionRecallState</code> <p>The state containing the ground truth and predicted labels.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.evaluator2 import PrecisionEvaluator\n&gt;&gt;&gt; from arkas.state import PrecisionRecallState\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; evaluator = PrecisionEvaluator(\n...     PrecisionRecallState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...         label_type=\"binary\",\n...     ),\n... )\n&gt;&gt;&gt; evaluator\nPrecisionEvaluator(\n  (state): PrecisionRecallState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', label_type='binary', nan_policy='propagate')\n)\n&gt;&gt;&gt; evaluator.evaluate()\n{'count': 5, 'precision': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; evaluator = PrecisionEvaluator(\n...     PrecisionRecallState(\n...         y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...         y_pred=np.array([[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...         label_type=\"multilabel\",\n...     )\n... )\n&gt;&gt;&gt; evaluator\nPrecisionEvaluator(\n  (state): PrecisionRecallState(y_true=(5, 3), y_pred=(5, 3), y_true_name='target', y_pred_name='pred', label_type='multilabel', nan_policy='propagate')\n)\n&gt;&gt;&gt; evaluator.evaluate()\n{'count': 5,\n 'macro_precision': 0.666...,\n 'micro_precision': 0.714...,\n 'precision': array([1., 1., 0.]),\n 'weighted_precision': 0.625}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; evaluator = PrecisionEvaluator(\n...     PrecisionRecallState(\n...         y_true=np.array([0, 0, 1, 1, 2, 2]),\n...         y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...         label_type=\"multiclass\",\n...     ),\n... )\n&gt;&gt;&gt; evaluator\nPrecisionEvaluator(\n  (state): PrecisionRecallState(y_true=(6,), y_pred=(6,), y_true_name='target', y_pred_name='pred', label_type='multiclass', nan_policy='propagate')\n)\n&gt;&gt;&gt; evaluator.evaluate()\n{'count': 6,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; evaluator = PrecisionEvaluator(\n...     PrecisionRecallState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; evaluator\nPrecisionEvaluator(\n  (state): PrecisionRecallState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', label_type='binary', nan_policy='propagate')\n)\n&gt;&gt;&gt; evaluator.evaluate()\n{'count': 5, 'precision': 1.0}\n</code></pre>"},{"location":"refs/exporter/","title":"arkas.exporter","text":""},{"location":"refs/exporter/#arkas.exporter","title":"arkas.exporter","text":"<p>Contain output exporters.</p>"},{"location":"refs/exporter/#arkas.exporter.BaseExporter","title":"arkas.exporter.BaseExporter","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to export an output object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     exporter = MetricExporter(path=Path(tmpdir).joinpath(\"metrics.pkl\"))\n...     print(exporter)\n...     exporter.export(output)\n...\nMetricExporter(\n  (path): .../metrics.pkl\n  (saver): PickleSaver(protocol=5)\n  (exist_ok): False\n  (show_metrics): False\n)\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.BaseExporter.export","title":"arkas.exporter.BaseExporter.export  <code>abstractmethod</code>","text":"<pre><code>export(output: BaseOutput) -&gt; None\n</code></pre> <p>Export an output.</p> <p>Parameters:</p> Name Type Description Default <code>output</code> <code>BaseOutput</code> <p>The output object to export.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     exporter = MetricExporter(path=Path(tmpdir).joinpath(\"metrics.pkl\"))\n...     exporter.export(output)\n...\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.FigureExporter","title":"arkas.exporter.FigureExporter","text":"<p>               Bases: <code>BaseExporter</code></p> <p>Implement a simple figure exporter.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>The path where to save the figures.</p> required <code>saver</code> <code>BaseSaver | dict | None</code> <p>The figure saver or its configuration.</p> <code>None</code> <code>exist_ok</code> <code>bool</code> <p>If <code>exist_ok</code> is <code>False</code> (the default), an exception is raised if the path already exists.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import FigureExporter\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     exporter = FigureExporter(path=Path(tmpdir).joinpath(\"figures.pkl\"))\n...     exporter.export(output)\n...\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.MetricExporter","title":"arkas.exporter.MetricExporter","text":"<p>               Bases: <code>BaseExporter</code></p> <p>Implement a simple metric exporter.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>The path where to save the metrics.</p> required <code>saver</code> <code>BaseSaver | dict | None</code> <p>The metric saver or its configuration.</p> <code>None</code> <code>exist_ok</code> <code>bool</code> <p>If <code>exist_ok</code> is <code>False</code> (the default), an exception is raised if the path already exists.</p> <code>False</code> <code>show_metrics</code> <code>bool</code> <p>If <code>True</code>, the metrics are shown in the logging output.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     exporter = MetricExporter(path=Path(tmpdir).joinpath(\"metrics.pkl\"))\n...     exporter.export(output)\n...\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.ReportExporter","title":"arkas.exporter.ReportExporter","text":"<p>               Bases: <code>BaseExporter</code></p> <p>Implement a simple report exporter.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>Path | str</code> <p>The path where to save the reports.</p> required <code>saver</code> <code>BaseSaver | dict | None</code> <p>The report saver or its configuration.</p> <code>None</code> <code>exist_ok</code> <code>bool</code> <p>If <code>exist_ok</code> is <code>False</code> (the default), an exception is raised if the path already exists.</p> <code>False</code> <code>max_toc_depth</code> <code>int</code> <p>The maximum level to show in the table of content.</p> <code>6</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import ReportExporter\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     exporter = ReportExporter(path=Path(tmpdir).joinpath(\"report.html\"))\n...     exporter.export(output)\n...\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.SequentialExporter","title":"arkas.exporter.SequentialExporter","text":"<p>               Bases: <code>BaseExporter</code></p> <p>Implement an exporter that sequentially calls several exporters.</p> <p>Parameters:</p> Name Type Description Default <code>exporters</code> <code>Sequence[BaseExporter | dict]</code> <p>The sequence of exporters.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.exporter import (\n...     SequentialExporter,\n...     FigureExporter,\n...     MetricExporter,\n... )\n&gt;&gt;&gt; output = AccuracyOutput(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     path = Path(tmpdir)\n...     exporter = SequentialExporter(\n...         [\n...             MetricExporter(path.joinpath(\"metrics.pkl\")),\n...             FigureExporter(path.joinpath(\"figures.pkl\")),\n...         ]\n...     )\n...     print(exporter)\n...     exporter.export(output)\n...\nSequentialExporter(\n  (0): MetricExporter(\n      (path): .../metrics.pkl\n      (saver): PickleSaver(protocol=5)\n      (exist_ok): False\n      (show_metrics): False\n    )\n  (1): FigureExporter(\n      (path): .../figures.pkl\n      (saver): PickleSaver(protocol=5)\n      (exist_ok): False\n    )\n)\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.is_exporter_config","title":"arkas.exporter.is_exporter_config","text":"<pre><code>is_exporter_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseExporter</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseExporter</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.exporter import is_exporter_config\n&gt;&gt;&gt; is_exporter_config(\n...     {\n...         \"_target_\": \"arkas.exporter.MetricExporter\",\n...         \"path\": \"/path/to/data.csv\",\n...     }\n... )\nTrue\n</code></pre>"},{"location":"refs/exporter/#arkas.exporter.setup_exporter","title":"arkas.exporter.setup_exporter","text":"<pre><code>setup_exporter(\n    exporter: BaseExporter | dict,\n) -&gt; BaseExporter\n</code></pre> <p>Set up a exporter.</p> <p>The exporter is instantiated from its configuration by using the <code>BaseExporter</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>exporter</code> <code>BaseExporter | dict</code> <p>A exporter or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseExporter</code> <p>An instantiated exporter.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.exporter import setup_exporter\n&gt;&gt;&gt; exporter = setup_exporter(\n...     {\n...         \"_target_\": \"arkas.exporter.MetricExporter\",\n...         \"path\": \"/path/to/data.csv\",\n...     }\n... )\n&gt;&gt;&gt; exporter\nMetricExporter(\n  (path): /path/to/data.csv\n  (saver): PickleSaver(protocol=5)\n  (exist_ok): False\n  (show_metrics): False\n)\n</code></pre>"},{"location":"refs/metric/","title":"arkas.metric","text":""},{"location":"refs/metric/#arkas.metric","title":"arkas.metric","text":"<p>Contain functions to compute metrics.</p>"},{"location":"refs/metric/#arkas.metric.accuracy","title":"arkas.metric.accuracy","text":"<pre><code>accuracy(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the accuracy metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import accuracy\n&gt;&gt;&gt; accuracy(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.average_precision","title":"arkas.metric.average_precision","text":"<pre><code>average_precision(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the average precision metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import average_precision\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; metrics = average_precision(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1])\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': 1.0, 'count': 5}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; metrics = average_precision(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_score=np.array([2, -1, 0, 3, 1]),\n...     label_type=\"binary\",\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': 1.0, 'count': 5}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; metrics = average_precision(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.3, 0.5],\n...             [0.4, 0.4, 0.2],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n...     label_type=\"multiclass\",\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': array([0.833..., 0.75 , 0.75 ]),\n 'count': 6,\n 'macro_average_precision': 0.777...,\n 'micro_average_precision': 0.75,\n 'weighted_average_precision': 0.777...}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; metrics = average_precision(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, -1], [-1, 1, 2], [0, 2, 3], [3, -2, -4], [1, -3, -5]]),\n...     label_type=\"multilabel\",\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': array([1. , 1. , 0.477...]),\n 'count': 5,\n 'macro_average_precision': 0.825...,\n 'micro_average_precision': 0.588...,\n 'weighted_average_precision': 0.804...}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.balanced_accuracy","title":"arkas.metric.balanced_accuracy","text":"<pre><code>balanced_accuracy(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the accuracy metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import balanced_accuracy\n&gt;&gt;&gt; balanced_accuracy(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'balanced_accuracy': 1.0, 'count': 5}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_average_precision","title":"arkas.metric.binary_average_precision","text":"<pre><code>binary_average_precision(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the average precision metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_average_precision\n&gt;&gt;&gt; metrics = binary_average_precision(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1])\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': 1.0, 'count': 5}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_confusion_matrix","title":"arkas.metric.binary_confusion_matrix","text":"<pre><code>binary_confusion_matrix(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the confusion matrix metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_confusion_matrix\n&gt;&gt;&gt; binary_confusion_matrix(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n{'confusion_matrix': array([[2, 0], [0, 3]]),\n 'count': 5,\n 'false_negative_rate': 0.0,\n 'false_negative': 0,\n 'false_positive_rate': 0.0,\n 'false_positive': 0,\n 'true_negative_rate': 1.0,\n 'true_negative': 2,\n 'true_positive_rate': 1.0,\n 'true_positive': 3}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_fbeta_score","title":"arkas.metric.binary_fbeta_score","text":"<pre><code>binary_fbeta_score(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    betas: Sequence[float] = (1,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the F-beta metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_fbeta_score\n&gt;&gt;&gt; binary_fbeta_score(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n... )\n{'count': 5, 'f1': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_jaccard","title":"arkas.metric.binary_jaccard","text":"<pre><code>binary_jaccard(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Jaccard metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_jaccard\n&gt;&gt;&gt; binary_jaccard(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'jaccard': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_precision","title":"arkas.metric.binary_precision","text":"<pre><code>binary_precision(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the precision metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_precision\n&gt;&gt;&gt; binary_precision(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'precision': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_recall","title":"arkas.metric.binary_recall","text":"<pre><code>binary_recall(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the recall metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import binary_recall\n&gt;&gt;&gt; binary_recall(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'recall': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.binary_roc_auc","title":"arkas.metric.binary_roc_auc","text":"<pre><code>binary_roc_auc(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Area Under the Receiver Operating Characteristic Curve (ROC AUC) metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p>"},{"location":"refs/metric/#arkas.metric.binary_top_k_accuracy","title":"arkas.metric.binary_top_k_accuracy","text":"<pre><code>binary_top_k_accuracy(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    k: Sequence[int] = (2,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Area Under the Top-k Accuracy classification metrics for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>k</code> <code>Sequence[int]</code> <p>The numbers of most likely outcomes considered to find the correct label.</p> <code>(2,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p>"},{"location":"refs/metric/#arkas.metric.confusion_matrix","title":"arkas.metric.confusion_matrix","text":"<pre><code>confusion_matrix(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the confusion matrix metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import confusion_matrix\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; confusion_matrix(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n{'confusion_matrix': array([[2, 0], [0, 3]]),\n 'count': 5,\n 'false_negative_rate': 0.0,\n 'false_negative': 0,\n 'false_positive_rate': 0.0,\n 'false_positive': 0,\n 'true_negative_rate': 1.0,\n 'true_negative': 2,\n 'true_positive_rate': 1.0,\n 'true_positive': 3}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; confusion_matrix(\n...     y_true=np.array([0, 1, 1, 2, 2, 2]),\n...     y_pred=np.array([0, 1, 1, 2, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n{'confusion_matrix': array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]), 'count': 6}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; confusion_matrix(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     label_type=\"multilabel\",\n... )\n{'confusion_matrix': array([[[2, 0], [0, 3]],\n                            [[3, 0], [0, 2]],\n                            [[2, 0], [0, 3]]]),\n 'count': 5}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.energy_distance","title":"arkas.metric.energy_distance","text":"<pre><code>energy_distance(\n    u_values: ndarray,\n    v_values: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the energy distance between two 1D distributions.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>v_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import energy_distance\n&gt;&gt;&gt; energy_distance(u_values=np.array([1, 2, 3, 4, 5]), v_values=np.array([1, 2, 3, 4, 5]))\n{'count': 5, 'energy_distance': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.fbeta_score","title":"arkas.metric.fbeta_score","text":"<pre><code>fbeta_score(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    betas: Sequence[float] = (1,),\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the F-beta metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import fbeta_score\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; fbeta_score(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'f1': 1.0}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; fbeta_score(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n{'count': 5, 'f1': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; fbeta_score(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n{'count': 6,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; fbeta_score(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     label_type=\"multilabel\",\n... )\n{'count': 5,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.jaccard","title":"arkas.metric.jaccard","text":"<pre><code>jaccard(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Jaccard metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import jaccard\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; jaccard(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'jaccard': 1.0}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; jaccard(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n{'count': 5, 'jaccard': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; jaccard(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n{'count': 6,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; jaccard(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     label_type=\"multilabel\",\n... )\n{'count': 5,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.jensen_shannon_divergence","title":"arkas.metric.jensen_shannon_divergence","text":"<pre><code>jensen_shannon_divergence(\n    p: ndarray,\n    q: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Jensen-Shannon (JS) divergence between two distributions.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>ndarray</code> <p>The true probability distribution.</p> required <code>q</code> <code>ndarray</code> <p>The model probability distribution.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import jensen_shannon_divergence\n&gt;&gt;&gt; jensen_shannon_divergence(\n...     p=np.array([0.1, 0.6, 0.1, 0.2]), q=np.array([0.2, 0.5, 0.2, 0.1])\n... )\n{'size': 4, 'jensen_shannon_divergence': 0.027...}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.kl_div","title":"arkas.metric.kl_div","text":"<pre><code>kl_div(\n    p: ndarray,\n    q: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Kullback-Leibler (KL) divergence between two distributions.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>ndarray</code> <p>The true probability distribution.</p> required <code>q</code> <code>ndarray</code> <p>The model probability distribution.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import kl_div\n&gt;&gt;&gt; kl_div(p=np.array([0.1, 0.6, 0.1, 0.2]), q=np.array([0.2, 0.5, 0.2, 0.1]))\n{'size': 4, 'kl_pq': 0.109..., 'kl_qp': 0.116...}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.mean_absolute_error","title":"arkas.metric.mean_absolute_error","text":"<pre><code>mean_absolute_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the mean absolute error (MAE).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import mean_absolute_error\n&gt;&gt;&gt; mean_absolute_error(y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5]))\n{'count': 5, 'mean_absolute_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.mean_absolute_percentage_error","title":"arkas.metric.mean_absolute_percentage_error","text":"<pre><code>mean_absolute_percentage_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the mean absolute percentage error (MAPE).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import mean_absolute_percentage_error\n&gt;&gt;&gt; mean_absolute_percentage_error(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'mean_absolute_percentage_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.mean_squared_error","title":"arkas.metric.mean_squared_error","text":"<pre><code>mean_squared_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the mean squared error (MSE).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import mean_squared_error\n&gt;&gt;&gt; mean_squared_error(y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5]))\n{'count': 5, 'mean_squared_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.mean_squared_log_error","title":"arkas.metric.mean_squared_log_error","text":"<pre><code>mean_squared_log_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the mean squared logarithmic error (MSLE).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import mean_squared_log_error\n&gt;&gt;&gt; mean_squared_log_error(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'mean_squared_log_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.mean_tweedie_deviance","title":"arkas.metric.mean_tweedie_deviance","text":"<pre><code>mean_tweedie_deviance(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    powers: Sequence[float] = (0,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the mean Tweedie deviance regression loss.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>powers</code> <code>Sequence[float]</code> <p>The Tweedie power parameter. The higher power the less weight is given to extreme deviations between true and predicted targets.</p> <code>(0,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import mean_tweedie_deviance\n&gt;&gt;&gt; mean_tweedie_deviance(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'mean_tweedie_deviance_power_0': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.median_absolute_error","title":"arkas.metric.median_absolute_error","text":"<pre><code>median_absolute_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the median absolute error.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import median_absolute_error\n&gt;&gt;&gt; median_absolute_error(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'median_absolute_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_average_precision","title":"arkas.metric.multiclass_average_precision","text":"<pre><code>multiclass_average_precision(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the average precision metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_average_precision\n&gt;&gt;&gt; metrics = multiclass_average_precision(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.3, 0.5],\n...             [0.4, 0.4, 0.2],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': array([0.833..., 0.75 , 0.75 ]),\n 'count': 6,\n 'macro_average_precision': 0.777...,\n 'micro_average_precision': 0.75,\n 'weighted_average_precision': 0.777...}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_confusion_matrix","title":"arkas.metric.multiclass_confusion_matrix","text":"<pre><code>multiclass_confusion_matrix(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the confusion matrix metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_confusion_matrix\n&gt;&gt;&gt; multiclass_confusion_matrix(\n...     y_true=np.array([0, 1, 1, 2, 2, 2]), y_pred=np.array([0, 1, 1, 2, 2, 2])\n... )\n{'confusion_matrix': array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]), 'count': 6}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_fbeta_score","title":"arkas.metric.multiclass_fbeta_score","text":"<pre><code>multiclass_fbeta_score(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    betas: Sequence[float] = (1,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the F-beta metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_fbeta_score\n&gt;&gt;&gt; multiclass_fbeta_score(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n... )\n{'count': 6,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_jaccard","title":"arkas.metric.multiclass_jaccard","text":"<pre><code>multiclass_jaccard(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Jaccard metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_jaccard\n&gt;&gt;&gt; multiclass_jaccard(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]), y_pred=np.array([0, 0, 1, 1, 2, 2])\n... )\n{'count': 6,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_precision","title":"arkas.metric.multiclass_precision","text":"<pre><code>multiclass_precision(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the precision metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_precision\n&gt;&gt;&gt; multiclass_precision(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]), y_pred=np.array([0, 0, 1, 1, 2, 2])\n... )\n{'count': 6,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_recall","title":"arkas.metric.multiclass_recall","text":"<pre><code>multiclass_recall(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the recall metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multiclass_recall\n&gt;&gt;&gt; multiclass_recall(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]), y_pred=np.array([0, 0, 1, 1, 2, 2])\n... )\n{'count': 6,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multiclass_roc_auc","title":"arkas.metric.multiclass_roc_auc","text":"<pre><code>multiclass_roc_auc(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Area Under the Receiver Operating Characteristic Curve (ROC AUC) metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p>"},{"location":"refs/metric/#arkas.metric.multiclass_top_k_accuracy","title":"arkas.metric.multiclass_top_k_accuracy","text":"<pre><code>multiclass_top_k_accuracy(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    k: Sequence[int] = (2,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Area Under the Top-k Accuracy classification metrics for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>k</code> <code>Sequence[int]</code> <p>The numbers of most likely outcomes considered to find the correct label.</p> <code>(2,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p>"},{"location":"refs/metric/#arkas.metric.multilabel_average_precision","title":"arkas.metric.multilabel_average_precision","text":"<pre><code>multilabel_average_precision(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the average precision metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_average_precision\n&gt;&gt;&gt; metrics = multilabel_average_precision(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, -1], [-1, 1, 2], [0, 2, 3], [3, -2, -4], [1, -3, -5]]),\n... )\n&gt;&gt;&gt; metrics\n{'average_precision': array([1. , 1. , 0.477...]),\n 'count': 5,\n 'macro_average_precision': 0.825...,\n 'micro_average_precision': 0.588...,\n 'weighted_average_precision': 0.804...}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_confusion_matrix","title":"arkas.metric.multilabel_confusion_matrix","text":"<pre><code>multilabel_confusion_matrix(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the confusion matrix metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_confusion_matrix\n&gt;&gt;&gt; multilabel_confusion_matrix(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n{'confusion_matrix': array([[[2, 0], [0, 3]],\n                            [[3, 0], [0, 2]],\n                            [[2, 0], [0, 3]]]),\n 'count': 5}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_fbeta_score","title":"arkas.metric.multilabel_fbeta_score","text":"<pre><code>multilabel_fbeta_score(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    betas: Sequence[float] = (1,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the F-beta metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_fbeta_score\n&gt;&gt;&gt; multilabel_fbeta_score(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n{'count': 5,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_jaccard","title":"arkas.metric.multilabel_jaccard","text":"<pre><code>multilabel_jaccard(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Jaccard metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_jaccard\n&gt;&gt;&gt; multilabel_jaccard(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n{'count': 5,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_precision","title":"arkas.metric.multilabel_precision","text":"<pre><code>multilabel_precision(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the precision metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_precision\n&gt;&gt;&gt; multilabel_precision(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n{'count': 5,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_recall","title":"arkas.metric.multilabel_recall","text":"<pre><code>multilabel_recall(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the recall metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import multilabel_recall\n&gt;&gt;&gt; multilabel_recall(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n{'count': 5,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.multilabel_roc_auc","title":"arkas.metric.multilabel_roc_auc","text":"<pre><code>multilabel_roc_auc(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Area Under the Receiver Operating Characteristic Curve (ROC AUC) metrics for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p>"},{"location":"refs/metric/#arkas.metric.ndcg","title":"arkas.metric.ndcg","text":"<pre><code>ndcg(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    k: int | None = None,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Normalized Discounted Cumulative Gain (NDCG) metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target targets of multilabel classification, or true scores of entities to be ranked. Negative values in y_true may result in an output that is not between 0 and 1. This input must be an array of shape <code>(n_samples, n_labels)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The predicted scores, can either be probability estimates, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_labels)</code>.</p> required <code>k</code> <code>int | None</code> <p>Only consider the highest <code>k</code> scores in the ranking. If <code>None</code>, use all outputs.</p> <code>None</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import ndcg\n&gt;&gt;&gt; ndcg(\n...     y_true=np.array([[1, 0, 0], [1, 2, 0], [1, 1, 2], [0, 0, 1]]),\n...     y_score=np.array(\n...         [[2.0, 1.0, 0.0], [0.0, 1.0, -1.0], [0.0, 0.0, 1.0], [1.0, 2.0, 3.0]]\n...     ),\n... )\n{'count': 4, 'ndcg': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.pearsonr","title":"arkas.metric.pearsonr","text":"<pre><code>pearsonr(\n    x: ndarray,\n    y: ndarray,\n    *,\n    alternative: str = \"two-sided\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Pearson correlation coefficient and p-value for testing non-correlation.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The first input array.</p> required <code>y</code> <code>ndarray</code> <p>The second input array.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import pearsonr\n&gt;&gt;&gt; pearsonr(x=np.array([1, 2, 3, 4, 5]), y=np.array([1, 2, 3, 4, 5]))\n{'count': 5, 'pearson_coeff': 1.0, 'pearson_pvalue': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.precision","title":"arkas.metric.precision","text":"<pre><code>precision(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the precision metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import precision\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; precision(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'precision': 1.0}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; precision(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n{'count': 5, 'precision': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; precision(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n{'count': 6,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; precision(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     label_type=\"multilabel\",\n... )\n{'count': 5,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.r2_score","title":"arkas.metric.r2_score","text":"<pre><code>r2_score(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the R^2 (coefficient of determination) regression score metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import r2_score\n&gt;&gt;&gt; r2_score(y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5]))\n{'count': 5, 'r2_score': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.recall","title":"arkas.metric.recall","text":"<pre><code>recall(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the recall metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import recall\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; recall(y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1]))\n{'count': 5, 'recall': 1.0}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; recall(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n{'count': 5, 'recall': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; recall(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n{'count': 6,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; recall(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     label_type=\"multilabel\",\n... )\n{'count': 5,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.regression_errors","title":"arkas.metric.regression_errors","text":"<pre><code>regression_errors(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the regression error metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import regression_errors\n&gt;&gt;&gt; regression_errors(y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5]))\n{'count': 5,\n 'mean_absolute_error': 0.0,\n 'median_absolute_error': 0.0,\n 'mean_squared_error': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.roc_auc","title":"arkas.metric.roc_auc","text":"<pre><code>roc_auc(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    label_type: str = \"auto\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Area Under the Receiver Operating Characteristic Curve (ROC AUC) metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import roc_auc\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; metrics = roc_auc(y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1]))\n&gt;&gt;&gt; metrics\n{'count': 5, 'roc_auc': 1.0}\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; metrics = roc_auc(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_score=np.array([2, -1, 0, 3, 1]),\n...     label_type=\"binary\",\n... )\n&gt;&gt;&gt; metrics\n{'count': 5, 'roc_auc': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; metrics = roc_auc(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.3, 0.5],\n...             [0.4, 0.4, 0.2],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n...     label_type=\"multiclass\",\n... )\n&gt;&gt;&gt; metrics\n{'count': 6,\n 'macro_roc_auc': 0.833...,\n 'micro_roc_auc': 0.826...,\n 'roc_auc': array([0.9375, 0.8125, 0.75  ]),\n 'weighted_roc_auc': 0.833...}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; metrics = roc_auc(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, -1], [-1, 1, 2], [0, 2, 3], [3, -2, -4], [1, -3, -5]]),\n...     label_type=\"multilabel\",\n... )\n&gt;&gt;&gt; metrics\n{'count': 5,\n 'macro_roc_auc': 0.666...,\n 'micro_roc_auc': 0.544...,\n 'roc_auc': array([1., 1., 0.]),\n 'weighted_roc_auc': 0.625}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.root_mean_squared_error","title":"arkas.metric.root_mean_squared_error","text":"<pre><code>root_mean_squared_error(\n    y_true: ndarray,\n    y_pred: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the root mean squared error (RMSE).</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import root_mean_squared_error\n&gt;&gt;&gt; root_mean_squared_error(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'root_mean_squared_error': 0.0}\n</code></pre> Note <p>Require <code>sklearn&gt;=1.4.0</code></p>"},{"location":"refs/metric/#arkas.metric.spearmanr","title":"arkas.metric.spearmanr","text":"<pre><code>spearmanr(\n    x: ndarray,\n    y: ndarray,\n    *,\n    alternative: str = \"two-sided\",\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Spearman correlation coefficient and p-value for testing non-correlation.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The first input array.</p> required <code>y</code> <code>ndarray</code> <p>The second input array.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import spearmanr\n&gt;&gt;&gt; spearmanr(\n...     x=np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n...     y=np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n... )\n{'count': 9, 'spearman_coeff': 1.0, 'spearman_pvalue': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.top_k_accuracy","title":"arkas.metric.top_k_accuracy","text":"<pre><code>top_k_accuracy(\n    y_true: ndarray,\n    y_score: ndarray,\n    *,\n    k: Sequence[int] = (2,),\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float | ndarray]\n</code></pre> <p>Return the Area Under the Top-k Accuracy classification metrics.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. The binary case expects scores with shape <code>(n_samples,)</code> while the multiclass case expects scores with shape <code>(n_samples, n_classes)</code>.</p> required <code>k</code> <code>Sequence[int]</code> <p>The numbers of most likely outcomes considered to find the correct label.</p> <code>(2,)</code> <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float | ndarray]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import top_k_accuracy\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; metrics = top_k_accuracy(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1]), k=[1, 2]\n... )\n&gt;&gt;&gt; metrics\n{'count': 5, 'top_1_accuracy': 1.0, 'top_2_accuracy': 1.0}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; metrics = top_k_accuracy(\n...     y_true=np.array([0, 1, 2, 2]),\n...     y_score=np.array(\n...         [[0.5, 0.2, 0.2], [0.3, 0.4, 0.2], [0.2, 0.4, 0.3], [0.7, 0.2, 0.1]]\n...     ),\n...     k=[1, 2, 3],\n... )\n&gt;&gt;&gt; metrics\n{'count': 4, 'top_1_accuracy': 0.5, 'top_2_accuracy': 0.75, 'top_3_accuracy': 1.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.wasserstein_distance","title":"arkas.metric.wasserstein_distance","text":"<pre><code>wasserstein_distance(\n    u_values: ndarray,\n    v_values: ndarray,\n    *,\n    prefix: str = \"\",\n    suffix: str = \"\",\n    nan_policy: str = \"propagate\"\n) -&gt; dict[str, float]\n</code></pre> <p>Return the Wasserstein distance between two 1D discrete distributions.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>ndarray</code> <p>An array that contains a sample from a probability distribution or the support (set of all possible values) of a probability distribution. Each element is an observation or possible value.</p> required <code>v_values</code> <code>ndarray</code> <p>An array that contains a sample from or the support of a second distribution.</p> required <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>The computed metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric import wasserstein_distance\n&gt;&gt;&gt; wasserstein_distance(\n...     u_values=np.array([1, 2, 3, 4, 5]), v_values=np.array([1, 2, 3, 4, 5])\n... )\n{'count': 5, 'wasserstein_distance': 0.0}\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils","title":"arkas.metric.utils","text":"<p>Contain utility functions to compute metrics.</p>"},{"location":"refs/metric/#arkas.metric.utils.check_array_ndim","title":"arkas.metric.utils.check_array_ndim","text":"<pre><code>check_array_ndim(arr: ndarray, ndim: int) -&gt; None\n</code></pre> <p>Check if the number of array dimensions is matching the target number of dimensions.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>The array to check.</p> required <code>ndim</code> <code>int</code> <p>The targeted number of array dimensions.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if the number of array dimensions does not match.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import check_array_ndim\n&gt;&gt;&gt; check_array_ndim(np.ones((2, 3)), ndim=2)\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_label_type","title":"arkas.metric.utils.check_label_type","text":"<pre><code>check_label_type(label_type: str) -&gt; None\n</code></pre> <p>Check if the label type value is valid or not.</p> <p>Parameters:</p> Name Type Description Default <code>label_type</code> <code>str</code> <p>The type of labels. The valid values are <code>'binary'</code>, <code>'multiclass'</code>, <code>'multilabel'</code>, and <code>'auto'</code>.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if an invalid value is passed to <code>label_type</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.metric.utils import check_label_type\n&gt;&gt;&gt; check_label_type(label_type=\"binary\")\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_nan_policy","title":"arkas.metric.utils.check_nan_policy","text":"<pre><code>check_nan_policy(nan_policy: str) -&gt; None\n</code></pre> <p>Check the NaN policy.</p> <p>Parameters:</p> Name Type Description Default <code>nan_policy</code> <code>str</code> <p>The NaN policy.</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>nan_policy</code> is not <code>'omit'</code>, <code>'propagate'</code>, or <code>'raise'</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.metric.utils import check_nan_policy\n&gt;&gt;&gt; check_nan_policy(nan_policy=\"omit\")\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_nan_pred","title":"arkas.metric.utils.check_nan_pred","text":"<pre><code>check_nan_pred(y_true: ndarray, y_pred: ndarray) -&gt; None\n</code></pre> <p>Check if any array elements in <code>y_true</code> or <code>y_pred</code> arrays is a NaN value.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p><code>'y_true'</code> or <code>'y_pred'</code> has a NaN value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import check_nan_pred\n&gt;&gt;&gt; y_true = np.array([1, 0, 0, 1])\n&gt;&gt;&gt; y_pred = np.array([0, 1, 0, 1])\n&gt;&gt;&gt; check_nan_pred(y_true, y_pred)\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_same_shape","title":"arkas.metric.utils.check_same_shape","text":"<pre><code>check_same_shape(arrays: Iterable[ndarray]) -&gt; None\n</code></pre> <p>Check if arrays have the same shape.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Iterable[ndarray]</code> <p>The arrays to check.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the arrays have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import check_same_shape\n&gt;&gt;&gt; check_same_shape([np.array([1, 0, 0, 1]), np.array([0, 1, 0, 1])])\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_same_shape_pred","title":"arkas.metric.utils.check_same_shape_pred","text":"<pre><code>check_same_shape_pred(\n    y_true: ndarray, y_pred: ndarray\n) -&gt; None\n</code></pre> <p>Check if <code>y_true</code> and <code>y_pred</code> arrays have the same shape.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p><code>'y_true'</code> and <code>'y_pred'</code> have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import check_same_shape_pred\n&gt;&gt;&gt; y_true = np.array([1, 0, 0, 1])\n&gt;&gt;&gt; y_pred = np.array([0, 1, 0, 1])\n&gt;&gt;&gt; check_same_shape_pred(y_true, y_pred)\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.check_same_shape_score","title":"arkas.metric.utils.check_same_shape_score","text":"<pre><code>check_same_shape_score(\n    y_true: ndarray, y_score: ndarray\n) -&gt; None\n</code></pre> <p>Check if <code>y_true</code> and <code>y_score</code> arrays have the same shape.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p><code>'y_true'</code> and <code>'y_score'</code> have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import check_same_shape_score\n&gt;&gt;&gt; y_true = np.array([1, 0, 0, 1])\n&gt;&gt;&gt; y_score = np.array([0, 1, 0, 1])\n&gt;&gt;&gt; check_same_shape_score(y_true, y_score)\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.contains_nan","title":"arkas.metric.utils.contains_nan","text":"<pre><code>contains_nan(\n    arr: ndarray,\n    nan_policy: str = \"propagate\",\n    name: str = \"input array\",\n) -&gt; bool\n</code></pre> <p>Indicate if the given array contains at least one NaN value.</p> <p>Parameters:</p> Name Type Description Default <code>arr</code> <code>ndarray</code> <p>The array to check.</p> required <code>nan_policy</code> <code>str</code> <p>The NaN policy. The valid values are <code>'omit'</code>, <code>'propagate'</code>, or <code>'raise'</code>.</p> <code>'propagate'</code> <code>name</code> <code>str</code> <p>An optional name to be more precise about the array when the exception is raised.</p> <code>'input array'</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the array contains at least one NaN value.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>if the array contains at least one NaN value and <code>nan_policy</code> is <code>'raise'</code>.</p>"},{"location":"refs/metric/#arkas.metric.utils.multi_isnan","title":"arkas.metric.utils.multi_isnan","text":"<pre><code>multi_isnan(arrays: Sequence[ndarray]) -&gt; ndarray\n</code></pre> <p>Test element-wise for NaN for all input arrays and return result as a boolean array.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Sequence[ndarray]</code> <p>The input arrays to test. All the arrays must have the same shape.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>A boolean array. <code>True</code> where any array is NaN, <code>False</code> otherwise.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import multi_isnan\n&gt;&gt;&gt; mask = multi_isnan(\n...     [np.array([1, 0, 0, 1, float(\"nan\")]), np.array([1, float(\"nan\"), 0, 1, 1])]\n... )\n&gt;&gt;&gt; mask\narray([False,  True, False, False,  True])\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_pred","title":"arkas.metric.utils.preprocess_pred","text":"<pre><code>preprocess_pred(\n    y_true: ndarray, y_pred: ndarray, drop_nan: bool = False\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Preprocess <code>y_true</code> and <code>y_pred</code> arrays.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_pred</code> arrays.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if an invalid value is passed to <code>nan</code>.</p> <code>RuntimeError</code> <p><code>'y_true'</code> and <code>'y_pred'</code> have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_pred\n&gt;&gt;&gt; y_true = np.array([1, 0, 0, 1, 1, float(\"nan\")])\n&gt;&gt;&gt; y_pred = np.array([0, 1, 0, 1, float(\"nan\"), 1])\n&gt;&gt;&gt; preprocess_pred(y_true, y_pred)\n(array([ 1.,  0.,  0.,  1.,  1., nan]), array([ 0.,  1.,  0.,  1., nan,  1.]))\n&gt;&gt;&gt; preprocess_pred(y_true, y_pred, drop_nan=True)\n(array([1., 0., 0., 1.]), array([0., 1., 0., 1.]))\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_pred_multilabel","title":"arkas.metric.utils.preprocess_pred_multilabel","text":"<pre><code>preprocess_pred_multilabel(\n    y_true: ndarray, y_pred: ndarray, drop_nan: bool = False\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Preprocess <code>y_true</code> and <code>y_pred</code> arrays.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_pred</code> arrays.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if an invalid value is passed to <code>nan</code>.</p> <code>RuntimeError</code> <p><code>'y_true'</code> and <code>'y_pred'</code> have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_pred_multilabel\n&gt;&gt;&gt; y_true = np.array([[1, float(\"nan\"), 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]])\n&gt;&gt;&gt; y_pred = np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, float(\"nan\")]])\n&gt;&gt;&gt; preprocess_pred_multilabel(y_true, y_pred)\n(array([[ 1., nan,  1.],\n        [ 0.,  1.,  0.],\n        [ 0.,  1.,  0.],\n        [ 1.,  0.,  1.],\n        [ 1.,  0.,  1.]]),\n array([[ 1.,  0.,  1.],\n        [ 0.,  1.,  0.],\n        [ 0.,  1.,  0.],\n        [ 1.,  0.,  1.],\n        [ 1.,  0., nan]]))\n&gt;&gt;&gt; preprocess_pred_multilabel(y_true, y_pred, drop_nan=True)\n(array([[0., 1., 0.],\n        [0., 1., 0.],\n        [1., 0., 1.]]),\n array([[0., 1., 0.],\n        [0., 1., 0.],\n        [1., 0., 1.]]))\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_same_shape_arrays","title":"arkas.metric.utils.preprocess_same_shape_arrays","text":"<pre><code>preprocess_same_shape_arrays(\n    arrays: Sequence[ndarray], drop_nan: bool = False\n) -&gt; tuple[ndarray, ...]\n</code></pre> <p>Preprocess a sequence of same shape arrays.</p> <p>Parameters:</p> Name Type Description Default <code>arrays</code> <code>Sequence[ndarray]</code> <p>The arrays to preprocess.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ...]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_pred</code> arrays.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the arrays have different shapes.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_same_shape_arrays\n&gt;&gt;&gt; arrays = [\n...     np.array([1, 0, 0, 1, 1, float(\"nan\")]),\n...     np.array([0, 1, 0, 1, float(\"nan\"), 1]),\n... ]\n&gt;&gt;&gt; preprocess_same_shape_arrays(arrays)\n(array([ 1.,  0.,  0.,  1.,  1., nan]), array([ 0.,  1.,  0.,  1., nan,  1.]))\n&gt;&gt;&gt; preprocess_same_shape_arrays(arrays, drop_nan=True)\n(array([1., 0., 0., 1.]), array([0., 1., 0., 1.]))\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_score_binary","title":"arkas.metric.utils.preprocess_score_binary","text":"<pre><code>preprocess_score_binary(\n    y_true: ndarray,\n    y_score: ndarray,\n    drop_nan: bool = False,\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Preprocess <code>y_true</code> and <code>y_score</code> arrays for the binary classification case.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_score</code> arrays.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_score_binary\n&gt;&gt;&gt; y_true = np.array([1, 0, 0, 1, 1, float(\"nan\")])\n&gt;&gt;&gt; y_score = np.array([0, 1, 0, 1, float(\"nan\"), 1])\n&gt;&gt;&gt; preprocess_score_binary(y_true, y_score)\n(array([ 1.,  0.,  0.,  1.,  1., nan]), array([ 0.,  1.,  0.,  1., nan,  1.]))\n&gt;&gt;&gt; preprocess_score_binary(y_true, y_score, drop_nan=True)\n(array([1., 0., 0., 1.]), array([0., 1., 0., 1.]))\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_score_multiclass","title":"arkas.metric.utils.preprocess_score_multiclass","text":"<pre><code>preprocess_score_multiclass(\n    y_true: ndarray,\n    y_score: ndarray,\n    drop_nan: bool = False,\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Preprocess <code>y_true</code> and <code>y_score</code> arrays for the multiclass classification case.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, 1)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_score</code> arrays.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_score_multiclass\n&gt;&gt;&gt; y_true = np.array([0, 0, 1, 1, 2, float(\"nan\")])\n&gt;&gt;&gt; y_score = np.array(\n...     [\n...         [0.7, 0.2, 0.1],\n...         [0.4, 0.3, 0.3],\n...         [0.1, 0.8, float(\"nan\")],\n...         [0.2, 0.3, 0.5],\n...         [0.4, 0.4, 0.2],\n...         [0.1, 0.2, 0.7],\n...     ]\n... )\n&gt;&gt;&gt; preprocess_score_multiclass(y_true, y_score)\n(array([ 0.,  0.,  1.,  1.,  2., nan]),\n array([[0.7, 0.2, 0.1],\n        [0.4, 0.3, 0.3],\n        [0.1, 0.8, nan],\n        [0.2, 0.3, 0.5],\n        [0.4, 0.4, 0.2],\n        [0.1, 0.2, 0.7]]))\n&gt;&gt;&gt; preprocess_score_multiclass(y_true, y_score, drop_nan=True)\n(array([0., 0., 1., 2.]),\n array([[0.7, 0.2, 0.1],\n        [0.4, 0.3, 0.3],\n        [0.2, 0.3, 0.5],\n        [0.4, 0.4, 0.2]]))\n</code></pre>"},{"location":"refs/metric/#arkas.metric.utils.preprocess_score_multilabel","title":"arkas.metric.utils.preprocess_score_multilabel","text":"<pre><code>preprocess_score_multilabel(\n    y_true: ndarray,\n    y_score: ndarray,\n    drop_nan: bool = False,\n) -&gt; tuple[ndarray, ndarray]\n</code></pre> <p>Preprocess <code>y_true</code> and <code>y_score</code> arrays for the multilabel classification case.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> or <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> or <code>(n_samples,)</code>.</p> required <code>drop_nan</code> <code>bool</code> <p>If <code>True</code>, the NaN values are removed, otherwise they are kept.</p> <code>False</code> <p>Returns:</p> Type Description <code>tuple[ndarray, ndarray]</code> <p>A tuple with the preprocessed <code>y_true</code> and <code>y_score</code> arrays.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.metric.utils import preprocess_score_multilabel\n&gt;&gt;&gt; y_true = np.array([[1, float(\"nan\"), 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]])\n&gt;&gt;&gt; y_score = np.array(\n...     [[2, -1, -1], [-1, 1, 2], [0, 2, 3], [3, -2, -4], [1, float(\"nan\"), -5]]\n... )\n&gt;&gt;&gt; preprocess_score_multilabel(y_true, y_score)\n(array([[ 1., nan,  1.],\n        [ 0.,  1.,  0.],\n        [ 0.,  1.,  0.],\n        [ 1.,  0.,  1.],\n        [ 1.,  0.,  1.]]),\n array([[ 2., -1., -1.],\n        [-1.,  1.,  2.],\n        [ 0.,  2.,  3.],\n        [ 3., -2., -4.],\n        [ 1., nan, -5.]]))\n&gt;&gt;&gt; preprocess_score_multilabel(y_true, y_score, drop_nan=True)\n(array([[0., 1., 0.],\n        [0., 1., 0.],\n        [1., 0., 1.]]),\n array([[-1.,  1.,  2.],\n        [ 0.,  2.,  3.],\n        [ 3., -2., -4.]]))\n</code></pre>"},{"location":"refs/output/","title":"arkas.output","text":""},{"location":"refs/output/#arkas.output","title":"arkas.output","text":"<p>Contain data outputs.</p>"},{"location":"refs/output/#arkas.output.AccuracyOutput","title":"arkas.output.AccuracyOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement the accuracy output.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AccuracyState</code> <p>The state containing the ground truth and predicted labels.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output\nAccuracyOutput(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n&gt;&gt;&gt; output.get_content_generator()\nAccuracyContentGenerator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n&gt;&gt;&gt; output.get_evaluator()\nAccuracyEvaluator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/output/#arkas.output.BalancedAccuracyOutput","title":"arkas.output.BalancedAccuracyOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement the balanced accuracy output.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>AccuracyState</code> <p>The state containing the ground truth and predicted labels.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import BalancedAccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = BalancedAccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output\nBalancedAccuracyOutput(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n&gt;&gt;&gt; output.get_content_generator()\nBalancedAccuracyContentGenerator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n&gt;&gt;&gt; output.get_evaluator()\nBalancedAccuracyEvaluator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/output/#arkas.output.BaseLazyOutput","title":"arkas.output.BaseLazyOutput","text":"<p>               Bases: <code>BaseOutput</code></p> <p>Define a base class that partially implements the lazy computation logic.</p>"},{"location":"refs/output/#arkas.output.BaseOutput","title":"arkas.output.BaseOutput","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement an output.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output\nAccuracyOutput(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.BaseOutput.compute","title":"arkas.output.BaseOutput.compute  <code>abstractmethod</code>","text":"<pre><code>compute() -&gt; BaseOutput\n</code></pre> <p>Compute the results and return a new ouptut.</p> <p>Returns:</p> Type Description <code>BaseOutput</code> <p>A new ouptut with the computed results.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output\nAccuracyOutput(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n&gt;&gt;&gt; out = output.compute()\n&gt;&gt;&gt; out\nOutput(\n  (content): ContentGenerator()\n  (evaluator): Evaluator(count=5)\n  (plotter): Plotter(count=0)\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.BaseOutput.equal","title":"arkas.output.BaseOutput.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two outputs are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other output to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two outputs are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output1 = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output2 = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output3 = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 0, 0]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output1.equal(output2)\nTrue\n&gt;&gt;&gt; output1.equal(output3)\nFalse\n</code></pre>"},{"location":"refs/output/#arkas.output.BaseOutput.get_content_generator","title":"arkas.output.BaseOutput.get_content_generator  <code>abstractmethod</code>","text":"<pre><code>get_content_generator(\n    lazy: bool = True,\n) -&gt; BaseContentGenerator\n</code></pre> <p>Get the HTML content generator associated to the output.</p> <p>Parameters:</p> Name Type Description Default <code>lazy</code> <code>bool</code> <p>If <code>True</code>, it forces the computation of the content, otherwise it returns a content generator object that contains the logic to generate the content.</p> <code>True</code> <p>Returns:</p> Type Description <code>BaseContentGenerator</code> <p>The HTML content generator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output.get_content_generator()\nAccuracyContentGenerator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.BaseOutput.get_evaluator","title":"arkas.output.BaseOutput.get_evaluator  <code>abstractmethod</code>","text":"<pre><code>get_evaluator(lazy: bool = True) -&gt; BaseEvaluator\n</code></pre> <p>Get the evaluator associated to the output.</p> <p>Parameters:</p> Name Type Description Default <code>lazy</code> <code>bool</code> <p>If <code>True</code>, it forces the computation of the metrics, otherwise it returns an evaluator object that contains the logic to evaluate the metrics.</p> <code>True</code> <p>Returns:</p> Type Description <code>BaseEvaluator</code> <p>The evaluator.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output.get_evaluator()\nAccuracyEvaluator(\n  (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.BaseOutput.get_plotter","title":"arkas.output.BaseOutput.get_plotter  <code>abstractmethod</code>","text":"<pre><code>get_plotter(lazy: bool = True) -&gt; BasePlotter\n</code></pre> <p>Get the plotter associated to the output.</p> <p>Parameters:</p> Name Type Description Default <code>lazy</code> <code>bool</code> <p>If <code>True</code>, it forces the computation of the figures, otherwise it returns a plotter object that contains the logic to generate the figures.</p> <code>True</code> <p>Returns:</p> Type Description <code>BasePlotter</code> <p>The plotter.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import AccuracyOutput\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = AccuracyOutput(\n...     AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/output/#arkas.output.ColumnCooccurrenceOutput","title":"arkas.output.ColumnCooccurrenceOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement the pairwise column co-occurrence output.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>ColumnCooccurrenceState</code> <p>The state with the co-occurrence matrix.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import ColumnCooccurrenceOutput\n&gt;&gt;&gt; from arkas.state import ColumnCooccurrenceState\n&gt;&gt;&gt; output = ColumnCooccurrenceOutput(\n...     ColumnCooccurrenceState(matrix=np.ones((3, 3)), columns=[\"a\", \"b\", \"c\"])\n... )\n&gt;&gt;&gt; output\nColumnCooccurrenceOutput(\n  (state): ColumnCooccurrenceState(matrix=(3, 3), figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_content_generator()\nColumnCooccurrenceContentGenerator(\n  (state): ColumnCooccurrenceState(matrix=(3, 3), figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_evaluator()\nColumnCooccurrenceEvaluator(\n  (state): ColumnCooccurrenceState(matrix=(3, 3), figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_plotter()\nColumnCooccurrencePlotter(\n  (state): ColumnCooccurrenceState(matrix=(3, 3), figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.ColumnCorrelationOutput","title":"arkas.output.ColumnCorrelationOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement an output to summarize the numeric columns of a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>TargetDataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.output import ColumnCorrelationOutput\n&gt;&gt;&gt; from arkas.state import TargetDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...         \"col2\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...     },\n... )\n&gt;&gt;&gt; output = ColumnCorrelationOutput(TargetDataFrameState(frame, target_column=\"col3\"))\n&gt;&gt;&gt; output\nColumnCorrelationOutput(\n  (state): TargetDataFrameState(dataframe=(7, 3), target_column='col3', nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_content_generator()\nColumnCorrelationContentGenerator(\n  (state): TargetDataFrameState(dataframe=(7, 3), target_column='col3', nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_evaluator()\nColumnCorrelationEvaluator(\n  (state): TargetDataFrameState(dataframe=(7, 3), target_column='col3', nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/output/#arkas.output.ContentOutput","title":"arkas.output.ContentOutput","text":"<p>               Bases: <code>Output</code></p> <p>Implement a simple content output.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The HTML content.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.output import ContentOutput\n&gt;&gt;&gt; output = ContentOutput(\"meow\")\n&gt;&gt;&gt; output\nContentOutput(\n  (content): ContentGenerator()\n  (evaluator): Evaluator(count=0)\n  (plotter): Plotter(count=0)\n)\n&gt;&gt;&gt; output.get_content_generator()\nContentGenerator()\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/output/#arkas.output.ContinuousSeriesOutput","title":"arkas.output.ContinuousSeriesOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement an output to analyze a series with continuous values.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>SeriesState</code> <p>The state containing the Series to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.output import ContinuousSeriesOutput\n&gt;&gt;&gt; from arkas.state import SeriesState\n&gt;&gt;&gt; output = ContinuousSeriesOutput(SeriesState(pl.Series(\"col1\", [1, 2, 3, 4, 5, 6, 7])))\n&gt;&gt;&gt; output\nContinuousSeriesOutput(\n  (state): SeriesState(name='col1', values=(7,), figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_content_generator()\nContinuousSeriesContentGenerator(\n  (state): SeriesState(name='col1', values=(7,), figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nContinuousSeriesPlotter(\n  (state): SeriesState(name='col1', values=(7,), figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.CorrelationOutput","title":"arkas.output.CorrelationOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement an output to summarize the numeric columns of a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>DataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.output import CorrelationOutput\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...         \"col2\": [7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0],\n...     },\n... )\n&gt;&gt;&gt; output = CorrelationOutput(DataFrameState(frame))\n&gt;&gt;&gt; output\nCorrelationOutput(\n  (state): DataFrameState(dataframe=(7, 2), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_content_generator()\nCorrelationContentGenerator(\n  (state): DataFrameState(dataframe=(7, 2), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_evaluator()\nCorrelationEvaluator(\n  (state): DataFrameState(dataframe=(7, 2), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_plotter()\nCorrelationPlotter(\n  (state): DataFrameState(dataframe=(7, 2), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.EmptyOutput","title":"arkas.output.EmptyOutput","text":"<p>               Bases: <code>Output</code></p> <p>Implement the accuracy output.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.output import EmptyOutput\n&gt;&gt;&gt; output = EmptyOutput()\n&gt;&gt;&gt; output\nEmptyOutput()\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/output/#arkas.output.NullValueOutput","title":"arkas.output.NullValueOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement an output to analyze the number of null values per column.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>NullValueState</code> <p>The state containing the number of null values per column.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import NullValueOutput\n&gt;&gt;&gt; from arkas.state import NullValueState\n&gt;&gt;&gt; output = NullValueOutput(\n...     NullValueState(\n...         null_count=np.array([0, 1, 2]),\n...         total_count=np.array([5, 5, 5]),\n...         columns=[\"col1\", \"col2\", \"col3\"],\n...     )\n... )\n&gt;&gt;&gt; output\nNullValueOutput(\n  (state): NullValueState(num_columns=3, figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_content_generator()\nNullValueContentGenerator(\n  (state): NullValueState(num_columns=3, figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nNullValuePlotter(\n  (state): NullValueState(num_columns=3, figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.NumericSummaryOutput","title":"arkas.output.NumericSummaryOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement an output to summarize the numeric columns of a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>DataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.output import NumericSummaryOutput\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...     },\n...     schema={\"col1\": pl.Int64, \"col2\": pl.Int32, \"col3\": pl.Float64},\n... )\n&gt;&gt;&gt; output = NumericSummaryOutput(DataFrameState(frame))\n&gt;&gt;&gt; output\nNumericSummaryOutput(\n  (state): DataFrameState(dataframe=(7, 3), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_content_generator()\nNumericSummaryContentGenerator(\n  (state): DataFrameState(dataframe=(7, 3), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/output/#arkas.output.Output","title":"arkas.output.Output","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement a simple output.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>BaseContentGenerator</code> <p>The HTML content generator.</p> required <code>evaluator</code> <code>BaseEvaluator</code> <p>The evaluator.</p> required <code>plotter</code> <code>BasePlotter</code> <p>The plotter.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.output import Output\n&gt;&gt;&gt; from arkas.content import ContentGenerator\n&gt;&gt;&gt; from arkas.evaluator2 import Evaluator\n&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; output = Output(\n...     content=ContentGenerator(\"meow\"), evaluator=Evaluator(), plotter=Plotter()\n... )\n&gt;&gt;&gt; output\nOutput(\n  (content): ContentGenerator()\n  (evaluator): Evaluator(count=0)\n  (plotter): Plotter(count=0)\n)\n&gt;&gt;&gt; output.get_content_generator()\nContentGenerator()\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/output/#arkas.output.OutputDict","title":"arkas.output.OutputDict","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement an output that combines a mapping of output objects into a single output object.</p> <p>Parameters:</p> Name Type Description Default <code>outputs</code> <code>Mapping[str, BaseOutput]</code> <p>The mapping of output objects to combine.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.output import OutputDict, Output, AccuracyOutput\n&gt;&gt;&gt; from arkas.content import ContentGenerator\n&gt;&gt;&gt; from arkas.evaluator2 import Evaluator\n&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; output = OutputDict(\n...     {\n...         \"one\": Output(\n...             content=ContentGenerator(\"meow\"), evaluator=Evaluator(), plotter=Plotter()\n...         ),\n...         \"two\": AccuracyOutput(\n...             AccuracyState(\n...                 y_true=np.array([1, 0, 0, 1, 1]),\n...                 y_pred=np.array([1, 0, 0, 1, 1]),\n...                 y_true_name=\"target\",\n...                 y_pred_name=\"pred\",\n...             )\n...         ),\n...     }\n... )\n&gt;&gt;&gt; output\nOutputDict(count=2)\n&gt;&gt;&gt; output.get_content_generator()\nContentGeneratorDict(\n  (one): ContentGenerator()\n  (two): AccuracyContentGenerator(\n      (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n    )\n)\n&gt;&gt;&gt; output.get_evaluator()\nEvaluatorDict(\n  (one): Evaluator(count=0)\n  (two): AccuracyEvaluator(\n      (state): AccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n    )\n)\n&gt;&gt;&gt; output.get_plotter()\nPlotterDict(\n  (one): Plotter(count=0)\n  (two): Plotter(count=0)\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.PlotColumnOutput","title":"arkas.output.PlotColumnOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement an output to plot each column of a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>DataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.output import PlotColumnOutput\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.2, 4.2, 4.2, 2.2],\n...         \"col2\": [1, 1, 1, 1],\n...         \"col3\": [1, 2, 2, 2],\n...     },\n...     schema={\"col1\": pl.Float64, \"col2\": pl.Int64, \"col3\": pl.Int64},\n... )\n&gt;&gt;&gt; output = PlotColumnOutput(DataFrameState(frame))\n&gt;&gt;&gt; output\nPlotColumnOutput(\n  (state): DataFrameState(dataframe=(4, 3), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_content_generator()\nPlotColumnContentGenerator(\n  (state): DataFrameState(dataframe=(4, 3), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nPlotColumnPlotter(\n  (state): DataFrameState(dataframe=(4, 3), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.ScatterColumnOutput","title":"arkas.output.ScatterColumnOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement an output to scatter plot some columns.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>ScatterDataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.output import ScatterColumnOutput\n&gt;&gt;&gt; from arkas.state import ScatterDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0],\n...         \"col2\": [0, 1, 0, 1],\n...         \"col3\": [1, 0, 0, 0],\n...     },\n...     schema={\"col1\": pl.Int64, \"col2\": pl.Int64, \"col3\": pl.Int64},\n... )\n&gt;&gt;&gt; output = ScatterColumnOutput(ScatterDataFrameState(frame, x=\"col1\", y=\"col2\"))\n&gt;&gt;&gt; output\nScatterColumnOutput(\n  (state): ScatterDataFrameState(dataframe=(4, 3), x='col1', y='col2', color=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_content_generator()\nScatterColumnContentGenerator(\n  (state): ScatterDataFrameState(dataframe=(4, 3), x='col1', y='col2', color=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nScatterColumnPlotter(\n  (state): ScatterDataFrameState(dataframe=(4, 3), x='col1', y='col2', color=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.SummaryOutput","title":"arkas.output.SummaryOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement the DataFrame summary output.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The DataFrame to analyze.</p> required <code>top</code> <code>int</code> <p>The number of most frequent values to show.</p> <code>5</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.output import SummaryOutput\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.2, 4.2, 4.2, 2.2],\n...         \"col2\": [1, 1, 1, 1],\n...         \"col3\": [1, 2, 2, 2],\n...     },\n...     schema={\"col1\": pl.Float64, \"col2\": pl.Int64, \"col3\": pl.Int64},\n... )\n&gt;&gt;&gt; output = SummaryOutput(frame)\n&gt;&gt;&gt; output\nSummaryOutput(shape=(4, 3), top=5)\n&gt;&gt;&gt; output.get_content_generator()\nSummaryContentGenerator(shape=(4, 3), top=5)\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nPlotter(count=0)\n</code></pre>"},{"location":"refs/output/#arkas.output.TemporalNullValueOutput","title":"arkas.output.TemporalNullValueOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement an output to analyze the number of null values in a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>TemporalDataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.output import TemporalNullValueOutput\n&gt;&gt;&gt; from arkas.state import TemporalDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0],\n...         \"col2\": [0, 1, 0, 1],\n...         \"col3\": [1, 0, 0, 0],\n...         \"datetime\": [\n...             datetime(year=2020, month=1, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=2, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=3, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=4, day=3, tzinfo=timezone.utc),\n...         ],\n...     },\n...     schema={\n...         \"col1\": pl.Int64,\n...         \"col2\": pl.Int64,\n...         \"col3\": pl.Int64,\n...         \"datetime\": pl.Datetime(time_unit=\"us\", time_zone=\"UTC\"),\n...     },\n... )\n&gt;&gt;&gt; output = TemporalNullValueOutput(\n...     TemporalDataFrameState(frame, temporal_column=\"datetime\")\n... )\n&gt;&gt;&gt; output\nTemporalNullValueOutput(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_content_generator()\nTemporalNullValueContentGenerator(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nTemporalNullValuePlotter(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/output/#arkas.output.TemporalPlotColumnOutput","title":"arkas.output.TemporalPlotColumnOutput","text":"<p>               Bases: <code>BaseLazyOutput</code></p> <p>Implement an output to plot each column of a DataFrame along a temporal dimension.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>TemporalDataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.output import TemporalPlotColumnOutput\n&gt;&gt;&gt; from arkas.state import TemporalDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0],\n...         \"col2\": [0, 1, 0, 1],\n...         \"col3\": [1, 0, 0, 0],\n...         \"datetime\": [\n...             datetime(year=2020, month=1, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=2, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=3, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=4, day=3, tzinfo=timezone.utc),\n...         ],\n...     },\n...     schema={\n...         \"col1\": pl.Int64,\n...         \"col2\": pl.Int64,\n...         \"col3\": pl.Int64,\n...         \"datetime\": pl.Datetime(time_unit=\"us\", time_zone=\"UTC\"),\n...     },\n... )\n&gt;&gt;&gt; output = TemporalPlotColumnOutput(\n...     TemporalDataFrameState(frame, temporal_column=\"datetime\")\n... )\n&gt;&gt;&gt; output\nTemporalPlotColumnOutput(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_content_generator()\nTemporalPlotColumnContentGenerator(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n&gt;&gt;&gt; output.get_evaluator()\nEvaluator(count=0)\n&gt;&gt;&gt; output.get_plotter()\nTemporalPlotColumnPlotter(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/plot/","title":"arkas.plot","text":""},{"location":"refs/plot/#arkas.plot","title":"arkas.plot","text":"<p>Contain plotting functionalities.</p>"},{"location":"refs/plot/#arkas.plot.bar_discrete","title":"arkas.plot.bar_discrete","text":"<pre><code>bar_discrete(\n    ax: Axes,\n    names: Sequence,\n    counts: Sequence[int],\n    yscale: str = \"auto\",\n) -&gt; None\n</code></pre> <p>Plot the histogram of an array containing discrete values.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes of the matplotlib figure to update.</p> required <code>names</code> <code>Sequence</code> <p>The name of the values to plot.</p> required <code>counts</code> <code>Sequence[int]</code> <p>The number of value occurrences.</p> required <code>yscale</code> <code>str</code> <p>The y-axis scale. If <code>'auto'</code>, the <code>'linear'</code> or <code>'log'/'symlog'</code> scale is chosen based on the distribution.</p> <code>'auto'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import bar_discrete\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; bar_discrete(ax, names=[\"a\", \"b\", \"c\", \"d\"], counts=[5, 100, 42, 27])\n</code></pre>"},{"location":"refs/plot/#arkas.plot.bar_discrete_temporal","title":"arkas.plot.bar_discrete_temporal","text":"<pre><code>bar_discrete_temporal(\n    ax: Axes,\n    counts: ndarray,\n    steps: Sequence | None = None,\n    values: Sequence | None = None,\n    proportion: bool = False,\n) -&gt; None\n</code></pre> <p>Plot the temporal distribution of discrete values.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes of the matplotlib figure to update.</p> required <code>counts</code> <code>ndarray</code> <p>A 2-d array that indicates the number of occurrences for each value and time step. The first dimension represents the value and the second dimension represents the steps.</p> required <code>steps</code> <code>Sequence | None</code> <p>The name associated to each step.</p> <code>None</code> <code>values</code> <code>Sequence | None</code> <p>The name associated to each value.</p> <code>None</code> <code>proportion</code> <code>bool</code> <p>If <code>True</code>, it plots the normalized number of occurrences for each step.</p> <code>False</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import bar_discrete_temporal\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; bar_discrete_temporal(\n...     ax, counts=np.ones((5, 20)), values=list(range(5)), steps=list(range(20))\n... )\n</code></pre>"},{"location":"refs/plot/#arkas.plot.binary_precision_recall_curve","title":"arkas.plot.binary_precision_recall_curve","text":"<pre><code>binary_precision_recall_curve(\n    ax: Axes,\n    y_true: ndarray,\n    y_pred: ndarray,\n    **kwargs: Any\n) -&gt; None\n</code></pre> <p>Plot the precision-recall curve for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes of the matplotlib figure to update.</p> required <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> with <code>0</code> and <code>1</code> values.</p> required <code>**kwargs</code> <code>Any</code> <p>Arbitrary keyword arguments that are passed to <code>PrecisionRecallDisplay.from_predictions</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import binary_precision_recall_curve\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; binary_precision_recall_curve(\n...     ax=ax, y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n</code></pre>"},{"location":"refs/plot/#arkas.plot.binary_roc_curve","title":"arkas.plot.binary_roc_curve","text":"<pre><code>binary_roc_curve(\n    ax: Axes,\n    y_true: ndarray,\n    y_score: ndarray,\n    **kwargs: Any\n) -&gt; None\n</code></pre> <p>Plot the Receiver Operating Characteristic Curve (ROC) for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes of the matplotlib figure to update.</p> required <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code>.</p> required <code>**kwargs</code> <code>Any</code> <p>Arbitrary keyword arguments that are passed to <code>RocCurveDisplay.from_predictions</code>.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import binary_roc_curve\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; binary_roc_curve(\n...     ax=ax, y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1])\n... )\n</code></pre>"},{"location":"refs/plot/#arkas.plot.boxplot_continuous","title":"arkas.plot.boxplot_continuous","text":"<pre><code>boxplot_continuous(\n    ax: Axes,\n    array: ndarray,\n    xmin: float | str | None = None,\n    xmax: float | str | None = None,\n) -&gt; None\n</code></pre> <p>Plot the histogram of an array containing continuous values.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes of the matplotlib figure to update.</p> required <code>array</code> <code>ndarray</code> <p>The array with the data.</p> required <code>xmin</code> <code>float | str | None</code> <p>The minimum value of the range or its associated quantile. <code>q0.1</code> means the 10% quantile. <code>0</code> is the minimum value and <code>1</code> is the maximum value.</p> <code>None</code> <code>xmax</code> <code>float | str | None</code> <p>The maximum value of the range or its associated quantile. <code>q0.9</code> means the 90% quantile. <code>0</code> is the minimum value and <code>1</code> is the maximum value.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import boxplot_continuous\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; boxplot_continuous(ax, array=np.arange(101))\n</code></pre>"},{"location":"refs/plot/#arkas.plot.boxplot_continuous_temporal","title":"arkas.plot.boxplot_continuous_temporal","text":"<pre><code>boxplot_continuous_temporal(\n    ax: Axes,\n    data: Sequence[ndarray],\n    steps: Sequence,\n    ymin: float | str | None = None,\n    ymax: float | str | None = None,\n    yscale: str = \"linear\",\n) -&gt; None\n</code></pre> <p>Plot the histogram of an array containing continuous values.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes of the matplotlib figure to update.</p> required <code>data</code> <code>Sequence[ndarray]</code> <p>The sequence of data where each item is a 1-d array with the values of the time step.</p> required <code>steps</code> <code>Sequence</code> <p>The sequence time step names.</p> required <code>ymin</code> <code>float | str | None</code> <p>The minimum value of the range or its associated quantile. <code>q0.1</code> means the 10% quantile. <code>0</code> is the minimum value and <code>1</code> is the maximum value.</p> <code>None</code> <code>ymax</code> <code>float | str | None</code> <p>The maximum value of the range or its associated quantile. <code>q0.9</code> means the 90% quantile. <code>0</code> is the minimum value and <code>1</code> is the maximum value.</p> <code>None</code> <code>yscale</code> <code>str</code> <p>The y-axis scale. If <code>'auto'</code>, the <code>'linear'</code> or <code>'log'/'symlog'</code> scale is chosen based on the distribution.</p> <code>'linear'</code> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if <code>data</code> and <code>steps</code> have different lengths</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import boxplot_continuous_temporal\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; rng = np.random.default_rng()\n&gt;&gt;&gt; data = [rng.standard_normal(1000) for _ in range(10)]\n&gt;&gt;&gt; boxplot_continuous_temporal(ax, data=data, steps=list(range(len(data))))\n</code></pre>"},{"location":"refs/plot/#arkas.plot.hist_continuous","title":"arkas.plot.hist_continuous","text":"<pre><code>hist_continuous(\n    ax: Axes,\n    array: ndarray,\n    nbins: int | None = None,\n    density: bool = False,\n    yscale: str = \"linear\",\n    xmin: float | str | None = None,\n    xmax: float | str | None = None,\n    cdf: bool = True,\n    quantile: bool = True,\n) -&gt; None\n</code></pre> <p>Plot the histogram of an array containing continuous values.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes of the matplotlib figure to update.</p> required <code>array</code> <code>ndarray</code> <p>The array with the data.</p> required <code>nbins</code> <code>int | None</code> <p>The number of bins to use to plot.</p> <code>None</code> <code>density</code> <code>bool</code> <p>If True, draw and return a probability density: each bin will display the bin's raw count divided by the total number of counts and the bin width, so that the area under the histogram integrates to 1.</p> <code>False</code> <code>yscale</code> <code>str</code> <p>The y-axis scale. If <code>'auto'</code>, the <code>'linear'</code> or <code>'log'/'symlog'</code> scale is chosen based on the distribution.</p> <code>'linear'</code> <code>xmin</code> <code>float | str | None</code> <p>The minimum value of the range or its associated quantile. <code>q0.1</code> means the 10% quantile. <code>0</code> is the minimum value and <code>1</code> is the maximum value.</p> <code>None</code> <code>xmax</code> <code>float | str | None</code> <p>The maximum value of the range or its associated quantile. <code>q0.9</code> means the 90% quantile. <code>0</code> is the minimum value and <code>1</code> is the maximum value.</p> <code>None</code> <code>cdf</code> <code>bool</code> <p>If <code>True</code>, the CDF is added to the plot.</p> <code>True</code> <code>quantile</code> <code>bool</code> <p>If <code>True</code>, the 5% and 95% quantiles are added to the plot.</p> <code>True</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import hist_continuous\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; hist_continuous(ax, array=np.arange(101))\n</code></pre>"},{"location":"refs/plot/#arkas.plot.hist_continuous2","title":"arkas.plot.hist_continuous2","text":"<pre><code>hist_continuous2(\n    ax: Axes,\n    array1: ndarray,\n    array2: ndarray,\n    label1: str = \"first\",\n    label2: str = \"second\",\n    nbins: int | None = None,\n    density: bool = False,\n    yscale: str = \"linear\",\n    xmin: float | str | None = None,\n    xmax: float | str | None = None,\n) -&gt; None\n</code></pre> <p>Plot the histogram of two arrays to compare the distributions.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes of the matplotlib figure to update.</p> required <code>array1</code> <code>ndarray</code> <p>The first array with the data.</p> required <code>array2</code> <code>ndarray</code> <p>The second array with the data.</p> required <code>label1</code> <code>str</code> <p>The label associated to the first array.</p> <code>'first'</code> <code>label2</code> <code>str</code> <p>The label associated to the second array.</p> <code>'second'</code> <code>nbins</code> <code>int | None</code> <p>The number of bins to use to plot.</p> <code>None</code> <code>density</code> <code>bool</code> <p>If True, draw and return a probability density: each bin will display the bin's raw count divided by the total number of counts and the bin width, so that the area under the histogram integrates to 1.</p> <code>False</code> <code>yscale</code> <code>str</code> <p>The y-axis scale. If <code>'auto'</code>, the <code>'linear'</code> or <code>'log'/'symlog'</code> scale is chosen based on the distribution.</p> <code>'linear'</code> <code>xmin</code> <code>float | str | None</code> <p>The minimum value of the range or its associated quantile. <code>q0.1</code> means the 10% quantile. <code>0</code> is the minimum value and <code>1</code> is the maximum value.</p> <code>None</code> <code>xmax</code> <code>float | str | None</code> <p>The maximum value of the range or its associated quantile. <code>q0.9</code> means the 90% quantile. <code>0</code> is the minimum value and <code>1</code> is the maximum value.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import hist_continuous2\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; hist_continuous2(ax, array1=np.arange(101), array2=np.arange(51))\n</code></pre>"},{"location":"refs/plot/#arkas.plot.plot_cdf","title":"arkas.plot.plot_cdf","text":"<pre><code>plot_cdf(\n    ax: Axes,\n    array: ndarray,\n    nbins: int | None = None,\n    xmin: float = float(\"-inf\"),\n    xmax: float = float(\"inf\"),\n    color: str = \"tab:blue\",\n    labelcolor: str = \"black\",\n) -&gt; None\n</code></pre> <p>Plot the cumulative distribution function (CDF).</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The axes of the matplotlib figure to update.</p> required <code>array</code> <code>ndarray</code> <p>The array with the data.</p> required <code>nbins</code> <code>int | None</code> <p>The number of bins to use to plot the CDF.</p> <code>None</code> <code>xmin</code> <code>float</code> <p>The minimum value of the range or its associated quantile. <code>q0.1</code> means the 10% quantile. <code>0</code> is the minimum value and <code>1</code> is the maximum value.</p> <code>float('-inf')</code> <code>xmax</code> <code>float</code> <p>The maximum value of the range or its associated quantile. <code>q0.9</code> means the 90% quantile. <code>0</code> is the minimum value and <code>1</code> is the maximum value.</p> <code>float('inf')</code> <code>color</code> <code>str</code> <p>The plot color.</p> <code>'tab:blue'</code> <code>labelcolor</code> <code>str</code> <p>The label color.</p> <code>'black'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import plot_cdf\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; plot_cdf(ax, array=np.arange(101))\n</code></pre>"},{"location":"refs/plot/#arkas.plot.plot_null_temporal","title":"arkas.plot.plot_null_temporal","text":"<pre><code>plot_null_temporal(\n    ax: Axes,\n    nulls: Sequence,\n    totals: Sequence,\n    labels: Sequence,\n) -&gt; None\n</code></pre> <p>Plot the temporal distribution of the number of missing values.</p> <p><code>nulls</code>, <code>totals</code>, and <code>labels</code> must have the same length and have the same order.</p> <p>Parameters:</p> Name Type Description Default <code>ax</code> <code>Axes</code> <p>The Axes object that encapsulates all the elements of an individual (sub-)plot in a figure.</p> required <code>nulls</code> <code>Sequence</code> <p>The number of null values for each temporal period.</p> required <code>totals</code> <code>Sequence</code> <p>The number of total values for each temporal period.</p> required <code>labels</code> <code>Sequence</code> <p>The labels for each temporal period.</p> required <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if <code>nulls</code>, <code>totals</code>, and <code>labels</code> have different lengths.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.plot import plot_null_temporal\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; plot_null_temporal(\n...     ax, nulls=[1, 2, 3, 4], totals=[10, 12, 14, 16], labels=[\"jan\", \"feb\", \"mar\", \"apr\"]\n... )\n</code></pre>"},{"location":"refs/plotter/","title":"arkas.plotter","text":""},{"location":"refs/plotter/#arkas.plotter","title":"arkas.plotter","text":"<p>Contain data plotters.</p>"},{"location":"refs/plotter/#arkas.plotter.BasePlotter","title":"arkas.plotter.BasePlotter","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement a plotter.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; plotter = Plotter()\n&gt;&gt;&gt; plotter\nPlotter(count=0)\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.BasePlotter.compute","title":"arkas.plotter.BasePlotter.compute  <code>abstractmethod</code>","text":"<pre><code>compute() -&gt; BasePlotter\n</code></pre> <p>Compute the figures and return a new plotter.</p> <p>Returns:</p> Type Description <code>BasePlotter</code> <p>A new plotter with the computed figures.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; plotter = Plotter({\"fig\": None})\n&gt;&gt;&gt; plotter\nPlotter(count=1)\n&gt;&gt;&gt; plotter2 = plotter.compute()\n&gt;&gt;&gt; plotter2\nPlotter(count=1)\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.BasePlotter.equal","title":"arkas.plotter.BasePlotter.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two plotters are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other plotter to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two plotters are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; plotter1 = Plotter()\n&gt;&gt;&gt; plotter2 = Plotter()\n&gt;&gt;&gt; plotter3 = Plotter({\"fig\": None})\n&gt;&gt;&gt; plotter1.equal(plotter2)\nTrue\n&gt;&gt;&gt; plotter1.equal(plotter3)\nFalse\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.BasePlotter.plot","title":"arkas.plotter.BasePlotter.plot  <code>abstractmethod</code>","text":"<pre><code>plot(prefix: str = '', suffix: str = '') -&gt; dict\n</code></pre> <p>Generate the figures.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary with the generated figures.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; plotter = Plotter()\n&gt;&gt;&gt; plotter.plot()\n{}\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.ColumnCooccurrencePlotter","title":"arkas.plotter.ColumnCooccurrencePlotter","text":"<p>               Bases: <code>BasePlotter</code></p> <p>Implement a pairwise column co-occurrence plotter.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>ColumnCooccurrenceState</code> <p>The state with the co-occurrence matrix.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.plotter import ColumnCooccurrencePlotter\n&gt;&gt;&gt; from arkas.state import ColumnCooccurrenceState\n&gt;&gt;&gt; plotter = ColumnCooccurrencePlotter(\n...     ColumnCooccurrenceState(matrix=np.ones((3, 3)), columns=[\"a\", \"b\", \"c\"])\n... )\n&gt;&gt;&gt; plotter\nColumnCooccurrencePlotter(\n  (state): ColumnCooccurrenceState(matrix=(3, 3), figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.ContinuousSeriesPlotter","title":"arkas.plotter.ContinuousSeriesPlotter","text":"<p>               Bases: <code>BasePlotter</code></p> <p>Implement a plotter that analyzes a column with continuous values.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>SeriesState</code> <p>The state containing the Series to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.plotter import ContinuousSeriesPlotter\n&gt;&gt;&gt; from arkas.state import SeriesState\n&gt;&gt;&gt; plotter = ContinuousSeriesPlotter(SeriesState(pl.Series(\"col1\", [1, 2, 3, 4, 5, 6, 7])))\n&gt;&gt;&gt; plotter\nContinuousSeriesPlotter(\n  (state): SeriesState(name='col1', values=(7,), figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.CorrelationPlotter","title":"arkas.plotter.CorrelationPlotter","text":"<p>               Bases: <code>BasePlotter</code></p> <p>Implement a DataFrame column plotter.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>DataFrameState</code> <p>The state containing the DataFrame to analyze. The DataFrame must have only 2 columns, which are the two columns to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.plotter import CorrelationPlotter\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...         \"col3\": [2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0],\n...     },\n... )\n&gt;&gt;&gt; plotter = CorrelationPlotter(DataFrameState(frame))\n&gt;&gt;&gt; plotter\nCorrelationPlotter(\n  (state): DataFrameState(dataframe=(7, 2), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.NullValuePlotter","title":"arkas.plotter.NullValuePlotter","text":"<p>               Bases: <code>BasePlotter</code></p> <p>Implement a plotter that plots the number of null values for each column.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>NullValueState</code> <p>The state containing the number of null values per column.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.plotter import NullValuePlotter\n&gt;&gt;&gt; from arkas.state import NullValueState\n&gt;&gt;&gt; plotter = NullValuePlotter(\n...     NullValueState(\n...         null_count=np.array([0, 1, 2]),\n...         total_count=np.array([5, 5, 5]),\n...         columns=[\"col1\", \"col2\", \"col3\"],\n...     )\n... )\n&gt;&gt;&gt; plotter\nNullValuePlotter(\n  (state): NullValueState(num_columns=3, figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.PlotColumnPlotter","title":"arkas.plotter.PlotColumnPlotter","text":"<p>               Bases: <code>BasePlotter</code></p> <p>Implement a DataFrame column plotter.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>DataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.plotter import PlotColumnPlotter\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.2, 4.2, 4.2, 2.2],\n...         \"col2\": [1, 1, 1, 1],\n...         \"col3\": [1, 2, 2, 2],\n...     },\n...     schema={\"col1\": pl.Float64, \"col2\": pl.Int64, \"col3\": pl.Int64},\n... )\n&gt;&gt;&gt; plotter = PlotColumnPlotter(DataFrameState(frame))\n&gt;&gt;&gt; plotter\nPlotColumnPlotter(\n  (state): DataFrameState(dataframe=(4, 3), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.Plotter","title":"arkas.plotter.Plotter","text":"<p>               Bases: <code>BasePlotter</code></p> <p>Implement a simple plotter.</p> <p>Parameters:</p> Name Type Description Default <code>figures</code> <code>dict | None</code> <p>The dictionary of figures.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.plotter import Plotter\n&gt;&gt;&gt; plotter = Plotter()\n&gt;&gt;&gt; plotter\nPlotter(count=0)\n&gt;&gt;&gt; plotter.plot()\n{}\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.PlotterDict","title":"arkas.plotter.PlotterDict","text":"<p>               Bases: <code>BasePlotter</code></p> <p>Implement a plotter that generates figures from a mapping of plotters.</p> <p>Parameters:</p> Name Type Description Default <code>plotters</code> <code>Mapping[Hashable, BasePlotter]</code> <p>The mapping of plotters.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.plotter import PlotterDict, Plotter\n&gt;&gt;&gt; plotter = PlotterDict(\n...     {\n...         \"one\": Plotter(),\n...         \"two\": Plotter({\"fig\": None}),\n...     }\n... )\n&gt;&gt;&gt; plotter\nPlotterDict(\n  (one): Plotter(count=0)\n  (two): Plotter(count=1)\n)\n&gt;&gt;&gt; figures = plotter.plot()\n&gt;&gt;&gt; figures\n{'one': {}, 'two': {'fig': None}}\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.ScatterColumnPlotter","title":"arkas.plotter.ScatterColumnPlotter","text":"<p>               Bases: <code>BasePlotter</code></p> <p>Implement a DataFrame column plotter.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>ScatterDataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.plotter import ScatterColumnPlotter\n&gt;&gt;&gt; from arkas.state import ScatterDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [1.2, 4.2, 4.2, 2.2],\n...         \"col2\": [1, 1, 1, 1],\n...         \"col3\": [1, 2, 2, 2],\n...     },\n...     schema={\"col1\": pl.Float64, \"col2\": pl.Int64, \"col3\": pl.Int64},\n... )\n&gt;&gt;&gt; plotter = ScatterColumnPlotter(\n...     ScatterDataFrameState(frame, x=\"col1\", y=\"col2\", color=\"col3\")\n... )\n&gt;&gt;&gt; plotter\nScatterColumnPlotter(\n  (state): ScatterDataFrameState(dataframe=(4, 3), x='col1', y='col2', color='col3', nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.TemporalNullValuePlotter","title":"arkas.plotter.TemporalNullValuePlotter","text":"<p>               Bases: <code>BasePlotter</code></p> <p>Implement a DataFrame column plotter.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>TemporalDataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.plotter import TemporalNullValuePlotter\n&gt;&gt;&gt; from arkas.state import TemporalDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0],\n...         \"col2\": [0, 1, 0, 1],\n...         \"col3\": [1, 0, 0, 0],\n...         \"datetime\": [\n...             datetime(year=2020, month=1, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=2, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=3, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=4, day=3, tzinfo=timezone.utc),\n...         ],\n...     },\n...     schema={\n...         \"col1\": pl.Int64,\n...         \"col2\": pl.Int64,\n...         \"col3\": pl.Int64,\n...         \"datetime\": pl.Datetime(time_unit=\"us\", time_zone=\"UTC\"),\n...     },\n... )\n&gt;&gt;&gt; plotter = TemporalNullValuePlotter(\n...     TemporalDataFrameState(frame, temporal_column=\"datetime\", period=\"1d\")\n... )\n&gt;&gt;&gt; plotter\nTemporalNullValuePlotter(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period='1d', nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/plotter/#arkas.plotter.TemporalPlotColumnPlotter","title":"arkas.plotter.TemporalPlotColumnPlotter","text":"<p>               Bases: <code>BasePlotter</code></p> <p>Implement a DataFrame column plotter.</p> <p>Parameters:</p> Name Type Description Default <code>state</code> <code>TemporalDataFrameState</code> <p>The state containing the DataFrame to analyze.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.plotter import TemporalPlotColumnPlotter\n&gt;&gt;&gt; from arkas.state import TemporalDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0],\n...         \"col2\": [0, 1, 0, 1],\n...         \"col3\": [1, 0, 0, 0],\n...         \"datetime\": [\n...             datetime(year=2020, month=1, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=2, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=3, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=4, day=3, tzinfo=timezone.utc),\n...         ],\n...     },\n...     schema={\n...         \"col1\": pl.Int64,\n...         \"col2\": pl.Int64,\n...         \"col3\": pl.Int64,\n...         \"datetime\": pl.Datetime(time_unit=\"us\", time_zone=\"UTC\"),\n...     },\n... )\n&gt;&gt;&gt; plotter = TemporalPlotColumnPlotter(\n...     TemporalDataFrameState(frame, temporal_column=\"datetime\")\n... )\n&gt;&gt;&gt; plotter\nTemporalPlotColumnPlotter(\n  (state): TemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n)\n</code></pre>"},{"location":"refs/reporter/","title":"arkas.reporter","text":""},{"location":"refs/reporter/#arkas.reporter","title":"arkas.reporter","text":"<p>Contain reporters.</p>"},{"location":"refs/reporter/#arkas.reporter.BaseReporter","title":"arkas.reporter.BaseReporter","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to generate a HTML report.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.reporter import EvalReporter\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     reporter = EvalReporter(\n...         ingestor=Ingestor(\n...             pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         evaluator=AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         report_path=Path(tmpdir).joinpath(\"report.html\"),\n...     )\n...     reporter.generate()\n...\n</code></pre>"},{"location":"refs/reporter/#arkas.reporter.BaseReporter.generate","title":"arkas.reporter.BaseReporter.generate  <code>abstractmethod</code>","text":"<pre><code>generate() -&gt; None\n</code></pre> <p>Generate a HTML report.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.reporter import EvalReporter\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     reporter = EvalReporter(\n...         ingestor=Ingestor(\n...             pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         evaluator=AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         report_path=Path(tmpdir).joinpath(\"report.html\"),\n...     )\n...     reporter.generate()\n...\n</code></pre>"},{"location":"refs/reporter/#arkas.reporter.EvalReporter","title":"arkas.reporter.EvalReporter","text":"<p>               Bases: <code>BaseReporter</code></p> <p>Implement a simple reporter that evaluates results and writes them in a HTML file.</p> <p>Parameters:</p> Name Type Description Default <code>ingestor</code> <code>BaseIngestor | dict</code> <p>The ingestor or its configuration.</p> required <code>transformer</code> <code>BaseTransformer | dict</code> <p>The data transformer or its configuration.</p> required <code>evaluator</code> <code>BaseEvaluator | dict</code> <p>The evaluator or its configuration.</p> required <code>report_path</code> <code>Path | str</code> <p>The path where to save the HTML report.</p> required <code>max_toc_depth</code> <code>int</code> <p>The maximum level to show in the table of content.</p> <code>6</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.reporter import EvalReporter\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     reporter = EvalReporter(\n...         ingestor=Ingestor(\n...             pl.DataFrame({\"pred\": [3, 2, 0, 1, 0, 1], \"target\": [3, 2, 0, 1, 0, 1]})\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         evaluator=AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         report_path=Path(tmpdir).joinpath(\"report.html\"),\n...     )\n...     reporter.generate()\n...\n</code></pre>"},{"location":"refs/reporter/#arkas.reporter.Reporter","title":"arkas.reporter.Reporter","text":"<p>               Bases: <code>BaseReporter</code></p> <p>Implement a simple reporter that generates a HTML file and save it.</p> <p>Parameters:</p> Name Type Description Default <code>report_path</code> <code>Path | str</code> <p>The path where to save the HTML report.</p> required <code>max_toc_depth</code> <code>int</code> <p>The maximum level to show in the table of content.</p> <code>6</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.content import AccuracyContentGenerator\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; from arkas.reporter import Reporter\n&gt;&gt;&gt; generator = AccuracyContentGenerator(\n...     state=AccuracyState(\n...         y_true=np.array([1, 0, 0, 1, 1]),\n...         y_pred=np.array([1, 0, 0, 1, 1]),\n...         y_true_name=\"target\",\n...         y_pred_name=\"pred\",\n...     )\n... )\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     reporter = Reporter(\n...         report_path=Path(tmpdir).joinpath(\"report.html\"),\n...     )\n...     reporter.generate(generator)\n...\n</code></pre>"},{"location":"refs/reporter/#arkas.reporter.is_reporter_config","title":"arkas.reporter.is_reporter_config","text":"<pre><code>is_reporter_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseReporter</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseReporter</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.reporter import is_reporter_config\n&gt;&gt;&gt; is_reporter_config(\n...     {\n...         \"_target_\": \"arkas.reporter.EvalReporter\",\n...         \"ingestor\": {\n...             \"_target_\": \"grizz.ingestor.CsvIngestor\",\n...             \"path\": \"/path/to/data.csv\",\n...         },\n...         \"transformer\": {\"_target_\": \"grizz.transformer.DropDuplicate\"},\n...         \"evaluator\": {\n...             \"_target_\": \"arkas.evaluator.AccuracyEvaluator\",\n...             \"y_true\": \"target\",\n...             \"y_pred\": \"pred\",\n...         },\n...         \"report_path\": \"/path/to/report.html\",\n...     }\n... )\nTrue\n</code></pre>"},{"location":"refs/reporter/#arkas.reporter.setup_reporter","title":"arkas.reporter.setup_reporter","text":"<pre><code>setup_reporter(\n    reporter: BaseReporter | dict,\n) -&gt; BaseReporter\n</code></pre> <p>Set up a reporter.</p> <p>The reporter is instantiated from its configuration by using the <code>BaseReporter</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>reporter</code> <code>BaseReporter | dict</code> <p>A reporter or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseReporter</code> <p>An instantiated reporter.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.reporter import setup_reporter\n&gt;&gt;&gt; reporter = setup_reporter(\n...     {\n...         \"_target_\": \"arkas.reporter.EvalReporter\",\n...         \"ingestor\": {\n...             \"_target_\": \"grizz.ingestor.CsvIngestor\",\n...             \"path\": \"/path/to/data.csv\",\n...         },\n...         \"transformer\": {\"_target_\": \"grizz.transformer.DropDuplicate\"},\n...         \"evaluator\": {\n...             \"_target_\": \"arkas.evaluator.AccuracyEvaluator\",\n...             \"y_true\": \"target\",\n...             \"y_pred\": \"pred\",\n...         },\n...         \"report_path\": \"/path/to/report.html\",\n...     }\n... )\n&gt;&gt;&gt; reporter\nEvalReporter(\n  (ingestor): CsvIngestor(path=/path/to/data.csv)\n  (transformer): DropDuplicateTransformer(columns=None, exclude_columns=(), missing_policy='raise')\n  (evaluator): AccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n  (report_path): /path/to/report.html\n  (max_toc_depth): 6\n)\n</code></pre>"},{"location":"refs/result/","title":"arkas.result","text":""},{"location":"refs/result/#arkas.result","title":"arkas.result","text":"<p>Contain results.</p>"},{"location":"refs/result/#arkas.result.AccuracyResult","title":"arkas.result.AccuracyResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the accuracy result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; result = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.AveragePrecisionResult","title":"arkas.result.AveragePrecisionResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the average precision result.</p> <p>This result can be used in 3 different settings:</p> <ul> <li>binary: <code>y_true</code> must be an array of shape <code>(*)</code>     with <code>0</code> and <code>1</code> values, and <code>y_score</code> must be an array     of shape <code>(*)</code>.</li> <li>multiclass: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with values in <code>{0, ..., n_classes-1}</code>, and <code>y_score</code> must     be an array of shape <code>(n_samples, n_classes)</code>.</li> <li>multilabel: <code>y_true</code> must be an array of shape     <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values, and     <code>y_score</code> must be an array of shape     <code>(n_samples, n_classes)</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, <code>'multilabel'</code>, and <code>'auto'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>. If <code>'auto'</code>, it tries to automatically find the label type from the arrays' shape.</p> <code>'auto'</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AveragePrecisionResult\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; result = AveragePrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_score=np.array([2, -1, 0, 3, 1]),\n...     label_type=\"binary\",\n... )\n&gt;&gt;&gt; result\nAveragePrecisionResult(y_true=(5,), y_score=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': 1.0, 'count': 5}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; result = AveragePrecisionResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, -1], [-1, 1, 2], [0, 2, 3], [3, -2, -4], [1, -3, -5]]),\n...     label_type=\"multilabel\",\n... )\n&gt;&gt;&gt; result\nAveragePrecisionResult(y_true=(5, 3), y_score=(5, 3), label_type='multilabel', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': array([1. , 1. , 0.477...]),\n 'count': 5,\n 'macro_average_precision': 0.825...,\n 'micro_average_precision': 0.588...,\n 'weighted_average_precision': 0.804...}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; result = AveragePrecisionResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.3, 0.5],\n...             [0.4, 0.4, 0.2],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n...     label_type=\"multiclass\",\n... )\n&gt;&gt;&gt; result\nAveragePrecisionResult(y_true=(6,), y_score=(6, 3), label_type='multiclass', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': array([0.833..., 0.75 , 0.75 ]),\n 'count': 6,\n 'macro_average_precision': 0.777...,\n 'micro_average_precision': 0.75,\n 'weighted_average_precision': 0.777...}\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; result = AveragePrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_score=np.array([2, -1, 0, 3, 1]),\n... )\n&gt;&gt;&gt; result\nAveragePrecisionResult(y_true=(5,), y_score=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': 1.0, 'count': 5}\n</code></pre>"},{"location":"refs/result/#arkas.result.BalancedAccuracyResult","title":"arkas.result.BalancedAccuracyResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the balanced accuracy result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; result = BalancedAccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBalancedAccuracyResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'balanced_accuracy': 1.0, 'count': 5}\n</code></pre>"},{"location":"refs/result/#arkas.result.BaseResult","title":"arkas.result.BaseResult","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to manage results.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; result = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nAccuracyResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BaseResult.compute_metrics","title":"arkas.result.BaseResult.compute_metrics  <code>abstractmethod</code>","text":"<pre><code>compute_metrics(prefix: str = '', suffix: str = '') -&gt; dict\n</code></pre> <p>Return the metrics associated to the result.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict</code> <p>The metrics.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; result = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 1.0, 'count_correct': 5, 'count_incorrect': 0, 'count': 5, 'error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BaseResult.equal","title":"arkas.result.BaseResult.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two results are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other result to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two results are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; res1 = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; res2 = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; res3 = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 0, 0]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; res1.equal(res2)\nTrue\n&gt;&gt;&gt; res1.equal(res3)\nFalse\n</code></pre>"},{"location":"refs/result/#arkas.result.BaseResult.generate_figures","title":"arkas.result.BaseResult.generate_figures  <code>abstractmethod</code>","text":"<pre><code>generate_figures(\n    prefix: str = \"\", suffix: str = \"\"\n) -&gt; dict[str, Figure]\n</code></pre> <p>Return the figures associated to the result.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>The key prefix in the returned dictionary.</p> <code>''</code> <code>suffix</code> <code>str</code> <p>The key suffix in the returned dictionary.</p> <code>''</code> <p>Returns:</p> Type Description <code>dict[str, Figure]</code> <p>The figures.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; result = AccuracyResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result.generate_figures()\n{}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryAveragePrecisionResult","title":"arkas.result.BinaryAveragePrecisionResult","text":"<p>               Bases: <code>BaseAveragePrecisionResult</code></p> <p>Implement the average precision result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryAveragePrecisionResult\n&gt;&gt;&gt; result = BinaryAveragePrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1])\n... )\n&gt;&gt;&gt; result\nBinaryAveragePrecisionResult(y_true=(5,), y_score=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': 1.0, 'count': 5}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryClassificationResult","title":"arkas.result.BinaryClassificationResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the default binary classification result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target binary labels. This input must be an array of shape <code>(n_samples,)</code> where the values are <code>0</code> or <code>1</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted binary labels. This input must be an array of shape <code>(n_samples,)</code> where the values are <code>0</code> or <code>1</code>.</p> required <code>y_score</code> <code>ndarray | None</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions.</p> <code>None</code> <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryClassificationResult\n&gt;&gt;&gt; result = BinaryClassificationResult(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_score=np.array([2, -1, 0, 3, 1]),\n... )\n&gt;&gt;&gt; result\nBinaryClassificationResult(y_true=(5,), y_pred=(5,), y_score=(5,), betas=(1,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 1.0,\n 'count_correct': 5,\n 'count_incorrect': 0,\n 'count': 5,\n 'error': 0.0,\n 'balanced_accuracy': 1.0,\n 'confusion_matrix': array([[2, 0], [0, 3]]),\n 'false_negative_rate': 0.0,\n 'false_negative': 0,\n 'false_positive_rate': 0.0,\n 'false_positive': 0,\n 'true_negative_rate': 1.0,\n 'true_negative': 2,\n 'true_positive_rate': 1.0,\n 'true_positive': 3,\n 'f1': 1.0,\n 'jaccard': 1.0,\n 'precision': 1.0,\n 'recall': 1.0,\n 'average_precision': 1.0,\n 'roc_auc': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryConfusionMatrixResult","title":"arkas.result.BinaryConfusionMatrixResult","text":"<p>               Bases: <code>BaseConfusionMatrixResult</code></p> <p>Implement the confusion matrix result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryConfusionMatrixResult\n&gt;&gt;&gt; result = BinaryConfusionMatrixResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBinaryConfusionMatrixResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'confusion_matrix': array([[2, 0], [0, 3]]),\n 'count': 5,\n 'false_negative_rate': 0.0,\n 'false_negative': 0,\n 'false_positive_rate': 0.0,\n 'false_positive': 0,\n 'true_negative_rate': 1.0,\n 'true_negative': 2,\n 'true_positive_rate': 1.0,\n 'true_positive': 3}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryFbetaScoreResult","title":"arkas.result.BinaryFbetaScoreResult","text":"<p>               Bases: <code>BaseFbetaScoreResult</code></p> <p>Implement the F-beta result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryFbetaScoreResult\n&gt;&gt;&gt; result = BinaryFbetaScoreResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBinaryFbetaScoreResult(y_true=(5,), y_pred=(5,), betas=(1,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'f1': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryJaccardResult","title":"arkas.result.BinaryJaccardResult","text":"<p>               Bases: <code>BaseJaccardResult</code></p> <p>Implement the Jaccard result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryJaccardResult\n&gt;&gt;&gt; result = BinaryJaccardResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBinaryJaccardResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'jaccard': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryPrecisionResult","title":"arkas.result.BinaryPrecisionResult","text":"<p>               Bases: <code>BasePrecisionResult</code></p> <p>Implement the precision result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryPrecisionResult\n&gt;&gt;&gt; result = BinaryPrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBinaryPrecisionResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryRecallResult","title":"arkas.result.BinaryRecallResult","text":"<p>               Bases: <code>BaseRecallResult</code></p> <p>Implement the recall result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryRecallResult\n&gt;&gt;&gt; result = BinaryRecallResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nBinaryRecallResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'recall': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.BinaryRocAucResult","title":"arkas.result.BinaryRocAucResult","text":"<p>               Bases: <code>BaseRocAucResult</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) result for binary labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, *)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import BinaryRocAucResult\n&gt;&gt;&gt; result = BinaryRocAucResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_score=np.array([2, -1, 0, 3, 1])\n... )\n&gt;&gt;&gt; result\nBinaryRocAucResult(y_true=(5,), y_score=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'roc_auc': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.EmptyResult","title":"arkas.result.EmptyResult","text":"<p>               Bases: <code>Result</code></p> <p>Implement an empty result.</p> <p>This result is designed to be used when it is possible to evaluate a result.</p>"},{"location":"refs/result/#arkas.result.EnergyDistanceResult","title":"arkas.result.EnergyDistanceResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the energy distance between two 1D distributions result.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>v_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import EnergyDistanceResult\n&gt;&gt;&gt; result = EnergyDistanceResult(\n...     u_values=np.array([1, 2, 3, 4, 5]), v_values=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nEnergyDistanceResult(u_values=(5,), v_values=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'energy_distance': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.JensenShannonDivergenceResult","title":"arkas.result.JensenShannonDivergenceResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the Jensen-Shannon (JS) divergence between two 1D distributions result.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>ndarray</code> <p>The true probability distribution.</p> required <code>q</code> <code>ndarray</code> <p>The model probability distribution.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import JensenShannonDivergenceResult\n&gt;&gt;&gt; result = JensenShannonDivergenceResult(\n...     p=np.array([0.1, 0.6, 0.1, 0.2]), q=np.array([0.2, 0.5, 0.2, 0.1])\n... )\n&gt;&gt;&gt; result\nJensenShannonDivergenceResult(p=(4,), q=(4,))\n&gt;&gt;&gt; result.compute_metrics()\n{'size': 4, 'jensen_shannon_divergence': 0.027...}\n</code></pre>"},{"location":"refs/result/#arkas.result.KLDivResult","title":"arkas.result.KLDivResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the Kullback-Leibler (KL) divergence between two 1D distributions result.</p> <p>Parameters:</p> Name Type Description Default <code>p</code> <code>ndarray</code> <p>The true probability distribution.</p> required <code>q</code> <code>ndarray</code> <p>The model probability distribution.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import KLDivResult\n&gt;&gt;&gt; result = KLDivResult(p=np.array([0.1, 0.6, 0.1, 0.2]), q=np.array([0.2, 0.5, 0.2, 0.1]))\n&gt;&gt;&gt; result\nKLDivResult(p=(4,), q=(4,))\n&gt;&gt;&gt; result.compute_metrics()\n{'size': 4, 'kl_pq': 0.109..., 'kl_qp': 0.116...}\n</code></pre>"},{"location":"refs/result/#arkas.result.MappingResult","title":"arkas.result.MappingResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement a result that combines a mapping of result objects into a single result object.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Mapping[str, BaseResult]</code> <p>The mapping of result objects to combine.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MappingResult, Result\n&gt;&gt;&gt; result = MappingResult(\n...     {\n...         \"class1\": Result(metrics={\"accuracy\": 62.0, \"count\": 42}),\n...         \"class2\": Result(metrics={\"accuracy\": 42.0, \"count\": 42}),\n...     }\n... )\n&gt;&gt;&gt; result\nMappingResult(count=2)\n&gt;&gt;&gt; result.compute_metrics()\n{'class1': {'accuracy': 62.0, 'count': 42}, 'class2': {'accuracy': 42.0, 'count': 42}}\n</code></pre>"},{"location":"refs/result/#arkas.result.MeanAbsoluteErrorResult","title":"arkas.result.MeanAbsoluteErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean absolute error (MAE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MeanAbsoluteErrorResult\n&gt;&gt;&gt; result = MeanAbsoluteErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMeanAbsoluteErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'mean_absolute_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MeanAbsolutePercentageErrorResult","title":"arkas.result.MeanAbsolutePercentageErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean absolute percentage error (MAPE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MeanAbsolutePercentageErrorResult\n&gt;&gt;&gt; result = MeanAbsolutePercentageErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMeanAbsolutePercentageErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'mean_absolute_percentage_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MeanSquaredErrorResult","title":"arkas.result.MeanSquaredErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean squared error (MSE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MeanSquaredErrorResult\n&gt;&gt;&gt; result = MeanSquaredErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMeanSquaredErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'mean_squared_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MeanSquaredLogErrorResult","title":"arkas.result.MeanSquaredLogErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean squared logarithmic error (MSLE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MeanSquaredLogErrorResult\n&gt;&gt;&gt; result = MeanSquaredLogErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMeanSquaredLogErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'mean_squared_log_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MeanTweedieDevianceResult","title":"arkas.result.MeanTweedieDevianceResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean Tweedie deviance regression loss result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>powers</code> <code>Sequence[float]</code> <p>The Tweedie power parameter. The higher power the less weight is given to extreme deviations between true and predicted targets.</p> <code>(0,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MeanTweedieDevianceResult\n&gt;&gt;&gt; result = MeanTweedieDevianceResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMeanTweedieDevianceResult(y_true=(5,), y_pred=(5,), powers=(0,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'mean_tweedie_deviance_power_0': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MedianAbsoluteErrorResult","title":"arkas.result.MedianAbsoluteErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the median absolute error (MAE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MedianAbsoluteErrorResult\n&gt;&gt;&gt; result = MedianAbsoluteErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nMedianAbsoluteErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'median_absolute_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassAveragePrecisionResult","title":"arkas.result.MulticlassAveragePrecisionResult","text":"<p>               Bases: <code>BaseAveragePrecisionResult</code></p> <p>Implement the average precision result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassAveragePrecisionResult\n&gt;&gt;&gt; result = MulticlassAveragePrecisionResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.5, 0.3],\n...             [0.3, 0.3, 0.4],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n... )\n&gt;&gt;&gt; result\nMulticlassAveragePrecisionResult(y_true=(6,), y_score=(6, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': array([1., 1., 1.]),\n 'count': 6,\n 'macro_average_precision': 1.0,\n 'micro_average_precision': 1.0,\n 'weighted_average_precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassConfusionMatrixResult","title":"arkas.result.MulticlassConfusionMatrixResult","text":"<p>               Bases: <code>BaseConfusionMatrixResult</code></p> <p>Implement the confusion matrix result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassConfusionMatrixResult\n&gt;&gt;&gt; result = MulticlassConfusionMatrixResult(\n...     y_true=np.array([0, 1, 1, 2, 2, 2]),\n...     y_pred=np.array([0, 1, 1, 2, 2, 2]),\n... )\n&gt;&gt;&gt; result\nMulticlassConfusionMatrixResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'confusion_matrix': array([[1, 0, 0], [0, 2, 0], [0, 0, 3]]), 'count': 6}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassFbetaScoreResult","title":"arkas.result.MulticlassFbetaScoreResult","text":"<p>               Bases: <code>BaseFbetaScoreResult</code></p> <p>Implement the F-beta result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassFbetaScoreResult\n&gt;&gt;&gt; result = MulticlassFbetaScoreResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n... )\n&gt;&gt;&gt; result\nMulticlassFbetaScoreResult(y_true=(6,), y_pred=(6,), betas=(1,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassJaccardResult","title":"arkas.result.MulticlassJaccardResult","text":"<p>               Bases: <code>BaseJaccardResult</code></p> <p>Implement the Jaccard result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassJaccardResult\n&gt;&gt;&gt; result = MulticlassJaccardResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n... )\n&gt;&gt;&gt; result\nMulticlassJaccardResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassPrecisionResult","title":"arkas.result.MulticlassPrecisionResult","text":"<p>               Bases: <code>BasePrecisionResult</code></p> <p>Implement the precision result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassPrecisionResult\n&gt;&gt;&gt; result = MulticlassPrecisionResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n... )\n&gt;&gt;&gt; result\nMulticlassPrecisionResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassRecallResult","title":"arkas.result.MulticlassRecallResult","text":"<p>               Bases: <code>BaseRecallResult</code></p> <p>Implement the recall result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, *)</code> with values in <code>{0, ..., n_classes-1}</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassRecallResult\n&gt;&gt;&gt; result = MulticlassRecallResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n... )\n&gt;&gt;&gt; result\nMulticlassRecallResult(y_true=(6,), y_pred=(6,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MulticlassRocAucResult","title":"arkas.result.MulticlassRocAucResult","text":"<p>               Bases: <code>BaseRocAucResult</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) result for multiclass labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MulticlassRocAucResult\n&gt;&gt;&gt; result = MulticlassRocAucResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_score=np.array(\n...         [\n...             [0.7, 0.2, 0.1],\n...             [0.4, 0.3, 0.3],\n...             [0.1, 0.8, 0.1],\n...             [0.2, 0.5, 0.3],\n...             [0.3, 0.3, 0.4],\n...             [0.1, 0.2, 0.7],\n...         ]\n...     ),\n... )\n&gt;&gt;&gt; result\nMulticlassRocAucResult(y_true=(6,), y_score=(6, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'macro_roc_auc': 1.0,\n 'micro_roc_auc': 1.0,\n 'roc_auc': array([1., 1., 1.]),\n 'weighted_roc_auc': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelAveragePrecisionResult","title":"arkas.result.MultilabelAveragePrecisionResult","text":"<p>               Bases: <code>BaseAveragePrecisionResult</code></p> <p>Implement the average precision result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelAveragePrecisionResult\n&gt;&gt;&gt; result = MultilabelAveragePrecisionResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, 1], [-1, 1, -2], [0, 2, -3], [3, -2, 4], [1, -3, 5]]),\n... )\n&gt;&gt;&gt; result\nMultilabelAveragePrecisionResult(y_true=(5, 3), y_score=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'average_precision': array([1., 1., 1.]),\n 'count': 5,\n 'macro_average_precision': 1.0,\n 'micro_average_precision': 1.0,\n 'weighted_average_precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelConfusionMatrixResult","title":"arkas.result.MultilabelConfusionMatrixResult","text":"<p>               Bases: <code>BaseConfusionMatrixResult</code></p> <p>Implement the confusion matrix result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelConfusionMatrixResult\n&gt;&gt;&gt; result = MultilabelConfusionMatrixResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n&gt;&gt;&gt; result\nMultilabelConfusionMatrixResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'confusion_matrix': array([[[2, 0], [0, 3]],\n                            [[3, 0], [0, 2]],\n                            [[2, 0], [0, 3]]]),\n 'count': 5}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelFbetaScoreResult","title":"arkas.result.MultilabelFbetaScoreResult","text":"<p>               Bases: <code>BaseFbetaScoreResult</code></p> <p>Implement the F-beta result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>betas</code> <code>Sequence[float]</code> <p>The betas used to compute the F-beta scores.</p> <code>(1,)</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelFbetaScoreResult\n&gt;&gt;&gt; result = MultilabelFbetaScoreResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n&gt;&gt;&gt; result\nMultilabelFbetaScoreResult(y_true=(5, 3), y_pred=(5, 3), betas=(1,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'f1': array([1., 1., 1.]),\n 'macro_f1': 1.0,\n 'micro_f1': 1.0,\n 'weighted_f1': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelJaccardResult","title":"arkas.result.MultilabelJaccardResult","text":"<p>               Bases: <code>BaseJaccardResult</code></p> <p>Implement the Jaccard result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelJaccardResult\n&gt;&gt;&gt; result = MultilabelJaccardResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n&gt;&gt;&gt; result\nMultilabelJaccardResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'jaccard': array([1., 1., 1.]),\n 'macro_jaccard': 1.0,\n 'micro_jaccard': 1.0,\n 'weighted_jaccard': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelPrecisionResult","title":"arkas.result.MultilabelPrecisionResult","text":"<p>               Bases: <code>BasePrecisionResult</code></p> <p>Implement the precision result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelPrecisionResult\n&gt;&gt;&gt; result = MultilabelPrecisionResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n&gt;&gt;&gt; result\nMultilabelPrecisionResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelRecallResult","title":"arkas.result.MultilabelRecallResult","text":"<p>               Bases: <code>BaseRecallResult</code></p> <p>Implement the recall result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelRecallResult\n&gt;&gt;&gt; result = MultilabelRecallResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n... )\n&gt;&gt;&gt; result\nMultilabelRecallResult(y_true=(5, 3), y_pred=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.MultilabelRocAucResult","title":"arkas.result.MultilabelRocAucResult","text":"<p>               Bases: <code>BaseRocAucResult</code></p> <p>Implement the Area Under the Receiver Operating Characteristic Curve (ROC AUC) result for multilabel labels.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values.</p> required <code>y_score</code> <code>ndarray</code> <p>The target scores, can either be probability estimates of the positive class, confidence values, or non-thresholded measure of decisions. This input must be an array of shape <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import MultilabelRocAucResult\n&gt;&gt;&gt; result = MultilabelRocAucResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_score=np.array([[2, -1, 1], [-1, 1, -2], [0, 2, -3], [3, -2, 4], [1, -3, 5]]),\n... )\n&gt;&gt;&gt; result\nMultilabelRocAucResult(y_true=(5, 3), y_score=(5, 3), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'macro_roc_auc': 1.0,\n 'micro_roc_auc': 1.0,\n 'roc_auc': array([1., 1., 1.]),\n 'weighted_roc_auc': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.PearsonCorrelationResult","title":"arkas.result.PearsonCorrelationResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the Pearson correlation result.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The first input array.</p> required <code>y</code> <code>ndarray</code> <p>The second input array.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import PearsonCorrelationResult\n&gt;&gt;&gt; result = PearsonCorrelationResult(\n...     x=np.array([1, 2, 3, 4, 5]), y=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nPearsonCorrelationResult(x=(5,), y=(5,), alternative='two-sided', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'pearson_coeff': 1.0, 'pearson_pvalue': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.PrecisionResult","title":"arkas.result.PrecisionResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the precision result.</p> <p>This result can be used in 3 different settings:</p> <ul> <li>binary: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with <code>0</code> and <code>1</code> values, and <code>y_pred</code> must be an array     of shape <code>(n_samples,)</code>.</li> <li>multiclass: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with values in <code>{0, ..., n_classes-1}</code>, and <code>y_pred</code> must     be an array of shape <code>(n_samples,)</code>.</li> <li>multilabel: <code>y_true</code> must be an array of shape     <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values, and     <code>y_pred</code> must be an array of shape     <code>(n_samples, n_classes)</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import PrecisionResult\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; result = PrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n&gt;&gt;&gt; result\nPrecisionResult(y_true=(5,), y_pred=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'precision': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; result = PrecisionResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]]),\n...     label_type=\"multilabel\",\n... )\n&gt;&gt;&gt; result\nPrecisionResult(y_true=(5, 3), y_pred=(5, 3), label_type='multilabel', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'macro_precision': 0.666...,\n 'micro_precision': 0.714...,\n 'precision': array([1., 1., 0.]),\n 'weighted_precision': 0.625}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; result = PrecisionResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n&gt;&gt;&gt; result\nPrecisionResult(y_true=(6,), y_pred=(6,), label_type='multiclass', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'macro_precision': 1.0,\n 'micro_precision': 1.0,\n 'precision': array([1., 1., 1.]),\n 'weighted_precision': 1.0}\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; result = PrecisionResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nPrecisionResult(y_true=(5,), y_pred=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'precision': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.R2ScoreResult","title":"arkas.result.R2ScoreResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the R^2 (coefficient of determination) regression score result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import R2ScoreResult\n&gt;&gt;&gt; result = R2ScoreResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nR2ScoreResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'r2_score': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.RecallResult","title":"arkas.result.RecallResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the recall result.</p> <p>This result can be used in 3 different settings:</p> <ul> <li>binary: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with <code>0</code> and <code>1</code> values, and <code>y_pred</code> must be an array     of shape <code>(n_samples,)</code>.</li> <li>multiclass: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with values in <code>{0, ..., n_classes-1}</code>, and <code>y_pred</code> must     be an array of shape <code>(n_samples,)</code>.</li> <li>multilabel: <code>y_true</code> must be an array of shape     <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values, and     <code>y_pred</code> must be an array of shape     <code>(n_samples, n_classes)</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import RecallResult\n&gt;&gt;&gt; # binary\n&gt;&gt;&gt; result = RecallResult(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     label_type=\"binary\",\n... )\n&gt;&gt;&gt; result\nRecallResult(y_true=(5,), y_pred=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'recall': 1.0}\n&gt;&gt;&gt; # multilabel\n&gt;&gt;&gt; result = RecallResult(\n...     y_true=np.array([[1, 0, 1], [0, 1, 0], [0, 1, 0], [1, 0, 1], [1, 0, 1]]),\n...     y_pred=np.array([[1, 0, 0], [0, 1, 1], [0, 1, 1], [1, 0, 0], [1, 0, 0]]),\n...     label_type=\"multilabel\",\n... )\n&gt;&gt;&gt; result\nRecallResult(y_true=(5, 3), y_pred=(5, 3), label_type='multilabel', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'macro_recall': 0.666...,\n 'micro_recall': 0.625,\n 'recall': array([1., 1., 0.]),\n 'weighted_recall': 0.625}\n&gt;&gt;&gt; # multiclass\n&gt;&gt;&gt; result = RecallResult(\n...     y_true=np.array([0, 0, 1, 1, 2, 2]),\n...     y_pred=np.array([0, 0, 1, 1, 2, 2]),\n...     label_type=\"multiclass\",\n... )\n&gt;&gt;&gt; result\nRecallResult(y_true=(6,), y_pred=(6,), label_type='multiclass', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 6,\n 'macro_recall': 1.0,\n 'micro_recall': 1.0,\n 'recall': array([1., 1., 1.]),\n 'weighted_recall': 1.0}\n&gt;&gt;&gt; # auto\n&gt;&gt;&gt; result = RecallResult(\n...     y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n... )\n&gt;&gt;&gt; result\nRecallResult(y_true=(5,), y_pred=(5,), label_type='binary', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'recall': 1.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.RegressionErrorResult","title":"arkas.result.RegressionErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement a \"universal\" regression error result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import RegressionErrorResult\n&gt;&gt;&gt; result = RegressionErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nRegressionErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5,\n 'mean_absolute_error': 0.0,\n 'median_absolute_error': 0.0,\n 'mean_squared_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.Result","title":"arkas.result.Result","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement a simple result.</p> <p>Parameters:</p> Name Type Description Default <code>metrics</code> <code>dict | None</code> <p>The metrics.</p> <code>None</code> <code>figures</code> <code>dict | None</code> <p>The figures.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.result import Result\n&gt;&gt;&gt; result = Result(metrics={\"accuracy\": 1.0, \"count\": 42}, figures={})\n&gt;&gt;&gt; result\nResult(metrics=2, figures=0)\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 1.0, 'count': 42}\n</code></pre>"},{"location":"refs/result/#arkas.result.RootMeanSquaredErrorResult","title":"arkas.result.RootMeanSquaredErrorResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the mean squared error (MSE) result.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target values.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted values.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import RootMeanSquaredErrorResult\n&gt;&gt;&gt; result = RootMeanSquaredErrorResult(\n...     y_true=np.array([1, 2, 3, 4, 5]), y_pred=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nRootMeanSquaredErrorResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'root_mean_squared_error': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.SequentialResult","title":"arkas.result.SequentialResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement a result to merge multiple result objects into a single result object.</p> <p>Parameters:</p> Name Type Description Default <code>results</code> <code>Sequence[BaseResult]</code> <p>The results to merge. This order is used to merge the metrics and figures if they have duplicate keys, i.e. only the last value for each key is kept.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import SequentialResult, Result\n&gt;&gt;&gt; result = SequentialResult(\n...     [\n...         Result(metrics={\"accuracy\": 62.0, \"count\": 42}),\n...         Result(metrics={\"ap\": 0.42, \"count\": 42}),\n...     ]\n... )\n&gt;&gt;&gt; result\nSequentialResult(count=2)\n&gt;&gt;&gt; result.compute_metrics()\n{'accuracy': 62.0, 'count': 42, 'ap': 0.42}\n</code></pre>"},{"location":"refs/result/#arkas.result.SpearmanCorrelationResult","title":"arkas.result.SpearmanCorrelationResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the Spearman correlation result.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>ndarray</code> <p>The first input array.</p> required <code>y</code> <code>ndarray</code> <p>The second input array.</p> required <code>alternative</code> <code>str</code> <p>The alternative hypothesis. Default is 'two-sided'. The following options are available: - 'two-sided': the correlation is nonzero - 'less': the correlation is negative (less than zero) - 'greater': the correlation is positive (greater than zero)</p> <code>'two-sided'</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import SpearmanCorrelationResult\n&gt;&gt;&gt; result = SpearmanCorrelationResult(\n...     x=np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n...     y=np.array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n... )\n&gt;&gt;&gt; result\nSpearmanCorrelationResult(x=(9,), y=(9,), alternative='two-sided', nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 9, 'spearman_coeff': 1.0, 'spearman_pvalue': 0.0}\n</code></pre>"},{"location":"refs/result/#arkas.result.WassersteinDistanceResult","title":"arkas.result.WassersteinDistanceResult","text":"<p>               Bases: <code>BaseResult</code></p> <p>Implement the Wasserstein distance between two 1D distributions result.</p> <p>Parameters:</p> Name Type Description Default <code>u_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>v_values</code> <code>ndarray</code> <p>The values observed in the (empirical) distribution.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.result import WassersteinDistanceResult\n&gt;&gt;&gt; result = WassersteinDistanceResult(\n...     u_values=np.array([1, 2, 3, 4, 5]), v_values=np.array([1, 2, 3, 4, 5])\n... )\n&gt;&gt;&gt; result\nWassersteinDistanceResult(u_values=(5,), v_values=(5,), nan_policy='propagate')\n&gt;&gt;&gt; result.compute_metrics()\n{'count': 5, 'wasserstein_distance': 0.0}\n</code></pre>"},{"location":"refs/runner/","title":"arkas.runner","text":""},{"location":"refs/runner/#arkas.runner","title":"arkas.runner","text":"<p>Contain runners.</p>"},{"location":"refs/runner/#arkas.runner.AnalysisRunner","title":"arkas.runner.AnalysisRunner","text":"<p>               Bases: <code>BaseRunner</code></p> <p>Implement a runner to analyze data.</p> <p>Parameters:</p> Name Type Description Default <code>ingestor</code> <code>BaseIngestor | dict</code> <p>The data ingestor or its configuration.</p> required <code>transformer</code> <code>BaseTransformer | dict</code> <p>The data transformer or its configuration.</p> required <code>analyzer</code> <code>BaseAnalyzer | dict</code> <p>The analyzer or its configuration.</p> required <code>exporter</code> <code>BaseExporter | dict</code> <p>The output exporter or its configuration.</p> required <code>lazy</code> <code>bool</code> <p>If <code>True</code>, the analyzer computation is done lazily.</p> <code>True</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; from arkas.runner import AnalysisRunner\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     runner = AnalysisRunner(\n...         ingestor=Ingestor(\n...             pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             )\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         analyzer=AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\"),\n...         exporter=MetricExporter(Path(tmpdir).joinpath(\"metrics.pkl\")),\n...     )\n...     print(runner)\n...     runner.run()\n...\nAnalysisRunner(\n  (ingestor): Ingestor(shape=(5, 2))\n  (transformer): SequentialTransformer()\n  (analyzer): AccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n  (exporter): MetricExporter(\n      (path): .../metrics.pkl\n      (saver): PickleSaver(protocol=5)\n      (exist_ok): False\n      (show_metrics): False\n    )\n  (lazy): True\n)\n</code></pre>"},{"location":"refs/runner/#arkas.runner.BaseRunner","title":"arkas.runner.BaseRunner","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement a runner.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; from arkas.runner import AnalysisRunner\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     runner = AnalysisRunner(\n...         ingestor=Ingestor(\n...             pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             )\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         analyzer=AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\"),\n...         exporter=MetricExporter(Path(tmpdir).joinpath(\"metrics.pkl\")),\n...     )\n...     print(runner)\n...     runner.run()\n...\nAnalysisRunner(\n  (ingestor): Ingestor(shape=(5, 2))\n  (transformer): SequentialTransformer()\n  (analyzer): AccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n  (exporter): MetricExporter(\n      (path): .../metrics.pkl\n      (saver): PickleSaver(protocol=5)\n      (exist_ok): False\n      (show_metrics): False\n    )\n  (lazy): True\n)\n</code></pre>"},{"location":"refs/runner/#arkas.runner.BaseRunner.run","title":"arkas.runner.BaseRunner.run  <code>abstractmethod</code>","text":"<pre><code>run() -&gt; Any\n</code></pre> <p>Execute the logic of the runner.</p> <p>Returns:</p> Type Description <code>Any</code> <p>Any artifact of the runner</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.analyzer import AccuracyAnalyzer\n&gt;&gt;&gt; from arkas.exporter import MetricExporter\n&gt;&gt;&gt; from arkas.runner import AnalysisRunner\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     runner = AnalysisRunner(\n...         ingestor=Ingestor(\n...             pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             )\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         analyzer=AccuracyAnalyzer(y_true=\"target\", y_pred=\"pred\"),\n...         exporter=MetricExporter(Path(tmpdir).joinpath(\"metrics.pkl\")),\n...     )\n...     runner.run()\n...\n</code></pre>"},{"location":"refs/runner/#arkas.runner.EvaluationRunner","title":"arkas.runner.EvaluationRunner","text":"<p>               Bases: <code>BaseRunner</code></p> <p>Implement a simple evaluation runner.</p> <p>Parameters:</p> Name Type Description Default <code>ingestor</code> <code>BaseIngestor | dict</code> <p>The data ingestor or its configuration.</p> required <code>transformer</code> <code>BaseTransformer | dict</code> <p>The data transformer or its configuration.</p> required <code>evaluator</code> <code>BaseEvaluator | dict</code> <p>The evaluator or its configuration.</p> required <code>saver</code> <code>BaseSaver | dict</code> <p>The metric saver or its configuration.</p> required <code>path</code> <code>Path | str</code> <p>The path where to save the metrics.</p> required <code>show_metrics</code> <code>bool</code> <p>If <code>True</code>, the metrics are shown in the logging output.</p> <code>True</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import tempfile\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from pathlib import Path\n&gt;&gt;&gt; from iden.io import PickleSaver\n&gt;&gt;&gt; from grizz.ingestor import Ingestor\n&gt;&gt;&gt; from grizz.transformer import SequentialTransformer\n&gt;&gt;&gt; from arkas.evaluator import AccuracyEvaluator\n&gt;&gt;&gt; from arkas.runner import EvaluationRunner\n&gt;&gt;&gt; with tempfile.TemporaryDirectory() as tmpdir:\n...     path = Path(tmpdir).joinpath(\"metrics.pkl\")\n...     runner = EvaluationRunner(\n...         ingestor=Ingestor(\n...             pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             )\n...         ),\n...         transformer=SequentialTransformer(transformers=[]),\n...         evaluator=AccuracyEvaluator(y_true=\"target\", y_pred=\"pred\"),\n...         saver=PickleSaver(),\n...         path=path,\n...     )\n...     print(runner)\n...     runner.run()\n...\nEvaluationRunner(\n  (ingestor): Ingestor(shape=(5, 2))\n  (transformer): SequentialTransformer()\n  (evaluator): AccuracyEvaluator(y_true='target', y_pred='pred', drop_nulls=True, nan_policy='propagate')\n  (saver): PickleSaver(protocol=5)\n  (path): .../metrics.pkl\n  (show_metrics): True\n)\n</code></pre>"},{"location":"refs/runner/#arkas.runner.is_runner_config","title":"arkas.runner.is_runner_config","text":"<pre><code>is_runner_config(config: dict) -&gt; bool\n</code></pre> <p>Indicate if the input configuration is a configuration for a <code>BaseRunner</code>.</p> <p>This function only checks if the value of the key  <code>_target_</code> is valid. It does not check the other values. If <code>_target_</code> indicates a function, the returned type hint is used to check the class.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>dict</code> <p>The configuration to check.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the input configuration is a configuration for a <code>BaseRunner</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.runner import is_runner_config\n&gt;&gt;&gt; is_runner_config(\n...     {\n...         \"_target_\": \"arkas.runner.AnalysisRunner\",\n...         \"ingestor\": {\n...             \"_target_\": \"grizz.ingestor.Ingestor\",\n...             \"frame\": pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             ),\n...         },\n...         \"transformer\": {\"_target_\": \"grizz.transformer.DropDuplicate\"},\n...         \"analyzer\": {\n...             \"_target_\": \"arkas.analyzer.AccuracyAnalyzer\",\n...             \"y_true\": \"target\",\n...             \"y_pred\": \"pred\",\n...         },\n...         \"exporter\": {\n...             \"_target_\": \"arkas.exporter.MetricExporter\",\n...             \"path\": \"/path/to/data.csv\",\n...         },\n...     }\n... )\nTrue\n</code></pre>"},{"location":"refs/runner/#arkas.runner.setup_runner","title":"arkas.runner.setup_runner","text":"<pre><code>setup_runner(runner: BaseRunner | dict) -&gt; BaseRunner\n</code></pre> <p>Set up a runner.</p> <p>The runner is instantiated from its configuration by using the <code>BaseRunner</code> factory function.</p> <p>Parameters:</p> Name Type Description Default <code>runner</code> <code>BaseRunner | dict</code> <p>Specifies a runner or its configuration.</p> required <p>Returns:</p> Type Description <code>BaseRunner</code> <p>An instantiated runner.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.runner import setup_runner\n&gt;&gt;&gt; runner = setup_runner(\n...     {\n...         \"_target_\": \"arkas.runner.AnalysisRunner\",\n...         \"ingestor\": {\n...             \"_target_\": \"grizz.ingestor.Ingestor\",\n...             \"frame\": pl.DataFrame(\n...                 {\n...                     \"pred\": [3, 2, 0, 1, 0],\n...                     \"target\": [3, 2, 0, 1, 0],\n...                 }\n...             ),\n...         },\n...         \"transformer\": {\"_target_\": \"grizz.transformer.DropDuplicate\"},\n...         \"analyzer\": {\n...             \"_target_\": \"arkas.analyzer.AccuracyAnalyzer\",\n...             \"y_true\": \"target\",\n...             \"y_pred\": \"pred\",\n...         },\n...         \"exporter\": {\n...             \"_target_\": \"arkas.exporter.MetricExporter\",\n...             \"path\": \"/path/to/data.csv\",\n...         },\n...     }\n... )\n&gt;&gt;&gt; runner\nAnalysisRunner(\n  (ingestor): Ingestor(shape=(5, 2))\n  (transformer): DropDuplicateTransformer(columns=None, exclude_columns=(), missing_policy='raise')\n  (analyzer): AccuracyAnalyzer(y_true='target', y_pred='pred', drop_nulls=True, missing_policy='raise', nan_policy='propagate')\n  (exporter): MetricExporter(\n      (path): /path/to/data.csv\n      (saver): PickleSaver(protocol=5)\n      (exist_ok): False\n      (show_metrics): False\n    )\n  (lazy): True\n)\n</code></pre>"},{"location":"refs/section/","title":"arkas.section","text":""},{"location":"refs/section/#arkas.section","title":"arkas.section","text":"<p>Contain sections.</p>"},{"location":"refs/section/#arkas.section.AccuracySection","title":"arkas.section.AccuracySection","text":"<p>               Bases: <code>BaseSection</code></p> <p>Implement a section that analyze accuracy results.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>BaseResult</code> <p>The data structure containing the results.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.section import AccuracySection\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; section = AccuracySection(\n...     result=AccuracyResult(\n...         y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n...     )\n... )\n&gt;&gt;&gt; section\nAccuracySection(\n  (result): AccuracyResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n)\n&gt;&gt;&gt; section.generate_html_body()\n</code></pre>"},{"location":"refs/section/#arkas.section.BaseSection","title":"arkas.section.BaseSection","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to manage sections.</p>"},{"location":"refs/section/#arkas.section.BaseSection.equal","title":"arkas.section.BaseSection.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any) -&gt; bool\n</code></pre> <p>Indicate if two sections are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other section to compare.</p> required <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two sections are equal, otherwise <code>False</code>.</p>"},{"location":"refs/section/#arkas.section.BaseSection.generate_html_body","title":"arkas.section.BaseSection.generate_html_body  <code>abstractmethod</code>","text":"<pre><code>generate_html_body(\n    number: str = \"\",\n    tags: Sequence[str] = (),\n    depth: int = 0,\n) -&gt; str\n</code></pre> <p>Return the HTML body associated to the section.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>str</code> <p>The section number.</p> <code>''</code> <code>tags</code> <code>Sequence[str]</code> <p>The tags associated to the section.</p> <code>()</code> <code>depth</code> <code>int</code> <p>The depth in the report.</p> <code>0</code> <p>Returns:</p> Type Description <code>str</code> <p>The HTML body associated to the section.</p>"},{"location":"refs/section/#arkas.section.BaseSection.generate_html_toc","title":"arkas.section.BaseSection.generate_html_toc  <code>abstractmethod</code>","text":"<pre><code>generate_html_toc(\n    number: str = \"\",\n    tags: Sequence[str] = (),\n    depth: int = 0,\n    max_depth: int = 1,\n) -&gt; str\n</code></pre> <p>Return the HTML table of content (TOC) associated to the section.</p> <p>Parameters:</p> Name Type Description Default <code>number</code> <code>str</code> <p>The section number associated to the section.</p> <code>''</code> <code>tags</code> <code>Sequence[str]</code> <p>The tags associated to the section.</p> <code>()</code> <code>depth</code> <code>int</code> <p>The depth in the report.</p> <code>0</code> <code>max_depth</code> <code>int</code> <p>The maximum depth to generate in the TOC.</p> <code>1</code> <p>Returns:</p> Type Description <code>str</code> <p>The HTML table of content associated to the section.</p>"},{"location":"refs/section/#arkas.section.BinaryPrecisionSection","title":"arkas.section.BinaryPrecisionSection","text":"<p>               Bases: <code>BaseSection</code></p> <p>Implement a section that analyze precision results.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>BaseResult</code> <p>The data structure containing the results.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.section import BinaryPrecisionSection\n&gt;&gt;&gt; from arkas.result import BinaryPrecisionResult\n&gt;&gt;&gt; section = BinaryPrecisionSection(\n...     result=BinaryPrecisionResult(\n...         y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n...     )\n... )\n&gt;&gt;&gt; section\nBinaryPrecisionSection(\n  (result): BinaryPrecisionResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n)\n&gt;&gt;&gt; section.generate_html_body()\n</code></pre>"},{"location":"refs/section/#arkas.section.ContentSection","title":"arkas.section.ContentSection","text":"<p>               Bases: <code>BaseSection</code></p> <p>Implement a section that generates the given custom content.</p> <p>Parameters:</p> Name Type Description Default <code>content</code> <code>str</code> <p>The content to use in the HTML code.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.section import ContentSection\n&gt;&gt;&gt; section = ContentSection(content=\"meow\")\n&gt;&gt;&gt; section\nContentSection()\n&gt;&gt;&gt; section.generate_html_body()\n</code></pre>"},{"location":"refs/section/#arkas.section.ResultSection","title":"arkas.section.ResultSection","text":"<p>               Bases: <code>BaseSection</code></p> <p>Implement a section that show the results in a HTML format.</p> <p>Parameters:</p> Name Type Description Default <code>result</code> <code>BaseResult</code> <p>The data structure containing the results.</p> required <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.section import ResultSection\n&gt;&gt;&gt; from arkas.result import AccuracyResult\n&gt;&gt;&gt; section = ResultSection(\n...     result=AccuracyResult(\n...         y_true=np.array([1, 0, 0, 1, 1]), y_pred=np.array([1, 0, 0, 1, 1])\n...     )\n... )\n&gt;&gt;&gt; section\nResultSection(\n  (result): AccuracyResult(y_true=(5,), y_pred=(5,), nan_policy='propagate')\n)\n&gt;&gt;&gt; section.generate_html_body()\n</code></pre>"},{"location":"refs/state/","title":"arkas.state","text":""},{"location":"refs/state/#arkas.state","title":"arkas.state","text":"<p>Contain states.</p>"},{"location":"refs/state/#arkas.state.AccuracyState","title":"arkas.state.AccuracyState","text":"<p>               Bases: <code>BaseState</code></p> <p>Implement the accuracy state.</p> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> where the values are in <code>{0, ..., n_classes-1}</code>.</p> required <code>y_true_name</code> <code>str</code> <p>The name associated to the ground truth target labels.</p> required <code>y_pred_name</code> <code>str</code> <p>The name associated to the predicted labels.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; state = AccuracyState(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n&gt;&gt;&gt; state\nAccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n</code></pre>"},{"location":"refs/state/#arkas.state.BaseArgState","title":"arkas.state.BaseArgState","text":"<p>               Bases: <code>BaseState</code></p> <p>Define a base class to manage arbitrary keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code>"},{"location":"refs/state/#arkas.state.BaseArgState.get_arg","title":"arkas.state.BaseArgState.get_arg","text":"<pre><code>get_arg(name: str, default: Any = None) -&gt; Any\n</code></pre> <p>Get a given argument from the state.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The argument name to get.</p> required <code>default</code> <code>Any</code> <p>The default value to return if the argument is missing.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The argument value or the default value.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...     },\n...     schema={\"col1\": pl.Int64, \"col2\": pl.Int32, \"col3\": pl.Float64},\n... )\n&gt;&gt;&gt; state = DataFrameState(frame, column=\"col3\")\n&gt;&gt;&gt; state.get_arg(\"column\")\ncol3\n</code></pre>"},{"location":"refs/state/#arkas.state.BaseArgState.get_args","title":"arkas.state.BaseArgState.get_args","text":"<pre><code>get_args() -&gt; dict\n</code></pre> <p>Get a dictionary with all the arguments of the state.</p> <p>Returns:</p> Type Description <code>dict</code> <p>The dictionary with all the arguments.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...     },\n...     schema={\"col1\": pl.Int64, \"col2\": pl.Int32, \"col3\": pl.Float64},\n... )\n&gt;&gt;&gt; state = DataFrameState(frame, column=\"col3\")\n&gt;&gt;&gt; args = state.get_args()\n</code></pre>"},{"location":"refs/state/#arkas.state.BaseState","title":"arkas.state.BaseState","text":"<p>               Bases: <code>ABC</code></p> <p>Define the base class to implement a state.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; state = AccuracyState(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n&gt;&gt;&gt; state\nAccuracyState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', nan_policy='propagate')\n</code></pre>"},{"location":"refs/state/#arkas.state.BaseState.clone","title":"arkas.state.BaseState.clone  <code>abstractmethod</code>","text":"<pre><code>clone(deep: bool = True) -&gt; Self\n</code></pre> <p>Return a copy of the state.</p> <p>Parameters:</p> Name Type Description Default <code>deep</code> <code>bool</code> <p>If <code>True</code>, it returns a deep copy of the state, otherwise it returns a shallow copy.</p> <code>True</code> <p>Returns:</p> Type Description <code>Self</code> <p>A copy of the state.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; state = AccuracyState(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n... cloned_state = state.clone()\n</code></pre>"},{"location":"refs/state/#arkas.state.BaseState.equal","title":"arkas.state.BaseState.equal  <code>abstractmethod</code>","text":"<pre><code>equal(other: Any, equal_nan: bool = False) -&gt; bool\n</code></pre> <p>Indicate if two states are equal or not.</p> <p>Parameters:</p> Name Type Description Default <code>other</code> <code>Any</code> <p>The other state to compare.</p> required <code>equal_nan</code> <code>bool</code> <p>Whether to compare NaN's as equal. If <code>True</code>, NaN's in both objects will be considered equal.</p> <code>False</code> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if the two states are equal, otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import AccuracyState\n&gt;&gt;&gt; state1 = AccuracyState(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n&gt;&gt;&gt; state2 = AccuracyState(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n&gt;&gt;&gt; state3 = AccuracyState(\n...     y_true=np.array([1, 0, 0, 0, 0]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n&gt;&gt;&gt; state1.equal(state2)\nTrue\n&gt;&gt;&gt; state1.equal(state3)\nFalse\n</code></pre>"},{"location":"refs/state/#arkas.state.ColumnCooccurrenceState","title":"arkas.state.ColumnCooccurrenceState","text":"<p>               Bases: <code>BaseState</code></p> <p>Implement the column co-occurrence state.</p> <p>Parameters:</p> Name Type Description Default <code>matrix</code> <code>ndarray</code> <p>The co-occurrence matrix.</p> required <code>columns</code> <code>Sequence[str]</code> <p>The column names.</p> required <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>An optional figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import ColumnCooccurrenceState\n&gt;&gt;&gt; state = ColumnCooccurrenceState(matrix=np.ones((3, 3)), columns=[\"a\", \"b\", \"c\"])\n&gt;&gt;&gt; state\nColumnCooccurrenceState(matrix=(3, 3), figure_config=MatplotlibFigureConfig())\n</code></pre>"},{"location":"refs/state/#arkas.state.ColumnCooccurrenceState.from_dataframe","title":"arkas.state.ColumnCooccurrenceState.from_dataframe  <code>classmethod</code>","text":"<pre><code>from_dataframe(\n    frame: DataFrame,\n    ignore_self: bool = False,\n    figure_config: BaseFigureConfig | None = None,\n) -&gt; ColumnCooccurrenceState\n</code></pre> <p>Instantiate a <code>ColumnCooccurrenceState</code> object from a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>frame</code> <code>DataFrame</code> <p>The DataFrame to analyze.</p> required <code>ignore_self</code> <code>bool</code> <p>If <code>True</code>, the diagonal of the co-occurrence matrix (a.k.a. self-co-occurrence) is set to 0.</p> <code>False</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>An optional figure configuration.</p> <code>None</code> <p>Returns:</p> Type Description <code>ColumnCooccurrenceState</code> <p>The instantiate state.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.state import ColumnCooccurrenceState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [0, 0, 0, 0, 1, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; state = ColumnCooccurrenceState.from_dataframe(frame)\n&gt;&gt;&gt; state\nColumnCooccurrenceState(matrix=(3, 3), figure_config=MatplotlibFigureConfig())\n</code></pre>"},{"location":"refs/state/#arkas.state.DataFrameState","title":"arkas.state.DataFrameState","text":"<p>               Bases: <code>BaseArgState</code></p> <p>Implement the DataFrame state.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The DataFrame.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>An optional figure configuration.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.state import DataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [0, 0, 0, 0, 1, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; state = DataFrameState(frame)\n&gt;&gt;&gt; state\nDataFrameState(dataframe=(7, 3), nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n</code></pre>"},{"location":"refs/state/#arkas.state.NullValueState","title":"arkas.state.NullValueState","text":"<p>               Bases: <code>BaseState</code></p> <p>Implement a state that contains the number of null values per columns.</p> <p>Parameters:</p> Name Type Description Default <code>null_count</code> <code>ndarray</code> <p>The array with the number of null values for each column.</p> required <code>total_count</code> <code>ndarray</code> <p>The total number of values for each column.</p> required <code>columns</code> <code>Sequence[str]</code> <p>The column names.</p> required <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>An optional figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import NullValueState\n&gt;&gt;&gt; state = NullValueState(\n...     null_count=np.array([0, 1, 2]),\n...     total_count=np.array([5, 5, 5]),\n...     columns=[\"col1\", \"col2\", \"col3\"],\n... )\n&gt;&gt;&gt; state\nNullValueState(num_columns=3, figure_config=MatplotlibFigureConfig())\n</code></pre>"},{"location":"refs/state/#arkas.state.NullValueState.from_dataframe","title":"arkas.state.NullValueState.from_dataframe  <code>classmethod</code>","text":"<pre><code>from_dataframe(\n    dataframe: DataFrame,\n    figure_config: BaseFigureConfig | None = None,\n) -&gt; NullValueState\n</code></pre> <p>Instantiate a <code>NullValueState</code> object from a DataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The DataFrame.</p> required <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>An optional figure configuration.</p> <code>None</code> <p>Returns:</p> Type Description <code>NullValueState</code> <p>The instantiated <code>NullValueState</code> object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.state import NullValueState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, None],\n...         \"col2\": [0, 1, None, None, 0, 1, 0],\n...         \"col3\": [None, 0, 0, 0, None, 1, None],\n...     }\n... )\n&gt;&gt;&gt; state = NullValueState.from_dataframe(frame)\n&gt;&gt;&gt; state\nNullValueState(num_columns=3, figure_config=MatplotlibFigureConfig())\n</code></pre>"},{"location":"refs/state/#arkas.state.NullValueState.to_dataframe","title":"arkas.state.NullValueState.to_dataframe","text":"<pre><code>to_dataframe() -&gt; DataFrame\n</code></pre> <p>Export the content of the state to a DataFrame.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The DataFrame.</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import NullValueState\n&gt;&gt;&gt; state = NullValueState(\n...     null_count=np.array([0, 1, 2]),\n...     total_count=np.array([5, 5, 5]),\n...     columns=[\"col1\", \"col2\", \"col3\"],\n... )\n&gt;&gt;&gt; state.to_dataframe()\nshape: (3, 3)\n\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n\u2502 column \u2506 null \u2506 total \u2502\n\u2502 ---    \u2506 ---  \u2506 ---   \u2502\n\u2502 str    \u2506 i64  \u2506 i64   \u2502\n\u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n\u2502 col1   \u2506 0    \u2506 5     \u2502\n\u2502 col2   \u2506 1    \u2506 5     \u2502\n\u2502 col3   \u2506 2    \u2506 5     \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre>"},{"location":"refs/state/#arkas.state.PrecisionRecallState","title":"arkas.state.PrecisionRecallState","text":"<p>               Bases: <code>BaseState</code></p> <p>Implement a state for precision-recall-based metrics.</p> <p>This state can be used in 3 different settings:</p> <ul> <li>binary: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with <code>0</code> and <code>1</code> values, and <code>y_pred</code> must be an array     of shape <code>(n_samples,)</code>.</li> <li>multiclass: <code>y_true</code> must be an array of shape <code>(n_samples,)</code>     with values in <code>{0, ..., n_classes-1}</code>, and <code>y_pred</code> must     be an array of shape <code>(n_samples,)</code>.</li> <li>multilabel: <code>y_true</code> must be an array of shape     <code>(n_samples, n_classes)</code> with <code>0</code> and <code>1</code> values, and     <code>y_pred</code> must be an array of shape     <code>(n_samples, n_classes)</code>.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>y_true</code> <code>ndarray</code> <p>The ground truth target labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_pred</code> <code>ndarray</code> <p>The predicted labels. This input must be an array of shape <code>(n_samples,)</code> or <code>(n_samples, n_classes)</code>.</p> required <code>y_true_name</code> <code>str</code> <p>The name associated to the ground truth target labels.</p> required <code>y_pred_name</code> <code>str</code> <p>The name associated to the predicted labels.</p> required <code>label_type</code> <code>str</code> <p>The type of labels used to evaluate the metrics. The valid values are: <code>'binary'</code>, <code>'multiclass'</code>, and <code>'multilabel'</code>. If <code>'binary'</code> or <code>'multilabel'</code>, <code>y_true</code> values  must be <code>0</code> and <code>1</code>.</p> <code>'auto'</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from arkas.state import PrecisionRecallState\n&gt;&gt;&gt; state = PrecisionRecallState(\n...     y_true=np.array([1, 0, 0, 1, 1]),\n...     y_pred=np.array([1, 0, 0, 1, 1]),\n...     y_true_name=\"target\",\n...     y_pred_name=\"pred\",\n... )\n&gt;&gt;&gt; state\nPrecisionRecallState(y_true=(5,), y_pred=(5,), y_true_name='target', y_pred_name='pred', label_type='binary', nan_policy='propagate')\n</code></pre>"},{"location":"refs/state/#arkas.state.ScatterDataFrameState","title":"arkas.state.ScatterDataFrameState","text":"<p>               Bases: <code>DataFrameState</code></p> <p>Implement the DataFrame state for scatter plots.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The DataFrame.</p> required <code>x</code> <code>str</code> <p>The x-axis data column.</p> required <code>y</code> <code>str</code> <p>The y-axis data column.</p> required <code>color</code> <code>str | None</code> <p>An optional color axis data column.</p> <code>None</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>An optional figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.state import ScatterDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [0, 0, 0, 0, 1, 1, 1],\n...     }\n... )\n&gt;&gt;&gt; state = ScatterDataFrameState(frame, x=\"col1\", y=\"col2\")\n&gt;&gt;&gt; state\nScatterDataFrameState(dataframe=(7, 3), x='col1', y='col2', color=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n</code></pre>"},{"location":"refs/state/#arkas.state.SeriesState","title":"arkas.state.SeriesState","text":"<p>               Bases: <code>BaseState</code></p> <p>Implement the Series state.</p> <p>Parameters:</p> Name Type Description Default <code>series</code> <code>Series</code> <p>The Series.</p> required <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>An optional figure configuration.</p> <code>None</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.state import SeriesState\n&gt;&gt;&gt; state = SeriesState(pl.Series(\"col1\", [1, 2, 3, 4, 5, 6, 7]))\n&gt;&gt;&gt; state\nSeriesState(name='col1', values=(7,), figure_config=MatplotlibFigureConfig())\n</code></pre>"},{"location":"refs/state/#arkas.state.TargetDataFrameState","title":"arkas.state.TargetDataFrameState","text":"<p>               Bases: <code>DataFrameState</code></p> <p>Implement a DataFrame state with a target column.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The DataFrame.</p> required <code>target_column</code> <code>str</code> <p>The target column in the DataFrame.</p> required <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>An optional figure configuration.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.state import TargetDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0, 0, 1, 0],\n...         \"col2\": [0, 1, 0, 1, 0, 1, 0],\n...         \"col3\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0],\n...     },\n...     schema={\"col1\": pl.Int64, \"col2\": pl.Int32, \"col3\": pl.Float64},\n... )\n&gt;&gt;&gt; state = TargetDataFrameState(frame, target_column=\"col3\")\n&gt;&gt;&gt; state\nTargetDataFrameState(dataframe=(7, 3), target_column='col3', nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n</code></pre>"},{"location":"refs/state/#arkas.state.TemporalDataFrameState","title":"arkas.state.TemporalDataFrameState","text":"<p>               Bases: <code>DataFrameState</code></p> <p>Implement the temporal DataFrame state.</p> <p>Parameters:</p> Name Type Description Default <code>dataframe</code> <code>DataFrame</code> <p>The DataFrame.</p> required <code>temporal_column</code> <code>str</code> <p>The temporal column in the DataFrame.</p> required <code>period</code> <code>str | None</code> <p>An optional temporal period e.g. monthly or daily.</p> <code>None</code> <code>nan_policy</code> <code>str</code> <p>The policy on how to handle NaN values in the input arrays. The following options are available: <code>'omit'</code>, <code>'propagate'</code>, and <code>'raise'</code>.</p> <code>'propagate'</code> <code>figure_config</code> <code>BaseFigureConfig | None</code> <p>An optional figure configuration.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from datetime import datetime, timezone\n&gt;&gt;&gt; import polars as pl\n&gt;&gt;&gt; from arkas.state import TemporalDataFrameState\n&gt;&gt;&gt; frame = pl.DataFrame(\n...     {\n...         \"col1\": [0, 1, 1, 0],\n...         \"col2\": [0, 1, 0, 1],\n...         \"col3\": [1, 0, 0, 0],\n...         \"datetime\": [\n...             datetime(year=2020, month=1, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=2, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=3, day=3, tzinfo=timezone.utc),\n...             datetime(year=2020, month=4, day=3, tzinfo=timezone.utc),\n...         ],\n...     },\n...     schema={\n...         \"col1\": pl.Int64,\n...         \"col2\": pl.Int64,\n...         \"col3\": pl.Int64,\n...         \"datetime\": pl.Datetime(time_unit=\"us\", time_zone=\"UTC\"),\n...     },\n... )\n&gt;&gt;&gt; state = TemporalDataFrameState(frame, temporal_column=\"datetime\")\n&gt;&gt;&gt; state\nTemporalDataFrameState(dataframe=(4, 4), temporal_column='datetime', period=None, nan_policy='propagate', figure_config=MatplotlibFigureConfig())\n</code></pre>"},{"location":"refs/utils/","title":"arkas.utils","text":""},{"location":"refs/utils/#arkas.utils","title":"arkas.utils","text":"<p>Contain utility functions.</p>"},{"location":"refs/utils/#arkas.utils.factory","title":"arkas.utils.factory","text":"<p>Contain a function to instantiate an object from its configuration.</p>"},{"location":"refs/utils/#arkas.utils.factory.setup_object","title":"arkas.utils.factory.setup_object","text":"<pre><code>setup_object(obj_or_config: T | dict) -&gt; T\n</code></pre> <p>Set up an object from its configuration.</p> <p>Parameters:</p> Name Type Description Default <code>obj_or_config</code> <code>T | dict</code> <p>The object or its configuration.</p> required <p>Returns:</p> Type Description <code>T</code> <p>The instantiated object.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.factory import setup_object\n&gt;&gt;&gt; obj = setup_object({\"_target_\": \"collections.deque\", \"iterable\": [1, 2, 1, 3]})\n&gt;&gt;&gt; obj\ndeque([1, 2, 1, 3])\n&gt;&gt;&gt; setup_object(obj)  # Do nothing because the object is already instantiated\ndeque([1, 2, 1, 3])\n</code></pre>"},{"location":"refs/utils/#arkas.utils.figure","title":"arkas.utils.figure","text":"<p>Contain utility functions to manage matplotlib figures.</p>"},{"location":"refs/utils/#arkas.utils.figure.figure2html","title":"arkas.utils.figure.figure2html","text":"<pre><code>figure2html(\n    fig: Figure | None,\n    reactive: bool = True,\n    close_fig: bool = False,\n) -&gt; str\n</code></pre> <p>Convert a matplotlib figure to a string that can be used in a HTML file.</p> <p>Parameters:</p> Name Type Description Default <code>fig</code> <code>Figure | None</code> <p>The figure to convert.</p> required <code>reactive</code> <code>bool</code> <p>If <code>True</code>, the generated is configured to be reactive to the screen size.</p> <code>True</code> <code>close_fig</code> <code>bool</code> <p>If <code>True</code>, the figure is closed after it is converted to HTML format.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The converted figure to a string.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from matplotlib import pyplot as plt\n&gt;&gt;&gt; from arkas.utils.figure import figure2html\n&gt;&gt;&gt; fig, ax = plt.subplots()\n&gt;&gt;&gt; string = figure2html(fig)\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports","title":"arkas.utils.imports","text":"<p>Implement some utility functions to manage optional dependencies.</p>"},{"location":"refs/utils/#arkas.utils.imports.check_colorlog","title":"arkas.utils.imports.check_colorlog","text":"<pre><code>check_colorlog() -&gt; None\n</code></pre> <p>Check if the <code>colorlog</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>colorlog</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_colorlog\n&gt;&gt;&gt; check_colorlog()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_hya","title":"arkas.utils.imports.check_hya","text":"<pre><code>check_hya() -&gt; None\n</code></pre> <p>Check if the <code>hya</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>hya</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_hya\n&gt;&gt;&gt; check_hya()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_hydra","title":"arkas.utils.imports.check_hydra","text":"<pre><code>check_hydra() -&gt; None\n</code></pre> <p>Check if the <code>hydra</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>hydra</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_hydra\n&gt;&gt;&gt; check_hydra()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_markdown","title":"arkas.utils.imports.check_markdown","text":"<pre><code>check_markdown() -&gt; None\n</code></pre> <p>Check if the <code>markdown</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>markdown</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_markdown\n&gt;&gt;&gt; check_markdown()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_matplotlib","title":"arkas.utils.imports.check_matplotlib","text":"<pre><code>check_matplotlib() -&gt; None\n</code></pre> <p>Check if the <code>matplotlib</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>matplotlib</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_matplotlib\n&gt;&gt;&gt; check_matplotlib()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_omegaconf","title":"arkas.utils.imports.check_omegaconf","text":"<pre><code>check_omegaconf() -&gt; None\n</code></pre> <p>Check if the <code>omegaconf</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>omegaconf</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_omegaconf\n&gt;&gt;&gt; check_omegaconf()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_plotly","title":"arkas.utils.imports.check_plotly","text":"<pre><code>check_plotly() -&gt; None\n</code></pre> <p>Check if the <code>plotly</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>plotly</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_plotly\n&gt;&gt;&gt; check_plotly()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.check_scipy","title":"arkas.utils.imports.check_scipy","text":"<pre><code>check_scipy() -&gt; None\n</code></pre> <p>Check if the <code>scipy</code> package is installed.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>if the <code>scipy</code> package is not installed.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import check_scipy\n&gt;&gt;&gt; check_scipy()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.colorlog_available","title":"arkas.utils.imports.colorlog_available","text":"<pre><code>colorlog_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>colorlog</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>colorlog</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import colorlog_available\n&gt;&gt;&gt; @colorlog_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.hya_available","title":"arkas.utils.imports.hya_available","text":"<pre><code>hya_available(fn: Callable[..., Any]) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>hya</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>hya</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import hya_available\n&gt;&gt;&gt; @hya_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.hydra_available","title":"arkas.utils.imports.hydra_available","text":"<pre><code>hydra_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>hydra</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>hydra</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import hydra_available\n&gt;&gt;&gt; @hydra_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_colorlog_available","title":"arkas.utils.imports.is_colorlog_available","text":"<pre><code>is_colorlog_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>colorlog</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>colorlog</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_colorlog_available\n&gt;&gt;&gt; is_colorlog_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_hya_available","title":"arkas.utils.imports.is_hya_available","text":"<pre><code>is_hya_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>hya</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>hya</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_hya_available\n&gt;&gt;&gt; is_hya_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_hydra_available","title":"arkas.utils.imports.is_hydra_available","text":"<pre><code>is_hydra_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>hydra</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>hydra</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_hydra_available\n&gt;&gt;&gt; is_hydra_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_markdown_available","title":"arkas.utils.imports.is_markdown_available","text":"<pre><code>is_markdown_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>markdown</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>markdown</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_markdown_available\n&gt;&gt;&gt; is_markdown_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_matplotlib_available","title":"arkas.utils.imports.is_matplotlib_available","text":"<pre><code>is_matplotlib_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>matplotlib</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>matplotlib</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_matplotlib_available\n&gt;&gt;&gt; is_matplotlib_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_omegaconf_available","title":"arkas.utils.imports.is_omegaconf_available","text":"<pre><code>is_omegaconf_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>omegaconf</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>omegaconf</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_omegaconf_available\n&gt;&gt;&gt; is_omegaconf_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_plotly_available","title":"arkas.utils.imports.is_plotly_available","text":"<pre><code>is_plotly_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>plotly</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>plotly</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_plotly_available\n&gt;&gt;&gt; is_plotly_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.is_scipy_available","title":"arkas.utils.imports.is_scipy_available","text":"<pre><code>is_scipy_available() -&gt; bool\n</code></pre> <p>Indicate if the <code>scipy</code> package is installed or not.</p> <p>Returns:</p> Type Description <code>bool</code> <p><code>True</code> if <code>scipy</code> is available otherwise <code>False</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import is_scipy_available\n&gt;&gt;&gt; is_scipy_available()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.markdown_available","title":"arkas.utils.imports.markdown_available","text":"<pre><code>markdown_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>markdown</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>markdown</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import markdown_available\n&gt;&gt;&gt; @markdown_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.matplotlib_available","title":"arkas.utils.imports.matplotlib_available","text":"<pre><code>matplotlib_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>matplotlib</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>matplotlib</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import matplotlib_available\n&gt;&gt;&gt; @matplotlib_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.omegaconf_available","title":"arkas.utils.imports.omegaconf_available","text":"<pre><code>omegaconf_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>omegaconf</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>omegaconf</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import omegaconf_available\n&gt;&gt;&gt; @omegaconf_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.plotly_available","title":"arkas.utils.imports.plotly_available","text":"<pre><code>plotly_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>plotly</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>plotly</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import plotly_available\n&gt;&gt;&gt; @plotly_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.imports.scipy_available","title":"arkas.utils.imports.scipy_available","text":"<pre><code>scipy_available(\n    fn: Callable[..., Any]\n) -&gt; Callable[..., Any]\n</code></pre> <p>Implement a decorator to execute a function only if <code>scipy</code> package is installed.</p> <p>Parameters:</p> Name Type Description Default <code>fn</code> <code>Callable[..., Any]</code> <p>The function to execute.</p> required <p>Returns:</p> Type Description <code>Callable[..., Any]</code> <p>A wrapper around <code>fn</code> if <code>scipy</code> package is installed, otherwise <code>None</code>.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.imports import scipy_available\n&gt;&gt;&gt; @scipy_available\n... def my_function(n: int = 0) -&gt; int:\n...     return 42 + n\n...\n&gt;&gt;&gt; my_function()\n</code></pre>"},{"location":"refs/utils/#arkas.utils.text","title":"arkas.utils.text","text":"<p>Contain text utility functions.</p>"},{"location":"refs/utils/#arkas.utils.text.markdown_to_html","title":"arkas.utils.text.markdown_to_html","text":"<pre><code>markdown_to_html(\n    text: str, ignore_error: bool = False\n) -&gt; str\n</code></pre> <p>Convert a markdown text to HTML text.</p> <p>Parameters:</p> Name Type Description Default <code>text</code> <code>str</code> <p>The markdown text to convert.</p> required <code>ignore_error</code> <code>bool</code> <p>If <code>False</code>, an error is raised if <code>markdown</code> is not installed, otherwise the input text is returned.</p> <code>False</code> <p>Returns:</p> Type Description <code>str</code> <p>The converted text if <code>markdown</code> is installed, otherwise the input text.</p> <p>Example usage:</p> <pre><code>&gt;&gt;&gt; from arkas.utils.text import markdown_to_html\n&gt;&gt;&gt; out = markdown_to_html(\"- a\\n- b\\n- c\")\n&gt;&gt;&gt; print(out)\n&lt;ul&gt;\n&lt;li&gt;a&lt;/li&gt;\n&lt;li&gt;b&lt;/li&gt;\n&lt;li&gt;c&lt;/li&gt;\n&lt;/ul&gt;\n</code></pre>"}]}